{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c039d719",
      "metadata": {
        "id": "c039d719"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IvanNece/Detection-of-Anomalies-with-Localization/blob/main/notebooks/10_global_model_clean.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d67760d",
      "metadata": {
        "id": "6d67760d"
      },
      "source": [
        "# PHASE 8: Global Model - Unified Training\n",
        "\n",
        "**Objective**: Train a **single** anomaly detection model on **all 3 classes** simultaneously.\n",
        "\n",
        "## Key Differences from Per-Class Models:\n",
        "1. **Single Model**: Train ONE PatchCore and ONE PaDiM on merged training data\n",
        "2. **Per-Class Thresholds**: Calibrate separate thresholds for each class on validation\n",
        "3. **Identical Shortcut Problem**: Can normals from one class be confused with anomalies from another?\n",
        "4. **Performance Gap Analysis**: Quantify degradation vs per-class models\n",
        "\n",
        "---\n",
        "\n",
        "## Expected Outcome:\n",
        "Global models should perform **worse** than per-class models due to:\n",
        "- **Distribution heterogeneity**: Mixing different textures/objects\n",
        "- **Identical shortcut**: Normal patterns of Class A may appear anomalous for Class B\n",
        "- **Feature space contamination**: Shared representation struggles with diverse nominal distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73a7b8b",
      "metadata": {
        "id": "a73a7b8b"
      },
      "source": [
        "## Terminological Note (Model-Unified vs Absolute-Unified)\n",
        "\n",
        "Following the taxonomy from recent literature [CADA, Guo et al. 2024; HierCore, Heo & Kang 2025]:\n",
        "\n",
        "| Setting | Training | Inference | Threshold | Our Experiment |\n",
        "|---------|----------|-----------|-----------|----------------|\n",
        "| **Per-Class** | Separate model per class | Class known | Per-class | ❌ |\n",
        "| **Model-Unified** | Single model for all classes | Class known | Per-class | ✅ **This notebook** |\n",
        "| **Absolute-Unified** | Single model for all classes | Class UNKNOWN | Single global | ❌ |\n",
        "\n",
        "**Our setting**: We train ONE global model but calibrate **per-class thresholds** at inference\n",
        "(class is known). This is the \"model-unified\" setting, NOT \"absolute-unified\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d69dc0",
      "metadata": {
        "id": "83d69dc0"
      },
      "source": [
        "## 0. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffcfc2ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffcfc2ec",
        "outputId": "20c0c3df-38a4-4570-da72-345ff1b569e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Done!\n",
            "\n",
            "Cloning repository (branch: main)...\n",
            "Cloning into '/content/Detection-of-Anomalies-with-Localization'...\n",
            "remote: Enumerating objects: 994, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 994 (delta 85), reused 103 (delta 35), pack-reused 798 (from 2)\u001b[K\n",
            "Receiving objects: 100% (994/994), 333.01 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (542/542), done.\n",
            "Filtering content: 100% (14/14), 501.63 MiB | 45.76 MiB/s, done.\n",
            "Done!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SETUP COMPLETE - PHASE 8: GLOBAL MODEL (MODEL-UNIFIED)\n",
            "======================================================================\n",
            "Project:    /content/Detection-of-Anomalies-with-Localization\n",
            "Dataset:    /content/drive/MyDrive/mvtec_ad\n",
            "Branch:     main\n",
            "Models:     /content/Detection-of-Anomalies-with-Localization/outputs/models\n",
            "Results:    /content/Detection-of-Anomalies-with-Localization/outputs/results\n",
            "Thresholds: /content/Detection-of-Anomalies-with-Localization/outputs/thresholds\n",
            "Viz:        /content/Detection-of-Anomalies-with-Localization/outputs/visualizations/global_model\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SETUP - Mount Google Drive & Clone Repository\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Clone repository on main branch\n",
        "print(\"Cloning repository (branch: main)...\")\n",
        "repo_dir = '/content/Detection-of-Anomalies-with-Localization'\n",
        "\n",
        "# Remove if exists\n",
        "if os.path.exists(repo_dir):\n",
        "    print(\"Removing existing repository...\")\n",
        "    !rm -rf {repo_dir}\n",
        "\n",
        "# Clone from main branch\n",
        "!git clone https://github.com/IvanNece/Detection-of-Anomalies-with-Localization.git {repo_dir}\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT = Path(repo_dir)\n",
        "\n",
        "# Dataset location (only clean for this notebook)\n",
        "CLEAN_DATASET_PATH = Path('/content/drive/MyDrive/mvtec_ad')\n",
        "\n",
        "# Output directories\n",
        "MODELS_DIR = PROJECT_ROOT / 'outputs' / 'models'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'outputs' / 'results'\n",
        "THRESHOLDS_DIR = PROJECT_ROOT / 'outputs' / 'thresholds'\n",
        "VIZ_DIR = PROJECT_ROOT / 'outputs' / 'visualizations' / 'global_model'\n",
        "\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "THRESHOLDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify dataset exists\n",
        "if not CLEAN_DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Clean dataset not found at {CLEAN_DATASET_PATH}\\n\"\n",
        "        f\"Please ensure mvtec_ad folder is in your Google Drive.\"\n",
        "    )\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE - PHASE 8: GLOBAL MODEL (MODEL-UNIFIED)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project:    {PROJECT_ROOT}\")\n",
        "print(f\"Dataset:    {CLEAN_DATASET_PATH}\")\n",
        "print(f\"Branch:     main\")\n",
        "print(f\"Models:     {MODELS_DIR}\")\n",
        "print(f\"Results:    {RESULTS_DIR}\")\n",
        "print(f\"Thresholds: {THRESHOLDS_DIR}\")\n",
        "print(f\"Viz:        {VIZ_DIR}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "94538d9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94538d9c",
        "outputId": "6da3ea64-373e-49f6-893b-8cdde010ef4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.8/851.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for freia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu --quiet\n",
        "!pip install anomalib --quiet\n",
        "!pip install umap-learn --quiet\n",
        "import umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e2c9ea8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2c9ea8a",
        "outputId": "d3a09243-0b13-4272-c00e-160fec35d058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful\n"
          ]
        }
      ],
      "source": [
        "# Standard imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dimensionality reduction\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Project imports\n",
        "from src.data.dataset import MVTecDataset\n",
        "from src.data.transforms import get_clean_transforms\n",
        "from src.models.patchcore import PatchCore\n",
        "from src.models.padim_wrapper import PadimWrapper\n",
        "from src.metrics.threshold_selection import calibrate_threshold\n",
        "from src.metrics.image_metrics import compute_auroc, compute_auprc, compute_f1_at_threshold, compute_classification_metrics\n",
        "from src.metrics.pixel_metrics import compute_pixel_auroc, compute_pro\n",
        "from src.utils.reproducibility import set_seed\n",
        "from src.utils.paths import ProjectPaths\n",
        "\n",
        "# Set matplotlib style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0c933060",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c933060",
        "outputId": "b90ab1fa-237f-40dc-9412-4b0cbc78d656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 42 for reproducibility\n",
            "Device: cpu\n",
            "Classes: ['hazelnut', 'carpet', 'zipper']\n",
            "Seed: 42 (FIXED for reproducibility)\n"
          ]
        }
      ],
      "source": [
        "# CRITICAL: Set seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Configuration\n",
        "CLASSES = ['hazelnut', 'carpet', 'zipper']\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "paths = ProjectPaths(PROJECT_ROOT)\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Classes: {CLASSES}\")\n",
        "print(f\"Seed: 42 (FIXED for reproducibility)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18792528",
      "metadata": {
        "id": "18792528"
      },
      "source": [
        "## 1. Data Preparation: Merge Training Sets from All Classes\n",
        "\n",
        "**CRITICAL**: We create a **SINGLE** global training set by merging Train-clean from all 3 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0fb7edda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fb7edda",
        "outputId": "88317628-e680-4145-c934-0ddbefd7822f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded splits for classes: ['splits', 'metadata']\n"
          ]
        }
      ],
      "source": [
        "# Load clean splits\n",
        "splits_path = paths.DATA_PROCESSED / 'clean_splits.json'\n",
        "with open(splits_path, 'r') as f:\n",
        "    splits = json.load(f)\n",
        "\n",
        "print(f\"Loaded splits for classes: {list(splits.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4f62c7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4f62c7c",
        "outputId": "5235239e-4a25-4d4c-8a18-77f8be3c7914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  hazelnut  :  312 normal images\n",
            "  carpet    :  224 normal images\n",
            "  zipper    :  192 normal images\n",
            "\n",
            "Global Train Set: 728 total images\n",
            "   Distribution: Hazelnut=312, Carpet=224, Zipper=192\n"
          ]
        }
      ],
      "source": [
        "# Merge all train_clean images into a single global dataset\n",
        "global_train_images = []\n",
        "global_train_masks = []\n",
        "global_train_labels = []\n",
        "global_train_class_ids = []  # Track which class each image belongs to\n",
        "\n",
        "for class_idx, class_name in enumerate(CLASSES):\n",
        "    class_splits = splits['splits'][class_name]['train']\n",
        "\n",
        "    # Train only contains normal images\n",
        "    n_samples = len(class_splits['images'])\n",
        "\n",
        "    global_train_images.extend(class_splits['images'])\n",
        "    global_train_masks.extend([None] * n_samples)  # Only normals\n",
        "    global_train_labels.extend([0] * n_samples)  # Label 0 = normal\n",
        "    global_train_class_ids.extend([class_idx] * n_samples)\n",
        "\n",
        "    print(f\"  {class_name:10s}: {n_samples:4d} normal images\")\n",
        "\n",
        "print(f\"\\nGlobal Train Set: {len(global_train_images)} total images\")\n",
        "print(f\"   Distribution: Hazelnut={global_train_class_ids.count(0)}, \"\n",
        "      f\"Carpet={global_train_class_ids.count(1)}, Zipper={global_train_class_ids.count(2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1fa729e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fa729e0",
        "outputId": "6988190d-24b0-4a22-c18f-fb7d7ee05c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Train DataLoader: 23 batches\n"
          ]
        }
      ],
      "source": [
        "# Custom collate function to handle None masks (MUST BE DEFINED FIRST!)\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function that handles None masks.\"\"\"\n",
        "    images = torch.stack([item[0] for item in batch])\n",
        "    masks = [item[1] for item in batch]  # Keep as list (may contain None)\n",
        "    labels = torch.tensor([item[2] for item in batch])\n",
        "    paths = [item[3] for item in batch]\n",
        "    return images, masks, labels, paths\n",
        "\n",
        "# Create global training dataset\n",
        "transform_clean = get_clean_transforms()\n",
        "\n",
        "global_train_dataset = MVTecDataset(\n",
        "    images=global_train_images,\n",
        "    masks=global_train_masks,\n",
        "    labels=global_train_labels,\n",
        "    transform=transform_clean,\n",
        "    phase='train'\n",
        ")\n",
        "\n",
        "global_train_loader = DataLoader(\n",
        "    global_train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=custom_collate_fn  # <-- QUESTA È LA RIGA CHIAVE!\n",
        ")\n",
        "\n",
        "print(f\"Global Train DataLoader: {len(global_train_loader)} batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c66f1966",
      "metadata": {
        "id": "c66f1966"
      },
      "source": [
        "## 2. Train Single PatchCore Global Model\n",
        "\n",
        "**KEY POINT**: Training ONE model on the merged dataset (not 3 separate models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b4c0b7ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4c0b7ba",
        "outputId": "8efbd268-aa8b-46ca-f5fe-dd30e36ca362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GLOBAL PATCHCORE MODEL\n",
            "======================================================================\n",
            "\n",
            "[FOUND] Pre-trained model exists. Loading...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 97.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using FAISS for fast k-NN search (memory bank: 28537 samples, 1536 dims)\n",
            "[OK] Model loaded from: /content/Detection-of-Anomalies-with-Localization/outputs/models/patchcore_global_clean.npy\n",
            "   Memory bank size: 28,537 patches\n",
            "   Feature dimensions: 1536\n",
            "\n",
            "======================================================================\n",
            "[READY] PatchCore Global model ready for inference\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN OR LOAD GLOBAL PATCHCORE MODEL\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"GLOBAL PATCHCORE MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if model already exists\n",
        "model_path = MODELS_DIR / 'patchcore_global_clean.npy'\n",
        "config_path = MODELS_DIR / 'patchcore_global_clean_config.pth'\n",
        "\n",
        "if model_path.exists() and config_path.exists():\n",
        "    # ========== LOAD EXISTING MODEL ==========\n",
        "    print(\"\\n[FOUND] Pre-trained model exists. Loading...\")\n",
        "\n",
        "    patchcore_global = PatchCore(\n",
        "        backbone_layers=['layer2', 'layer3'],\n",
        "        patch_size=3,\n",
        "        coreset_ratio=0.05,\n",
        "        n_neighbors=9,\n",
        "        device=str(device)\n",
        "    )\n",
        "\n",
        "    patchcore_global.load(MODELS_DIR, class_name='global', domain='clean')\n",
        "\n",
        "    print(f\"[OK] Model loaded from: {model_path}\")\n",
        "    print(f\"   Memory bank size: {patchcore_global.memory_bank.features.shape[0]:,} patches\")\n",
        "    print(f\"   Feature dimensions: {patchcore_global.memory_bank.features.shape[1]}\")\n",
        "\n",
        "else:\n",
        "    # ========== TRAIN NEW MODEL ==========\n",
        "    print(\"\\n[NOT FOUND] Training new model...\")\n",
        "\n",
        "    patchcore_global = PatchCore(\n",
        "        backbone_layers=['layer2', 'layer3'],\n",
        "        patch_size=3,\n",
        "        coreset_ratio=0.05,  # 5% as per PHASE 3.5\n",
        "        n_neighbors=9,\n",
        "        device=str(device)\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    patchcore_global.fit(global_train_loader, apply_coreset=True)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n[OK] PatchCore Global trained in {training_time:.2f}s\")\n",
        "    print(f\"   Memory bank size: {patchcore_global.memory_bank.features.shape[0]:,} patches\")\n",
        "\n",
        "    # Save model\n",
        "    patchcore_global.save(MODELS_DIR, class_name='global', domain='clean')\n",
        "    print(f\"   Model saved to: {model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[READY] PatchCore Global model ready for inference\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8ee2bf",
      "metadata": {
        "id": "0d8ee2bf"
      },
      "source": [
        "## 3. Train Single PaDiM Global Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a9ff8b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ff8b67",
        "outputId": "6f2613fa-8a81-42bd-ba09-baf62ab7b8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GLOBAL PADIM MODEL\n",
            "======================================================================\n",
            "\n",
            "[NOT FOUND] Training new model...\n",
            "\n",
            "[CONFIG] PaDiM Global Settings:\n",
            "   Backbone: resnet50 (same as per-class models)\n",
            "   Layers: ['layer1', 'layer2', 'layer3']\n",
            "   N features: 100\n",
            "   Device: cpu\n",
            "\n",
            "[TRAIN] Training on 728 global samples...\n",
            "\n",
            "============================================================\n",
            "Training PaDiM on 728 normal samples\n",
            "Backbone: resnet50 | Layers: ['layer1', 'layer2', 'layer3']\n",
            "N features: 100\n",
            "Device: cpu\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 23/23 [05:03<00:00, 13.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fitting Gaussian distributions...\n",
            "  Total samples: 728\n",
            "  Memory bank size: 23 batches\n",
            "\n",
            "============================================================\n",
            "[OK] Training completed in 317.66s\n",
            "  Gaussian mean shape: torch.Size([100, 3136])\n",
            "  Inv covariance shape: torch.Size([3136, 100, 100])\n",
            "  Memory usage: 120.83 MB\n",
            "============================================================\n",
            "\n",
            "\n",
            "[OK] PaDiM Global trained in 317.66s\n",
            "[OK] Model saved: padim_global_clean.pt\n",
            "  Stats saved: padim_global_clean.json\n",
            "[OK] Model saved: /content/Detection-of-Anomalies-with-Localization/outputs/models/padim_global_clean.pt\n",
            "\n",
            "======================================================================\n",
            "[READY] PaDiM Global model ready for inference\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN OR LOAD GLOBAL PADIM MODEL\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"GLOBAL PADIM MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if model already exists\n",
        "model_path = MODELS_DIR / 'padim_global_clean.pt'\n",
        "\n",
        "if model_path.exists():\n",
        "    # ========== LOAD EXISTING MODEL ==========\n",
        "    print(\"\\n[FOUND] Pre-trained model exists. Loading...\")\n",
        "\n",
        "    padim_global = PadimWrapper(\n",
        "        backbone='resnet50',               # Same as notebook 05\n",
        "        layers=['layer1', 'layer2', 'layer3'],\n",
        "        n_features=100,\n",
        "        image_size=224,\n",
        "        device=str(device)\n",
        "    )\n",
        "\n",
        "    padim_global.load(model_path)\n",
        "\n",
        "    print(f\"[OK] Model loaded from: {model_path}\")\n",
        "    if hasattr(padim_global, 'training_stats'):\n",
        "        print(f\"   Training samples: {padim_global.training_stats.get('num_samples', 'N/A')}\")\n",
        "\n",
        "else:\n",
        "    # ========== TRAIN NEW MODEL ==========\n",
        "    print(\"\\n[NOT FOUND] Training new model...\")\n",
        "\n",
        "    # Same configuration as notebook 05 (per-class training)\n",
        "    padim_global = PadimWrapper(\n",
        "        backbone='resnet50',               # NOT wide_resnet50_2!\n",
        "        layers=['layer1', 'layer2', 'layer3'],\n",
        "        n_features=100,\n",
        "        image_size=224,\n",
        "        device=str(device)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n[CONFIG] PaDiM Global Settings:\")\n",
        "    print(f\"   Backbone: resnet50 (same as per-class models)\")\n",
        "    print(f\"   Layers: ['layer1', 'layer2', 'layer3']\")\n",
        "    print(f\"   N features: 100\")\n",
        "    print(f\"   Device: {device}\")\n",
        "\n",
        "    # Train on GLOBAL merged dataset\n",
        "    print(f\"\\n[TRAIN] Training on {len(global_train_dataset)} global samples...\")\n",
        "    start_time = time.time()\n",
        "    padim_global.fit(global_train_loader, verbose=True)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n[OK] PaDiM Global trained in {training_time:.2f}s\")\n",
        "\n",
        "    # Save model\n",
        "    padim_global.save(model_path, include_stats=True)\n",
        "    print(f\"[OK] Model saved: {model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[READY] PaDiM Global model ready for inference\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2571c097",
      "metadata": {
        "id": "2571c097"
      },
      "source": [
        "## 4. Per-Class Threshold Calibration (Using Global Models)\n",
        "\n",
        "**CRITICAL**: Although we have ONE model, we calibrate **SEPARATE thresholds** for each class on their validation sets.\n",
        "\n",
        "This allows fair comparison: each class gets an optimal threshold despite using a shared model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "31091db2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31091db2",
        "outputId": "a2dcf96a-da1f-4289-a144-3b1a2c890902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PER-CLASS THRESHOLD CALIBRATION (GLOBAL MODELS)\n",
            "======================================================================\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Calibrating thresholds for: HAZELNUT\n",
            "──────────────────────────────────────────────────\n",
            "   Validation samples: 100\n",
            "   Normal: 79, Anomalous: 21\n",
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬───────────────┬──────────┬──────────┐\n",
            "   │ Method      │ Threshold     │ Val F1   │ Val AUROC│\n",
            "   ├─────────────┼───────────────┼──────────┼──────────┤\n",
            "   │ PatchCore   │      400.1891 │   1.0000 │   1.0000 │\n",
            "   │ PaDiM       │       41.1537 │   0.6829 │   0.9156 │\n",
            "   └─────────────┴───────────────┴──────────┴──────────┘\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Calibrating thresholds for: CARPET\n",
            "──────────────────────────────────────────────────\n",
            "   Validation samples: 82\n",
            "   Normal: 56, Anomalous: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬───────────────┬──────────┬──────────┐\n",
            "   │ Method      │ Threshold     │ Val F1   │ Val AUROC│\n",
            "   ├─────────────┼───────────────┼──────────┼──────────┤\n",
            "   │ PatchCore   │      186.9182 │   1.0000 │   1.0000 │\n",
            "   │ PaDiM       │       22.5797 │   0.8621 │   0.9505 │\n",
            "   └─────────────┴───────────────┴──────────┴──────────┘\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Calibrating thresholds for: ZIPPER\n",
            "──────────────────────────────────────────────────\n",
            "   Validation samples: 83\n",
            "   Normal: 48, Anomalous: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬───────────────┬──────────┬──────────┐\n",
            "   │ Method      │ Threshold     │ Val F1   │ Val AUROC│\n",
            "   ├─────────────┼───────────────┼──────────┼──────────┤\n",
            "   │ PatchCore   │      151.6652 │   0.9859 │   0.9994 │\n",
            "   │ PaDiM       │       18.1095 │   0.7179 │   0.8298 │\n",
            "   └─────────────┴───────────────┴──────────┴──────────┘\n",
            "\n",
            "======================================================================\n",
            "[OK] Thresholds saved to: /content/Detection-of-Anomalies-with-Localization/outputs/thresholds/global_thresholds.json\n",
            "======================================================================\n",
            "\n",
            "THRESHOLD CALIBRATION SUMMARY (Global Models)\n",
            "======================================================================\n",
            "Class        │ PatchCore Thresh │   PaDiM Thresh\n",
            "─────────────┼──────────────────┼───────────────\n",
            "hazelnut     │         400.1891 │        41.1537\n",
            "carpet       │         186.9182 │        22.5797\n",
            "zipper       │         151.6652 │        18.1095\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 8.2: PER-CLASS THRESHOLD CALIBRATION (GLOBAL MODELS)\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PER-CLASS THRESHOLD CALIBRATION (GLOBAL MODELS)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "thresholds_global = {\n",
        "    'patchcore': {},\n",
        "    'padim': {}\n",
        "}\n",
        "\n",
        "# Store validation metrics for analysis\n",
        "val_metrics_global = {\n",
        "    'patchcore': {},\n",
        "    'padim': {}\n",
        "}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'─'*50}\")\n",
        "    print(f\"Calibrating thresholds for: {class_name.upper()}\")\n",
        "    print(f\"{'─'*50}\")\n",
        "\n",
        "    # Load validation split for this class\n",
        "    val_split = splits['splits'][class_name]['val']\n",
        "\n",
        "    val_dataset = MVTecDataset(\n",
        "        images=val_split['images'],\n",
        "        masks=val_split['masks'],\n",
        "        labels=val_split['labels'],\n",
        "        transform=transform_clean,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    # CRITICAL: Use custom_collate_fn to handle None masks!\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        collate_fn=custom_collate_fn  # <-- FIX FOR NONE MASKS\n",
        "    )\n",
        "\n",
        "    print(f\"   Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"   Normal: {val_split['labels'].count(0)}, Anomalous: {val_split['labels'].count(1)}\")\n",
        "\n",
        "    # Collect all images from validation set\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    for batch in val_loader:\n",
        "        images, masks, labels, paths = batch\n",
        "        all_images.append(images)\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "    all_images = torch.cat(all_images, dim=0).to(device)\n",
        "    val_labels = np.array(all_labels)\n",
        "\n",
        "    # Get predictions from GLOBAL models\n",
        "    print(f\"   Running PatchCore inference...\")\n",
        "    patchcore_scores, _ = patchcore_global.predict(all_images, return_heatmaps=False)\n",
        "\n",
        "    print(f\"   Running PaDiM inference...\")\n",
        "    padim_scores, _ = padim_global.predict(all_images, return_heatmaps=False)\n",
        "\n",
        "    # Calibrate thresholds to maximize F1\n",
        "    threshold_pc = calibrate_threshold(patchcore_scores, val_labels)\n",
        "    threshold_pd = calibrate_threshold(padim_scores, val_labels)\n",
        "\n",
        "    thresholds_global['patchcore'][class_name] = float(threshold_pc)\n",
        "    thresholds_global['padim'][class_name] = float(threshold_pd)\n",
        "\n",
        "    # Compute metrics at calibrated thresholds\n",
        "    f1_pc = compute_f1_at_threshold(val_labels, patchcore_scores, threshold_pc)\n",
        "    f1_pd = compute_f1_at_threshold(val_labels, padim_scores, threshold_pd)\n",
        "\n",
        "    auroc_pc = compute_auroc(val_labels, patchcore_scores)\n",
        "    auroc_pd = compute_auroc(val_labels, padim_scores)\n",
        "\n",
        "    # Store metrics\n",
        "    val_metrics_global['patchcore'][class_name] = {\n",
        "        'threshold': float(threshold_pc),\n",
        "        'val_f1': float(f1_pc),\n",
        "        'val_auroc': float(auroc_pc)\n",
        "    }\n",
        "    val_metrics_global['padim'][class_name] = {\n",
        "        'threshold': float(threshold_pd),\n",
        "        'val_f1': float(f1_pd),\n",
        "        'val_auroc': float(auroc_pd)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n   ┌─────────────┬───────────────┬──────────┬──────────┐\")\n",
        "    print(f\"   │ Method      │ Threshold     │ Val F1   │ Val AUROC│\")\n",
        "    print(f\"   ├─────────────┼───────────────┼──────────┼──────────┤\")\n",
        "    print(f\"   │ PatchCore   │ {threshold_pc:13.4f} │ {f1_pc:8.4f} │ {auroc_pc:8.4f} │\")\n",
        "    print(f\"   │ PaDiM       │ {threshold_pd:13.4f} │ {f1_pd:8.4f} │ {auroc_pd:8.4f} │\")\n",
        "    print(f\"   └─────────────┴───────────────┴──────────┴──────────┘\")\n",
        "\n",
        "# Save thresholds\n",
        "thresholds_path = THRESHOLDS_DIR / 'global_thresholds.json'\n",
        "with open(thresholds_path, 'w') as f:\n",
        "    json.dump({\n",
        "        'thresholds': thresholds_global,\n",
        "        'validation_metrics': val_metrics_global,\n",
        "        'setting': 'model-unified',\n",
        "        'note': 'Per-class thresholds calibrated on class validation sets using global models'\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"[OK] Thresholds saved to: {thresholds_path}\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Summary table\n",
        "print(\"\\nTHRESHOLD CALIBRATION SUMMARY (Global Models)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Class':<12} │ {'PatchCore Thresh':>16} │ {'PaDiM Thresh':>14}\")\n",
        "print(\"─\"*12 + \"─┼─\" + \"─\"*16 + \"─┼─\" + \"─\"*14)\n",
        "for class_name in CLASSES:\n",
        "    pc_t = thresholds_global['patchcore'][class_name]\n",
        "    pd_t = thresholds_global['padim'][class_name]\n",
        "    print(f\"{class_name:<12} │ {pc_t:>16.4f} │ {pd_t:>14.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b7358f2",
      "metadata": {
        "id": "0b7358f2"
      },
      "source": [
        "## 5. Evaluate Global Models on Test-Clean (Per-Class)\n",
        "\n",
        "Test the global models on each class separately using per-class thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "54e7c323",
      "metadata": {
        "id": "54e7c323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3ef4e6-41fe-4569-b21d-9143479a1e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING GLOBAL MODELS ON TEST-CLEAN\n",
            "======================================================================\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Evaluating: HAZELNUT\n",
            "──────────────────────────────────────────────────\n",
            "   Test samples: 89\n",
            "   Normal: 40, Anomalous: 49\n",
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬──────────┬──────────┬──────────┬────────────┐\n",
            "   │ Method      │ AUROC    │ F1       │ Pix AUROC│ PRO        │\n",
            "   ├─────────────┼──────────┼──────────┼──────────┼────────────┤\n",
            "   │ PatchCore   │   1.0000 │   1.0000 │   0.9793 │     0.8380 │\n",
            "   │ PaDiM       │   0.8413 │   0.7473 │   0.9568 │     0.8155 │\n",
            "   └─────────────┴──────────┴──────────┴──────────┴────────────┘\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Evaluating: CARPET\n",
            "──────────────────────────────────────────────────\n",
            "   Test samples: 91\n",
            "   Normal: 28, Anomalous: 63\n",
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬──────────┬──────────┬──────────┬────────────┐\n",
            "   │ Method      │ AUROC    │ F1       │ Pix AUROC│ PRO        │\n",
            "   ├─────────────┼──────────┼──────────┼──────────┼────────────┤\n",
            "   │ PatchCore   │   0.9677 │   0.9508 │   0.9823 │     0.7795 │\n",
            "   │ PaDiM       │   0.9223 │   0.8739 │   0.9598 │     0.5473 │\n",
            "   └─────────────┴──────────┴──────────┴──────────┴────────────┘\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "Evaluating: ZIPPER\n",
            "──────────────────────────────────────────────────\n",
            "   Test samples: 116\n",
            "   Normal: 32, Anomalous: 84\n",
            "   Running PatchCore inference...\n",
            "   Running PaDiM inference...\n",
            "\n",
            "   ┌─────────────┬──────────┬──────────┬──────────┬────────────┐\n",
            "   │ Method      │ AUROC    │ F1       │ Pix AUROC│ PRO        │\n",
            "   ├─────────────┼──────────┼──────────┼──────────┼────────────┤\n",
            "   │ PatchCore   │   0.9844 │   0.9595 │   0.9805 │     0.7857 │\n",
            "   │ PaDiM       │   0.8683 │   0.9274 │   0.8852 │     0.6410 │\n",
            "   └─────────────┴──────────┴──────────┴──────────┴────────────┘\n",
            "\n",
            "======================================================================\n",
            "[OK] Global model evaluation complete!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 8.3: EVALUATE GLOBAL MODELS ON TEST-CLEAN (PER-CLASS)\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUATING GLOBAL MODELS ON TEST-CLEAN\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results_global = {\n",
        "    'patchcore': {},\n",
        "    'padim': {}\n",
        "}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'─'*50}\")\n",
        "    print(f\"Evaluating: {class_name.upper()}\")\n",
        "    print(f\"{'─'*50}\")\n",
        "\n",
        "    # Load test split\n",
        "    test_split = splits['splits'][class_name]['test']\n",
        "\n",
        "    test_dataset = MVTecDataset(\n",
        "        images=test_split['images'],\n",
        "        masks=test_split['masks'],\n",
        "        labels=test_split['labels'],\n",
        "        transform=transform_clean,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    # CRITICAL: Use custom_collate_fn to handle None masks!\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=custom_collate_fn  # <-- FIX!\n",
        "    )\n",
        "\n",
        "    print(f\"   Test samples: {len(test_dataset)}\")\n",
        "    print(f\"   Normal: {test_split['labels'].count(0)}, Anomalous: {test_split['labels'].count(1)}\")\n",
        "\n",
        "    # Collect all test data\n",
        "    all_images = []\n",
        "    all_masks = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in test_loader:\n",
        "        images, masks, labels, paths = batch\n",
        "        all_images.append(images)\n",
        "        all_masks.extend(masks)  # List of masks (some may be None)\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "    test_images = torch.cat(all_images, dim=0).to(device)\n",
        "    test_labels = np.array(all_labels)\n",
        "\n",
        "    # PatchCore predictions\n",
        "    print(f\"   Running PatchCore inference...\")\n",
        "    pc_scores, pc_heatmaps = patchcore_global.predict(test_images, return_heatmaps=True)\n",
        "    pc_predictions = (pc_scores >= thresholds_global['patchcore'][class_name]).astype(int)\n",
        "\n",
        "    # PaDiM predictions\n",
        "    print(f\"   Running PaDiM inference...\")\n",
        "    pd_scores, pd_heatmaps = padim_global.predict(test_images, return_heatmaps=True)\n",
        "    pd_predictions = (pd_scores >= thresholds_global['padim'][class_name]).astype(int)\n",
        "\n",
        "    # Compute image-level metrics\n",
        "    pc_auroc = compute_auroc(test_labels, pc_scores)\n",
        "    pc_auprc = compute_auprc(test_labels, pc_scores)\n",
        "    pc_metrics = compute_classification_metrics(test_labels, pc_predictions)\n",
        "\n",
        "    pd_auroc = compute_auroc(test_labels, pd_scores)\n",
        "    pd_auprc = compute_auprc(test_labels, pd_scores)\n",
        "    pd_metrics = compute_classification_metrics(test_labels, pd_predictions)\n",
        "\n",
        "    # Compute pixel-level metrics (for anomalous images with masks)\n",
        "    anomaly_indices = np.where(test_labels == 1)[0]\n",
        "    pc_pixel_auroc = pc_pro = pd_pixel_auroc = pd_pro = None\n",
        "\n",
        "    if len(anomaly_indices) > 0:\n",
        "        # Filter masks that are not None and convert to numpy\n",
        "        valid_masks = []\n",
        "        pc_valid_heatmaps = []\n",
        "        pd_valid_heatmaps = []\n",
        "\n",
        "        for i in anomaly_indices:\n",
        "            mask = all_masks[i]\n",
        "            if mask is not None:\n",
        "                # Convert mask tensor to numpy if needed\n",
        "                if isinstance(mask, torch.Tensor):\n",
        "                    mask_np = mask.squeeze().cpu().numpy()\n",
        "                else:\n",
        "                    mask_np = np.array(mask)\n",
        "                valid_masks.append(mask_np)\n",
        "                pc_valid_heatmaps.append(pc_heatmaps[i])\n",
        "                pd_valid_heatmaps.append(pd_heatmaps[i])\n",
        "\n",
        "        if len(valid_masks) > 0:\n",
        "            pc_pixel_auroc = compute_pixel_auroc(valid_masks, pc_valid_heatmaps)\n",
        "            pc_pro = compute_pro(valid_masks, pc_valid_heatmaps)\n",
        "            pd_pixel_auroc = compute_pixel_auroc(valid_masks, pd_valid_heatmaps)\n",
        "            pd_pro = compute_pro(valid_masks, pd_valid_heatmaps)\n",
        "\n",
        "    # Store results\n",
        "    results_global['patchcore'][class_name] = {\n",
        "        'auroc': float(pc_auroc),\n",
        "        'auprc': float(pc_auprc),\n",
        "        'f1': float(pc_metrics['f1']),\n",
        "        'accuracy': float(pc_metrics['accuracy']),\n",
        "        'precision': float(pc_metrics['precision']),\n",
        "        'recall': float(pc_metrics['recall']),\n",
        "        'pixel_auroc': float(pc_pixel_auroc) if pc_pixel_auroc else None,\n",
        "        'pro': float(pc_pro) if pc_pro else None\n",
        "    }\n",
        "\n",
        "    results_global['padim'][class_name] = {\n",
        "        'auroc': float(pd_auroc),\n",
        "        'auprc': float(pd_auprc),\n",
        "        'f1': float(pd_metrics['f1']),\n",
        "        'accuracy': float(pd_metrics['accuracy']),\n",
        "        'precision': float(pd_metrics['precision']),\n",
        "        'recall': float(pd_metrics['recall']),\n",
        "        'pixel_auroc': float(pd_pixel_auroc) if pd_pixel_auroc else None,\n",
        "        'pro': float(pd_pro) if pd_pro else None\n",
        "    }\n",
        "\n",
        "    # Print results table\n",
        "    print(f\"\\n   ┌─────────────┬──────────┬──────────┬──────────┬────────────┐\")\n",
        "    print(f\"   │ Method      │ AUROC    │ F1       │ Pix AUROC│ PRO        │\")\n",
        "    print(f\"   ├─────────────┼──────────┼──────────┼──────────┼────────────┤\")\n",
        "    pc_pix = f\"{pc_pixel_auroc:.4f}\" if pc_pixel_auroc else \"N/A\"\n",
        "    pc_pro_s = f\"{pc_pro:.4f}\" if pc_pro else \"N/A\"\n",
        "    pd_pix = f\"{pd_pixel_auroc:.4f}\" if pd_pixel_auroc else \"N/A\"\n",
        "    pd_pro_s = f\"{pd_pro:.4f}\" if pd_pro else \"N/A\"\n",
        "    print(f\"   │ PatchCore   │ {pc_auroc:8.4f} │ {pc_metrics['f1']:8.4f} │ {pc_pix:>8} │ {pc_pro_s:>10} │\")\n",
        "    print(f\"   │ PaDiM       │ {pd_auroc:8.4f} │ {pd_metrics['f1']:8.4f} │ {pd_pix:>8} │ {pd_pro_s:>10} │\")\n",
        "    print(f\"   └─────────────┴──────────┴──────────┴──────────┴────────────┘\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[OK] Global model evaluation complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f569c90",
      "metadata": {
        "id": "2f569c90"
      },
      "source": [
        "## 6. Load Per-Class Models for Comparison\n",
        "\n",
        "Load the per-class trained models to compute the performance gap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cac9b3a0",
      "metadata": {
        "id": "cac9b3a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ec3240-b78a-4007-b727-9ec88b2545df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "LOADING PER-CLASS RESULTS FOR COMPARISON\n",
            "======================================================================\n",
            "[OK] Loaded per-class results from: /content/Detection-of-Anomalies-with-Localization/outputs/results/clean_results.json\n",
            "\n",
            "[INFO] Per-class results loaded for: ['hazelnut', 'carpet', 'zipper']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 6. LOAD PER-CLASS RESULTS FOR COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"LOADING PER-CLASS RESULTS FOR COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load per-class results from PHASE 5 (clean domain evaluation)\n",
        "clean_results_path = RESULTS_DIR / 'clean_results.json'\n",
        "\n",
        "if clean_results_path.exists():\n",
        "    with open(clean_results_path, 'r') as f:\n",
        "        clean_results = json.load(f)\n",
        "    print(f\"[OK] Loaded per-class results from: {clean_results_path}\")\n",
        "else:\n",
        "    print(f\"[ERROR] File not found: {clean_results_path}\")\n",
        "    print(\"   Please run notebook 06_evaluation_clean.ipynb first!\")\n",
        "    clean_results = None\n",
        "\n",
        "# Extract per-class metrics for comparison\n",
        "if clean_results:\n",
        "    perclass_results = {\n",
        "        'patchcore': {},\n",
        "        'padim': {}\n",
        "    }\n",
        "\n",
        "    for class_name in CLASSES:\n",
        "        if class_name in clean_results.get('patchcore', {}):\n",
        "            perclass_results['patchcore'][class_name] = clean_results['patchcore'][class_name]\n",
        "        if class_name in clean_results.get('padim', {}):\n",
        "            perclass_results['padim'][class_name] = clean_results['padim'][class_name]\n",
        "\n",
        "    print(f\"\\n[INFO] Per-class results loaded for: {list(perclass_results['patchcore'].keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda86126",
      "metadata": {
        "id": "dda86126"
      },
      "source": [
        "## 7. Performance Gap Analysis: Global vs Per-Class\n",
        "\n",
        "**Key Question**: How much performance do we lose by using a single global model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6221209b",
      "metadata": {
        "id": "6221209b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24588225-d493-4627-ff08-166c57090af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PERFORMANCE GAP ANALYSIS: Per-Class vs Global Model\n",
            "======================================================================\n",
            "\n",
            "PATCHCORE:\n",
            "Class         Per-Class AUROC   Global AUROC        Gap\n",
            "--------------------------------------------------------\n",
            "hazelnut               1.0000         1.0000     0.0000\n",
            "carpet                 0.9450         0.9677    -0.0227\n",
            "zipper                 0.9888         0.9844    +0.0045\n",
            "--------------------------------------------------------\n",
            "AVERAGE                                         -0.0061\n",
            "\n",
            "PADIM:\n",
            "Class         Per-Class AUROC   Global AUROC        Gap\n",
            "--------------------------------------------------------\n",
            "hazelnut               0.9709         0.8413    +0.1296\n",
            "carpet                 0.9586         0.9223    +0.0363\n",
            "zipper                 0.8616         0.8683    -0.0067\n",
            "--------------------------------------------------------\n",
            "AVERAGE                                         +0.0531\n",
            "\n",
            "[OK] Gap analysis saved to: /content/Detection-of-Anomalies-with-Localization/outputs/results/global_vs_perclass_gap.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 7. PERFORMANCE GAP ANALYSIS: Per-Class vs Global Model\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PERFORMANCE GAP ANALYSIS: Per-Class vs Global Model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if clean_results:\n",
        "    # Calculate and display performance gap\n",
        "    gap_analysis = {\n",
        "        'patchcore': {},\n",
        "        'padim': {}\n",
        "    }\n",
        "\n",
        "    for method in ['patchcore', 'padim']:\n",
        "        print(f\"\\n{method.upper()}:\")\n",
        "        print(f\"{'Class':<12} {'Per-Class AUROC':>16} {'Global AUROC':>14} {'Gap':>10}\")\n",
        "        print(\"-\" * 56)\n",
        "\n",
        "        total_gap = 0\n",
        "        for class_name in CLASSES:\n",
        "            # Per-class uses 'image_level' structure\n",
        "            if 'image_level' in clean_results[method][class_name]:\n",
        "                auroc_per_class = clean_results[method][class_name]['image_level']['auroc']\n",
        "            else:\n",
        "                auroc_per_class = clean_results[method][class_name]['auroc']\n",
        "\n",
        "            auroc_global = results_global[method][class_name]['auroc']\n",
        "            gap = auroc_per_class - auroc_global\n",
        "            total_gap += gap\n",
        "\n",
        "            gap_analysis[method][class_name] = {\n",
        "                'per_class_auroc': auroc_per_class,\n",
        "                'global_auroc': auroc_global,\n",
        "                'gap': gap\n",
        "            }\n",
        "\n",
        "            # Color-code the gap\n",
        "            gap_str = f\"{gap:+.4f}\" if gap != 0 else \"0.0000\"\n",
        "            print(f\"{class_name:<12} {auroc_per_class:>16.4f} {auroc_global:>14.4f} {gap_str:>10}\")\n",
        "\n",
        "        avg_gap = total_gap / len(CLASSES)\n",
        "        print(\"-\" * 56)\n",
        "        print(f\"{'AVERAGE':<12} {'':<16} {'':<14} {avg_gap:>+10.4f}\")\n",
        "\n",
        "    # Save gap analysis\n",
        "    gap_analysis_path = RESULTS_DIR / 'global_vs_perclass_gap.json'\n",
        "    with open(gap_analysis_path, 'w') as f:\n",
        "        json.dump(gap_analysis, f, indent=2)\n",
        "    print(f\"\\n[OK] Gap analysis saved to: {gap_analysis_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"[SKIP] Cannot perform gap analysis - per-class results not loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "728feb35",
      "metadata": {
        "id": "728feb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "3adda229-e303-4769-feb9-04a1432c02ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Gap visualization saved to: /content/Detection-of-Anomalies-with-Localization/outputs/visualizations/global_vs_perclass_gap.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 8. VISUALIZATION: Performance Gap Charts\n",
        "# ============================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, method in enumerate(['patchcore', 'padim']):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Extract gap values from gap_analysis\n",
        "    gap_values = [gap_analysis[method][c]['gap'] for c in CLASSES]\n",
        "\n",
        "    # Color: green if per-class better (positive gap), red if global better (negative gap)\n",
        "    colors = ['forestgreen' if g > 0 else 'crimson' for g in gap_values]\n",
        "\n",
        "    # Create bar chart\n",
        "    bars = ax.bar(CLASSES, gap_values, color=colors, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, val in zip(bars, gap_values):\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{val:+.4f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 5 if height >= 0 else -15),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom' if height >= 0 else 'top',\n",
        "                    fontsize=11, fontweight='bold')\n",
        "\n",
        "    # Styling\n",
        "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
        "    ax.set_ylabel('AUROC Gap (Per-Class - Global)', fontsize=12)\n",
        "    ax.set_xlabel('Class', fontsize=12)\n",
        "    ax.set_title(f'{method.upper()}\\nPositive = Per-Class Better, Negative = Global Better', fontsize=13)\n",
        "    ax.set_ylim(min(gap_values) - 0.05, max(gap_values) + 0.05)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add average line\n",
        "    avg_gap = sum(gap_values) / len(gap_values)\n",
        "    ax.axhline(y=avg_gap, color='blue', linestyle='--', linewidth=1.5, label=f'Average: {avg_gap:+.4f}')\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "plt.suptitle('Performance Gap Analysis: Per-Class vs Global Model', fontsize=15, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "VIS_DIR = PROJECT_ROOT / 'outputs' / 'visualizations'\n",
        "VIS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "gap_fig_path = VIS_DIR / 'global_vs_perclass_gap.png'\n",
        "plt.savefig(gap_fig_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "print(f\"[OK] Gap visualization saved to: {gap_fig_path}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8391ec3f",
      "metadata": {
        "id": "8391ec3f"
      },
      "source": [
        "## 8. Identical Shortcut Problem Analysis\n",
        "\n",
        "**Context**: In model-unified anomaly detection [CADA, Guo et al. 2024], a single model\n",
        "is trained on multiple classes but evaluated with per-class thresholds. This differs from\n",
        "absolute-unified settings where class information is unavailable at inference.\n",
        "\n",
        "**The \"Identical Shortcut\" Problem** [UniAD, You et al. 2022]: When training a unified model\n",
        "on heterogeneous classes, normal patterns from one class may appear anomalous for another.\n",
        "\n",
        "**Hypothesis**: Normal images from Class A may exceed the anomaly threshold calibrated for Class B,\n",
        "even with per-class thresholds, due to shared feature representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "db705e4f",
      "metadata": {
        "id": "db705e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "9da2f7f4-8ade-4151-b16d-c175824a95ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "IDENTICAL SHORTCUT PROBLEM ANALYSIS\n",
            "======================================================================\n",
            "Testing: Do normals from Class A trigger anomaly threshold for Class B?\n",
            "\n",
            "\n",
            "Target Class: HAZELNUT (threshold=400.1891)\n",
            "--------------------------------------------------\n",
            "   carpet normals → hazelnut threshold: FP=0/224 (0.0%) LOW\n",
            "   zipper normals → hazelnut threshold: FP=0/192 (0.0%) LOW\n",
            "\n",
            "Target Class: CARPET (threshold=186.9182)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2831700145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Predict with global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatchcore_global\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_images_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_heatmaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Count how many are classified as anomalies (using target class threshold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Detection-of-Anomalies-with-Localization/src/models/patchcore.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, images, return_heatmaps)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Extract patch features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mpatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_patch_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Compute anomaly scores for each patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Detection-of-Anomalies-with-Localization/src/models/backbones.py\u001b[0m in \u001b[0;36mget_patch_features\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mspatial_dims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSpatial\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, C, H, W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Detection-of-Anomalies-with-Localization/src/models/backbones.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Forward pass through backbone (populates feature_maps via hooks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0maggregated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1827\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1830\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 9. IDENTICAL SHORTCUT PROBLEM ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"IDENTICAL SHORTCUT PROBLEM ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(\"Testing: Do normals from Class A trigger anomaly threshold for Class B?\\n\")\n",
        "\n",
        "# For each class, test if normal images from OTHER classes\n",
        "# are incorrectly classified as anomalies using that class's threshold\n",
        "\n",
        "shortcut_analysis = {}\n",
        "\n",
        "for target_class in CLASSES:\n",
        "    threshold = thresholds_global['patchcore'][target_class]\n",
        "    print(f\"\\nTarget Class: {target_class.upper()} (threshold={threshold:.4f})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    shortcut_analysis[target_class] = {}\n",
        "\n",
        "    for source_class in CLASSES:\n",
        "        if source_class == target_class:\n",
        "            continue\n",
        "\n",
        "        # Load NORMAL images from source class (train split)\n",
        "        train_split = splits['splits'][source_class]['train']\n",
        "\n",
        "        # Filter only normal images\n",
        "        normal_indices = [i for i, label in enumerate(train_split['labels']) if label == 0]\n",
        "        normal_images = [train_split['images'][i] for i in normal_indices]\n",
        "        normal_masks = [train_split['masks'][i] for i in normal_indices]\n",
        "        normal_labels = [train_split['labels'][i] for i in normal_indices]\n",
        "\n",
        "        normal_dataset = MVTecDataset(\n",
        "            images=normal_images,\n",
        "            masks=normal_masks,\n",
        "            labels=normal_labels,\n",
        "            transform=transform_clean,\n",
        "            phase='train'\n",
        "        )\n",
        "\n",
        "        # Use custom_collate_fn!\n",
        "        normal_loader = DataLoader(\n",
        "            normal_dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            collate_fn=custom_collate_fn  # <-- FIX!\n",
        "        )\n",
        "\n",
        "        # Collect images\n",
        "        all_images = []\n",
        "        for batch in normal_loader:\n",
        "            images, masks, labels, paths = batch\n",
        "            all_images.append(images)\n",
        "\n",
        "        normal_images_tensor = torch.cat(all_images, dim=0).to(device)\n",
        "\n",
        "        # Predict with global model\n",
        "        scores, _ = patchcore_global.predict(normal_images_tensor, return_heatmaps=False)\n",
        "\n",
        "        # Count how many are classified as anomalies (using target class threshold)\n",
        "        false_positives = (scores >= threshold).sum()\n",
        "        fp_rate = false_positives / len(scores)\n",
        "\n",
        "        shortcut_analysis[target_class][source_class] = {\n",
        "            'n_samples': len(scores),\n",
        "            'false_positives': int(false_positives),\n",
        "            'fp_rate': float(fp_rate),\n",
        "            'mean_score': float(scores.mean()),\n",
        "            'max_score': float(scores.max())\n",
        "        }\n",
        "\n",
        "        status = \"HIGH\" if fp_rate > 0.1 else \"LOW\"\n",
        "        print(f\"   {source_class} normals → {target_class} threshold: \"\n",
        "              f\"FP={false_positives}/{len(scores)} ({fp_rate*100:.1f}%) {status}\")\n",
        "\n",
        "# Save analysis\n",
        "shortcut_path = RESULTS_DIR / 'identical_shortcut_analysis.json'\n",
        "with open(shortcut_path, 'w') as f:\n",
        "    json.dump(shortcut_analysis, f, indent=2)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"[OK] Identical Shortcut Analysis saved to: {shortcut_path}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43443568",
      "metadata": {
        "id": "43443568"
      },
      "outputs": [],
      "source": [
        "# Visualization: Confusion heatmap\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix_cross * 100,  # Convert to percentage\n",
        "    annot=True,\n",
        "    fmt='.1f',\n",
        "    cmap='RdYlGn_r',  # Red = high confusion, Green = low confusion\n",
        "    xticklabels=CLASSES,\n",
        "    yticklabels=CLASSES,\n",
        "    cbar_kws={'label': 'False Positive Rate (%)'},\n",
        "    vmin=0,\n",
        "    vmax=100,\n",
        "    linewidths=1,\n",
        "    linecolor='gray',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "ax.set_title('Identical Shortcut Problem\\n'\n",
        "             'Cross-Class Confusion Matrix (PatchCore Global Model)',\n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Source Class (Normal Images)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Target Class (Threshold)', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Add explanation text\n",
        "fig.text(0.5, 0.02,\n",
        "         'Higher values (red) indicate normals from Source Class are confused as anomalies for Target Class',\n",
        "         ha='center', fontsize=10, style='italic')\n",
        "\n",
        "plt.tight_layout()\n",
        "confusion_plot_path = aths.VISUALIZATIONS / 'identical_shortcut_confusion.png'\n",
        "plt.savefig(confusion_plot_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Confusion heatmap saved to: {confusion_plot_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c95bf8",
      "metadata": {
        "id": "59c95bf8"
      },
      "source": [
        "## 9. Feature Space Visualization: T-SNE\n",
        "\n",
        "Visualize how the global model represents normal and anomalous samples from all classes in feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3619c1c",
      "metadata": {
        "id": "f3619c1c"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"FEATURE SPACE VISUALIZATION (T-SNE)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Collect features from all classes\n",
        "all_features = []\n",
        "all_labels = []\n",
        "all_class_names = []\n",
        "\n",
        "n_samples_per_class = 30  # Limit for visualization\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    test_split = splits['splits'][class_name]['test']\n",
        "\n",
        "    # Sample normal and anomalous images\n",
        "    normal_indices = [i for i, lbl in enumerate(test_split['labels']) if lbl == 0][:n_samples_per_class]\n",
        "    anomaly_indices = [i for i, lbl in enumerate(test_split['labels']) if lbl == 1][:n_samples_per_class]\n",
        "\n",
        "    selected_indices = normal_indices + anomaly_indices\n",
        "    selected_images = [test_split['images'][i] for i in selected_indices]\n",
        "    selected_labels = [test_split['labels'][i] for i in selected_indices]\n",
        "\n",
        "    # Create dataset\n",
        "    sample_dataset = MVTecDataset(\n",
        "        images=selected_images,\n",
        "        masks=[None] * len(selected_images),\n",
        "        labels=selected_labels,\n",
        "        transform=transform_clean,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    sample_loader = DataLoader(sample_dataset, batch_size=len(selected_images), shuffle=False)\n",
        "    sample_images_tensor = next(iter(sample_loader))[0].to(device)\n",
        "\n",
        "    # Extract features using PatchCore backbone\n",
        "    with torch.no_grad():\n",
        "        features = patchcore_global.backbone(sample_images_tensor)  # (B, C, H, W)\n",
        "        # Global average pooling to get image-level features\n",
        "        features_pooled = features.mean(dim=[2, 3])  # (B, C)\n",
        "        features_numpy = features_pooled.cpu().numpy()\n",
        "\n",
        "    all_features.append(features_numpy)\n",
        "    all_labels.extend(selected_labels)\n",
        "    all_class_names.extend([class_name] * len(selected_images))\n",
        "\n",
        "    print(f\"   {class_name}: {len(normal_indices)} normals, {len(anomaly_indices)} anomalies\")\n",
        "\n",
        "# Concatenate all features\n",
        "all_features = np.vstack(all_features)\n",
        "print(f\"\\nCollected {all_features.shape[0]} samples with {all_features.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65d2d29",
      "metadata": {
        "id": "c65d2d29"
      },
      "outputs": [],
      "source": [
        "# Run T-SNE\n",
        "print(\"Running T-SNE (this may take a minute)...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "features_2d = tsne.fit_transform(all_features)\n",
        "print(\"T-SNE complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20343bc6",
      "metadata": {
        "id": "20343bc6"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Define colors and markers\n",
        "class_colors = {'hazelnut': 'blue', 'carpet': 'green', 'zipper': 'purple'}\n",
        "label_markers = {0: 'o', 1: 'X'}  # o = normal, X = anomaly\n",
        "label_sizes = {0: 50, 1: 100}\n",
        "\n",
        "# Plot each combination\n",
        "for class_name in CLASSES:\n",
        "    for label_type in [0, 1]:\n",
        "        mask = [(c == class_name and l == label_type)\n",
        "                for c, l in zip(all_class_names, all_labels)]\n",
        "\n",
        "        if not any(mask):\n",
        "            continue\n",
        "\n",
        "        label_str = 'Normal' if label_type == 0 else 'Anomaly'\n",
        "\n",
        "        ax.scatter(\n",
        "            features_2d[mask, 0],\n",
        "            features_2d[mask, 1],\n",
        "            c=class_colors[class_name],\n",
        "            marker=label_markers[label_type],\n",
        "            s=label_sizes[label_type],\n",
        "            alpha=0.7,\n",
        "            edgecolors='black',\n",
        "            linewidth=0.5,\n",
        "            label=f'{class_name} - {label_str}'\n",
        "        )\n",
        "\n",
        "ax.set_title('T-SNE Visualization of Feature Space\\n'\n",
        "             'Global PatchCore Model (All Classes)',\n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('T-SNE Dimension 1', fontsize=12)\n",
        "ax.set_ylabel('T-SNE Dimension 2', fontsize=12)\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, frameon=True, shadow=True)\n",
        "ax.grid(alpha=0.3, linestyle=':')\n",
        "\n",
        "plt.tight_layout()\n",
        "tsne_plot_path = aths.VISUALIZATIONS / 'tsne_global_model.png'\n",
        "plt.savefig(tsne_plot_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"T-SNE plot saved to: {tsne_plot_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d558eabf",
      "metadata": {
        "id": "d558eabf"
      },
      "source": [
        "## 10. Summary Table and Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45135eeb",
      "metadata": {
        "id": "45135eeb"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive summary table\n",
        "summary_data = []\n",
        "\n",
        "for method in ['patchcore', 'padim']:\n",
        "    for class_name in CLASSES:\n",
        "        # Per-class model\n",
        "        per_class_res = results_per_class[method][class_name]['image_level']\n",
        "\n",
        "        # Global model\n",
        "        global_res = results_global[method][class_name]\n",
        "\n",
        "        summary_data.append({\n",
        "            'Method': method.upper(),\n",
        "            'Class': class_name,\n",
        "            'Model Type': 'Per-Class',\n",
        "            'AUROC': per_class_res['auroc'],\n",
        "            'AUPRC': per_class_res['auprc'],\n",
        "            'F1': per_class_res['f1'],\n",
        "            'Accuracy': per_class_res['accuracy']\n",
        "        })\n",
        "\n",
        "        summary_data.append({\n",
        "            'Method': method.upper(),\n",
        "            'Class': class_name,\n",
        "            'Model Type': 'Global',\n",
        "            'AUROC': global_res['auroc'],\n",
        "            'AUPRC': global_res['auprc'],\n",
        "            'F1': global_res['f1'],\n",
        "            'Accuracy': global_res['accuracy']\n",
        "        })\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "\n",
        "# Display\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL SUMMARY: Per-Class vs Global Model\")\n",
        "print(\"=\"*70)\n",
        "print(df_summary.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "summary_path = paths.RESULTS / 'global_model_summary.csv'\n",
        "df_summary.to_csv(summary_path, index=False)\n",
        "print(f\"\\nSummary saved to: {summary_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5debcf",
      "metadata": {
        "id": "7c5debcf"
      },
      "outputs": [],
      "source": [
        "# Save complete results dictionary\n",
        "final_results = {\n",
        "    'global_model_results': results_global,\n",
        "    'per_class_model_results': results_per_class,\n",
        "    'performance_gaps': gaps,\n",
        "    'cross_class_confusion_matrix': confusion_matrix_cross.tolist(),\n",
        "    'thresholds_global': thresholds_global,\n",
        "    'metadata': {\n",
        "        'classes': CLASSES,\n",
        "        'global_train_size': len(global_train_images),\n",
        "        'patchcore_coreset_ratio': 0.05,\n",
        "        'seed': 42\n",
        "    }\n",
        "}\n",
        "\n",
        "results_json_path = paths.RESULTS / 'global_model_analysis.json'\n",
        "with open(results_json_path, 'w') as f:\n",
        "    json.dump(final_results, f, indent=2)\n",
        "\n",
        "print(f\"Complete results saved to: {results_json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a635234a",
      "metadata": {
        "id": "a635234a"
      },
      "source": [
        "Save results (google drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e586331",
      "metadata": {
        "id": "0e586331"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# COPY ALL RESULTS TO GOOGLE DRIVE FOR PERSISTENCE\n",
        "# ============================================================\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Create destination folder in Drive\n",
        "DRIVE_ROOT = Path('/content/drive/MyDrive/anomaly_detection_project')\n",
        "PHASE8_OUTPUTS = DRIVE_ROOT / '10_global_model_outputs'\n",
        "PHASE8_OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COPYING FILES TO GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDestination: {PHASE8_OUTPUTS}\")\n",
        "\n",
        "# List of all generated files\n",
        "generated_files = []\n",
        "\n",
        "# Models (Global models)\n",
        "print(\"\\nCopying models...\")\n",
        "model_files = [\n",
        "    MODELS_DIR / 'patchcore_global_clean.npy',\n",
        "    MODELS_DIR / 'patchcore_global_clean_config.pth',\n",
        "    MODELS_DIR / 'padim_global_clean.pt',\n",
        "    MODELS_DIR / 'padim_global_clean.json'\n",
        "]\n",
        "generated_files.extend(model_files)\n",
        "\n",
        "# Results\n",
        "print(\"Copying results...\")\n",
        "result_files = [\n",
        "    RESULTS_DIR / 'global_model_analysis.json',\n",
        "    RESULTS_DIR / 'global_model_summary.csv',\n",
        "    RESULTS_DIR / 'global_vs_per_class_comparison.csv'\n",
        "]\n",
        "generated_files.extend(result_files)\n",
        "\n",
        "# Thresholds\n",
        "print(\"Copying thresholds...\")\n",
        "threshold_files = [\n",
        "    THRESHOLDS_DIR / 'global_thresholds.json'\n",
        "]\n",
        "generated_files.extend(threshold_files)\n",
        "\n",
        "# Visualizations\n",
        "print(\"Copying visualizations...\")\n",
        "viz_files = [\n",
        "    VIZ_DIR / 'global_model_performance_gap.png',\n",
        "    VIZ_DIR / 'identical_shortcut_confusion.png',\n",
        "    VIZ_DIR / 'tsne_global_model.png'\n",
        "]\n",
        "generated_files.extend(viz_files)\n",
        "\n",
        "# Copy all files\n",
        "copied_count = 0\n",
        "missing_count = 0\n",
        "\n",
        "for src_path in generated_files:\n",
        "    if src_path.exists():\n",
        "        # Preserve directory structure\n",
        "        if 'models' in str(src_path):\n",
        "            dst_dir = PHASE8_OUTPUTS / 'models'\n",
        "        elif 'results' in str(src_path):\n",
        "            dst_dir = PHASE8_OUTPUTS / 'results'\n",
        "        elif 'thresholds' in str(src_path):\n",
        "            dst_dir = PHASE8_OUTPUTS / 'thresholds'\n",
        "        elif 'visualizations' in str(src_path):\n",
        "            dst_dir = PHASE8_OUTPUTS / 'visualizations'\n",
        "        else:\n",
        "            dst_dir = PHASE8_OUTPUTS\n",
        "\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        dst_path = dst_dir / src_path.name\n",
        "\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        print(f\"  ✓ {src_path.name}\")\n",
        "        copied_count += 1\n",
        "    else:\n",
        "        print(f\"  ✗ MISSING: {src_path.name}\")\n",
        "        missing_count += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ Copy complete: {copied_count} files copied, {missing_count} missing\")\n",
        "print(f\"✓ All results saved to: {PHASE8_OUTPUTS}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d01dc51",
      "metadata": {
        "id": "6d01dc51"
      },
      "source": [
        "// TO CHECK\n",
        "## 11. Key Findings and Interpretation\n",
        "\n",
        "### Setting Clarification:\n",
        "This experiment uses the **Model-Unified** setting [CADA, 2024; HierCore, 2025]:\n",
        "- Single model trained on all classes\n",
        "- **Per-class thresholds** at inference (class is known)\n",
        "- This is NOT \"absolute-unified\" (which would require class-agnostic thresholds)\n",
        "\n",
        "### Observations:\n",
        "1. **Performance Gap**: Model-unified approach shows degraded AUROC vs per-class models\n",
        "   - This validates CADA's observation that shared representations struggle with heterogeneous distributions\n",
        "   \n",
        "2. **Cross-Class Confusion**: The confusion matrix shows non-zero false positive rates across classes\n",
        "   - Normal textures from one class can trigger another class's threshold\n",
        "   - This is the \"identical shortcut\" phenomenon [UniAD, You et al. 2022]\n",
        "\n",
        "### Implications:\n",
        "- For industrial deployment with **single-category** quality control: **per-class models remain optimal**\n",
        "- Model-unified approaches are useful when:\n",
        "  - Storage/training efficiency is critical\n",
        "  - Class categories are related (e.g., similar textures)\n",
        "- Absolute-unified remains an open research challenge (see CADA, HierCore for solutions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87ecd0a",
      "metadata": {
        "id": "d87ecd0a"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Outputs Generated:\n",
        "1. **Models**: `patchcore_global_clean.npy`, `padim_global_clean.pt`\n",
        "2. **Thresholds**: `global_thresholds.json` (per-class thresholds for global models)\n",
        "3. **Results**: `global_model_analysis.json`, `global_model_summary.csv`\n",
        "4. **Visualizations**:\n",
        "   - `global_model_performance_gap.png` (bar chart)\n",
        "   - `identical_shortcut_confusion.png` (heatmap)\n",
        "   - `tsne_global_model.png` (feature space)\n",
        "\n",
        "- Compare with [You et al., 2022] findings on unified anomaly detection\n",
        "- Discuss implications for industrial deployment"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}