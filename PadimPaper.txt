PaDiM: A Patch Distribution Modeling
Framework for Anomaly Detection
and Localization
Thomas Defard , Aleksandr Setkov(B) , Angelique Loesch ,
and Romaric Audigier
Universit´e Paris-Saclay, CEA, List, 91120 Palaiseau, France
thomas.defard@imt-atlantique.net,
{aleksandr.setkov,angelique.loesch,romaric.audigier}@cea.fr
Abstract. We present a new framework for Patch Distribution Modeling, PaDiM, to concurrently detect and localize anomalies in images in
a one-class learning setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for patch embedding, and of multivariate
Gaussian distributions to get a probabilistic representation of the normal class. It also exploits correlations between the different semantic
levels of CNN to better localize anomalies. PaDiM outperforms current
state-of-the-art approaches for both anomaly detection and localization
on the MVTec AD and STC datasets. To match real-world visual industrial inspection, we extend the evaluation protocol to assess performance
of anomaly localization algorithms on non-aligned dataset. The stateof-the-art performance and low complexity of PaDiM make it a good
candidate for many industrial applications.
Keywords: Anomaly detection · Anomaly localization · Computer
vision
1 Introduction
Humans are able to detect heterogeneous or unexpected patterns in a set of
homogeneous natural images. This task is known as anomaly or novelty detection and has a large number of applications, among which visual industrial
inspections. However, anomalies are very rare events on manufacturing lines
and cumbersome to detect manually. Therefore, anomaly detection automation
would enable a constant quality control by avoiding reduced attention span and
facilitating human operator work. In this paper, we focus on anomaly detection
and, in particular, on anomaly localization, mainly in an industrial inspection
context. In computer vision, anomaly detection consists in giving an anomaly
score to images. Anomaly localization is a more complex task which assigns each
pixel, or each patch of pixels, an anomaly score to output an anomaly map. Thus,
anomaly localization yields more precise and interpretable results. Examples of
c Springer Nature Switzerland AG 2021
A. Del Bimbo et al. (Eds.): ICPR 2020 Workshops, LNCS 12664, pp. 475–489, 2021.
https://doi.org/10.1007/978-3-030-68799-1_35
476 T. Defard et al.
Fig. 1. Image samples from the MVTec AD [6]. Left column: normal images of Transistor, Capsule and Wood classes. Middle column: images of the same classes with
the ground truth anomalies highlighted in yellow. Right column: anomaly heatmaps
obtained by our PaDiM model. Yellow areas correspond to the detected anomalies,
whereas the blue areas indicate the normality zones. Best viewed in color. (Color figure
online)
anomaly maps produced by our method to localize anomalies in images from the
MVTec Anomaly Detection (MVTec AD) dataset [6] are displayed in Fig. 1.
Anomaly detection is a binary classification between the normal and the
anomalous classes. However, it is not possible to train a model with full supervision for this task because we frequently lack anomalous examples, and, what is
more, anomalies can have unexpected patterns. Hence, anomaly detection models are often estimated in a one-class learning setting, i.e., when the training
dataset contains only images from the normal class and anomalous examples are
not available during the training. At test time, examples that differ from the
normal training dataset are classified as anomalous.
Recently, several methods have been proposed to combine anomaly localization and detection tasks in a one-class learning setting [7,9,30,31]. However,
either they require deep neural network training [5,30] which might be cumbersome, or they use a K-nearest-neighbor (K-NN) algorithm [10] on the entire
training dataset at test time [9,31]. The linear complexity of the KNN algorithm
increases the time and space complexity as the size of the training dataset grows.
These two scalability issues may hinder the deployment of anomaly localization
algorithms in industrial context.
PaDiM 477
Fig. 2. For each image patch corresponding to position (i, j) in the largest CNN feature
map, PaDiM learns the Gaussian parameters (μij , Σij ) from the set of N training
embedding vectors Xij = {xk
ij , k ∈ [[1, N]]}, computed from N different training images
and three different pretrained CNN layers. (Color figure online)
To mitigate the aforementioned issues, we propose a new anomaly detection
and localization approach, named PaDiM for Patch Distribution Modeling. It
makes use of a pretrained convolutional neural network (CNN) for embedding
extraction and has the two following properties:
– Each patch position is described by a multivariate Gaussian distribution;
– PaDiM takes into account the correlations between different semantic levels
of a pretrained CNN.
With this new and efficient approach, PaDiM outperforms the existing stateof-the-art methods for anomaly localization and detection on the MVTec AD [6]
and the ShanghaiTech Campus (STC) [19] datasets. Besides, at test time, it has
a low time and space complexity, independent of the dataset training size which
is an asset for industrial applications. We also extend the evaluation protocol
to assess model performance in more realistic conditions, i.e., on a non-aligned
dataset.
2 Related Work
Anomaly detection and localization methods can be categorized as either reconstruction-based or embedding similarity-based methods.
Reconstruction-based methods are widely-used for anomaly detection
and localization. Neural network architectures like autoencoders (AE) [6,8,12,14],
variational autoencoders (VAE) [16,18,28,30] or generative adversarial networks
(GAN) [2,24,27] are trained to reconstruct normal training images only. Therefore, anomalous images can be spotted as they are not well reconstructed. At the
478 T. Defard et al.
image level, the simplest approach is to take the reconstructed error as an anomaly
score [12] but additional information from the latent space [1,24], intermediate
activations [15] or a discriminator [2,3] can help to better recognize anomalous
images. Yet to localize anomalies, reconstruction-based methods can take the
pixel-wise reconstruction error as the anomaly score [6] or the structural similarity [8]. Alternatively, the anomaly map can be a visual attention map generated
from the latent space [18,30]. Although reconstruction-based methods are very
intuitive and interpretable, their performance is limited by the fact that AE can
sometimes yield good reconstruction results for anomalous images too [23].
Embedding similarity-based methods use deep neural networks to
extract meaningful vectors describing an entire image for anomaly detection
[4,5,25,26] or an image patch for anomaly localization [7,9,21,31]. Still, embedding similarity-based methods that only perform anomaly detection give promising results but often lack interpretability as it is not possible to know which part
of an anomalous images is responsible for a high anomaly score. The anomaly
score is in this case the distance between embedding vectors of a test image and
reference vectors representing normality from the training dataset. The normal
reference can be the center of a n-sphere containing embeddings from normal
images [26,31], parameters of Gaussian distributions [17,25] or the entire set of
normal embedding vectors [4,9]. The last option is used by SPADE [9] which
has the best reported results for anomaly localization. However, it runs a K-NN
algorithm on a set of normal embedding vectors at test time, so the inference
complexity scales linearly to the dataset training size. This may hinder industrial
deployment of the method.
Our method, PaDiM, generates patch embeddings for anomaly localization,
similar to the aforementioned approaches. However, the normal class in PaDiM
is described through a set of Gaussian distributions that also model correlations between semantic levels of the used pretrained CNN model. Inspired by
[9,25], we choose as pretrained networks a ResNet [13], a Wide-ResNet [32] or an
EfficientNet [29]. Thanks to this modelisation, PaDiM outperforms the current
state-of-the-art methods. Moreover, its time complexity is low and independent
of the training dataset size at the prediction stage.
3 Patch Distribution Modeling
3.1 Embedding Extraction
Pretrained CNNs are able to output relevant features for anomaly detection
[4]. Therefore, we choose to avoid ponderous neural network optimization by
only using a pretrained CNN to generate patch embedding vectors. The patch
embedding process in PaDiM is similar to one from SPADE [9] and illustrated
in Fig. 2. During the training phase, each patch of the normal images is associated to its spatially corresponding activation vectors in the pretrained CNN
activation maps. Activation vectors from different layers are then concatenated
to get embedding vectors carrying information from different semantic levels and
resolutions, in order to encode fine-grained and global contexts. As activation
PaDiM 479
maps have a lower resolution than the input image, many pixels have the same
embeddings and then form pixel patches with no overlap in the original image
resolution. Hence, an input image can be divided in a grid of (i, j) ∈ [1, W]×[1, H]
positions where W × H is the resolution of the largest activation map used to
generate embeddings. Finally, each patch position (i, j) in this grid is associated
to an embedding vector xij computed as described above.
The generated patch embedding vectors may carry redundant information,
therefore we experimentally study the possibility to reduce their size (Sect. 5.1).
We noticed that randomly selecting few dimensions is more efficient that a classic Principal Component Analysis (PCA) algorithm [22]. This simple random
dimensionality reduction significantly decreases the complexity of our model for
both training and testing time while maintaining the state-of-the-art performance. Finally, patch embedding vectors from test images are used to output
an anomaly map with the help of the learned parametric representation of the
normal class described in the next subsection.
3.2 Learning of the Normality
To learn the normal image characteristics at position (i, j), we first compute the
set of patch embedding vectors at (i, j), Xij = {xk
ij , k ∈ [[1, N]]} from the N
normal training images as shown on Fig. 2. To sum up the information carried
by this set we make the assumption that Xij is generated by a multivariate
Gaussian distribution N (μij , Σij ) where μij is the sample mean of Xij and the
sample covariance Σij is estimated as follows :
Σij = 1
N − 1

N
k=1
(xk
ij − μij)(xk
ij − μij)
T + I (1)
where the regularisation term I makes the sample covariance matrix Σij
full rank and invertible. Finally, each possible patch position is associated with
a multivariate Gaussian distribution as shown in Fig. 2 by the matrix of Gaussian
parameters.
Our patch embedding vectors carry information from different semantic levels. Hence, each estimated multivariate Gaussian distribution N (μij , Σij ) captures information from different levels too and Σij contains the inter-level correlations. We experimentally show (Sect. 5.1) that modeling these relationships
between the different semantic levels of the pretrained CNN helps to increase
anomaly localization performance.
3.3 Inference: Computation of the Anomaly Map
Inspired by [17,25], we use the Mahalanobis distance [20] M(xij ) to give an
anomaly score to the patch in position (i, j) of a test image. M(xij ) can be
interpreted as the distance between the test patch embedding xij and learned
distribution N (μij , Σij ), where M(xij ) is computed as follows:
480 T. Defard et al.
M(xij ) =
(xij − μij )T Σ−1
ij (xij − μij ) (2)
Hence, the matrix of Mahalanobis distances M = (M(xij ))1<i<W,1<j<H that
forms an anomaly map can be computed. High scores in this map indicate the
anomalous areas. The final anomaly score of the entire image is the maximum of
anomaly map M. Finally, at test time, our method does not have the scalability
issue of the K-NN based methods [5,9,21,31] as we do not have to compute and
sort a large amount of distance values to get the anomaly score of a patch.
4 Experiments
4.1 Datasets and Metrics
Metrics. To assess the localization performance we compute two threshold independent metrics. We use the Area Under the Receiver Operating Characteristic
curve (AUROC) where the true positive rate is the percentage of pixels correctly
classified as anomalous. Since the AUROC is biased in favor of large anomalies
we also employ the per-region-overlap score (PRO-score) [7]. It consists in plotting, for each connected component, a curve of the mean values of the correctly
classified pixel rates as a function of the false positive rate between 0 and 0.3.
The PRO-score is the normalized integral of this curve. A high PRO-score means
that both large and small anomalies are well-localized.
Datasets. We first evaluate our models on the MVTec AD [6] designed to test
anomaly localization algorithms for industrial quality control and in a one-class
learning setting. It contains 15 classes of approximately 240 images. The original
image resolution is between 700 × 700 and 1024 × 1024. There are 10 object and
5 texture classes. Objects are always well-centered and aligned in the same way
across the dataset as we can see in Fig. 1 for classes Transistor and Capsule. In
addition to the original dataset, to assess performance of anomaly localization
models in a more realistic context, we create a modified version of the MVTec
AD, referred as Rd-MVTec AD, where we apply random rotation (–10, +10)
and random crop (from 256 × 256 to 224 × 224) to both the train and test sets.
This modified version of the MVTec AD may better describe real use cases of
anomaly localization for quality control where objects of interest are not always
centered and aligned in the image.
For further evaluation, we also test PaDiM on the Shanghai Tech Campus
(STC) Dataset [19] that simulates video surveillance from a static camera. It
contains 274 515 training and 42 883 testing frames divided in 13 scenes. The
original image resolution is 856 × 480. The training videos are composed of
normal sequences and test videos have anomalies like the presence of vehicles in
pedestrian areas or people fighting.
PaDiM 481
4.2 Experimental Setups
We train PaDiM with different backbones, a ResNet18 (R18) [13], a Wide
ResNet-50-2 (WR50) [32] and an EfficientNet-B5 [29], all pretrained on ImageNet [11]. Like in [9], patch embedding vectors are extracted from the first
three layers when the backbone is a ResNet, in order to combine information
from different semantic levels, while keeping a high enough resolution for the
localization task. Following this idea, we extract patch embedding vectors from
layers 7 (level 2), 20 (level 4), and 26 (level 5), if an EfficientNet-B5 is used. We
also apply a random dimensionality reduction (Rd) (see Sects. 3.1 and 5.1). Our
model names indicate the backbone and the dimensionality reduction method
used, if any. For example, PaDiM-R18-Rd100 is a PaDiM model with a ResNet18
backbone using 100 randomly selected dimensions for the patch embedding vectors. By default we use  = 0.01 for the  from Eq. 1.
We reproduce the model SPADE [9] as described in the original publication
with a Wide ResNet-50-2 (WR50) [32] as backbone. For SPADE and PaDiM we
apply the same prepocessing as in [9]. We resize the images from the MVTec AD
to 256 × 256 and center crop them to 224 × 224. For the images from the STC
we use a 256 × 256 resize only. We resize the images and the localization maps
using bicubic interpolation and we use a Gaussian filter on the anomaly maps
with parameter σ = 4 like in [9].
We also implement our own VAE as a reconstruction-based baseline implemented with a ResNet18 as encoder and a 8 × 8 convolutional latent variable.
It is trained on each MVTec AD class with 10 000 images using the following
data augmentations operations: random rotation (−2◦, +2◦), 292 × 292 resize,
random crop to 282 × 282, and finally center crop to 256 × 256. The training
is performed during 100 epochs with the Adam optimizer [16] with an initial
learning rate of 10−4 and a batch size of 32 images. The anomaly map for the
localization corresponds to the pixel-wise L2 error for reconstruction.
5 Results
5.1 Ablative Studies
First, we evaluate the impact of modeling correlations between semantic levels
in PaDiM and explore the possibility to simplify our method through dimensionality reduction.
Inter-Layer Correlation. The combination of Gaussian modeling and the
Mahalanobis distance has already been employed in previous works to detect
adversarial attacks [17] and for anomaly detection [25] at the image level. However those methods do not model correlations between different CNN’s semantic
levels as we do in PaDiM. In Table 1 we show the anomaly localization performance on the MVTec AD of PaDiM with a ResNet18 backbone when using only
one of the first three layers (Layer 1, Layer 2, or Layer 3) and when summing the
outputs of these 3 models to form an ensemble method that takes into account
482 T. Defard et al.
the first three layers but not the correlations between them (Layers 1+2+3). The
last row of Table 1 (PaDiM-R18) is our proposed version of PaDiM where each
patch location is described by one Gaussian distribution taking into account the
first three ResNet18 layers and correlations between them.
Table 1. Study of the anomaly localization performance using different semantic-level
CNN layers. Results are displayed as tuples (AUROC%, PRO-score%) on the MVTec
AD.
Layer used All texture classes All object classes All classes
Layer 1 (93.1, 87.1) (95.6, 86.5) (94.8, 86.8)
Layer 2 (95.0, 89.7) (96.1, 87.9) (95.7, 88.5)
Layer 3 (94.8, 89.6) (97.1, 87.7) (95.7, 88.3)
Layer 1+2+3 (95.4, 90.7) (96.3, 88.1) (96.0, 89.0)
PaDiM-R18 (96.3, 92.3) (97.5, 90.1) (97.1, 90.8)
It can be observed that using Layer 3 produces the best results in terms of
AUROC among the three layers. It is due to the fact that Layer 3 carries higher
semantic level information which helps to better describe normality. However,
Layer 3 has a slightly worse PRO-score than Layer 2 that can be explained by the
lower resolution of Layer 2 which affects the accuracy of anomaly localization.
As we see in the two last rows of Table 1, aggregating information from different layers can solve the trade-off issue between high semantic information and
high resolution. Unlike model Layer 1+2+3 that simply sums the outputs, our
model PaDiM-R18 takes into account correlations between semantic levels. As a
result, it outperforms Layer 1+2+3 by 1.1p.p (percent point). for AUROC and
1.8p.p. for PRO-score. It confirms the relevance of modeling correlation between
semantic levels.
Table 2. Study of the anomaly localization performance with a dimensionality reduction from 448 to 100 and 200 using PCA or random feature selection (Rd). Results are
displayed as tuples (AUROC%, PRO-score%) on the MVTec AD.
All texture classes All object classes All classes
Rd 100 (95.7, 91.3) (97.2, 89.4) (96.7, 90.5)
PCA 100 (93.7, 88.9) (93.5, 84.1) (93.5, 85.7)
Rd 200 (96.1, 92.0) (97.5, 89.8) (97.0, 90.5)
PCA 200 (95.1, 91.8) (96.0, 88.1) (95.7, 89.3)
all (448) (96.3, 92.3) (97.5, 90.1) (97.1, 90.8)
Dimensionality Reduction. PaDiM-R18 estimates multivariate Gaussian distributions from sets of patch embeddings vectors of 448 dimensions each.
PaDiM 483
Decreasing the embedding vector size would reduce the computational and memory complexity of our model. We study two different dimensionality reduction
methods. The first one consists in applying a Principal Component Analysis
(PCA) algorithm to reduce the vector size to 100 or 200 dimensions. The second
method is a random feature selection where we randomly select features before
the training. In this case, we train 10 different models and take the average
scores. Still the randomness does not change the results between different seeds
as the standard error mean (SEM) for the average AUROC is always between
10−4 and 10−7.
From Table 2 we can notice that for the same number of dimensions, the random dimensionality reduction (Rd) outperforms the PCA on all the MVTec AD
classes by at least 1.3p.p in the AUROC and 1.2p.p in the PRO-score. It can be
explained by the fact that PCA selects the dimensions with the highest variance
which may not be the ones that help to discriminate the normal class from the
anomalous one [25]. It can also be noted from Table 2 that randomly reducing
the embedding vector size to only 100 dimensions has a very little impact on
the anomaly localization performance. The results drop only by 0.4p.p in the
AUROC and 0.3p.p in the PRO-score. This simple yet effective dimensionality
reduction method significantly reduces PaDiM time and space complexity as it
will be shown in Sect. 5.4.
Table 3. Comparison of our PaDiM models with the state-of-the-art for the anomaly
localization on the MVTec AD. Results are displayed as tuples (AUROC%, PROscore%)
Type Reconstruction-based methods Embedding similarity based methods Our methods
Model AE
simm
[6–8]
AE L2
[6,7]
VAE Student [7] Patch
SVDD
[31]
SPADE
[9]
PaDiMR18-Rd100
PaDiMWR50-
Rd550
Carpet (87, 64.7) (59, 45.6) (59.7, 61.9) (-, 69.5) (92.6, -) (97.5, 94.7) (98.9, 96.0) (99.1, 96.2)
Grid (94, 84.9) (90, 58.2) (61.2, 40.8) (-, 81.9) (96.2, -) (93.7, 86.7) (94.9, 90.9) (97.3, 94.6)
Leather (78, 56.1) (75, 81.9) (67.1, 64.9) (-, 81.9) (97.4, -) (97.6, 97.2) (99.1, 97.9) (99.2, 97.8)
Tile (59, 17.5) (51, 89.7) (51.3, 24.2) (-, 91.2) (91.4, -) (87.4, 75.9) (91.2, 81.6) (94.1, 86.0)
Wood (73, 60.5) (73, 72.7) (66.6, 57.8) (-, 72.5) (90.8, -) (88.5, 87.4) (93.6, 90.3) (94.9, 91.1)
All texture
classes
(78, 56.7) (70, 69.6) (61.2, 49.9) (-, 79.4) (93.7, -) (92.9, 88.4) (95.6, 91.3) (96.9, 93.2)
Bottle (93, 83.4) (86, 91.0) (83.1, 70.5) (-, 91.8) (98.1, -) (98.4, 95.5) (98.1, 93.9) (98.3, 94.8)
Cable (82, 47.8) (86, 82.5) (83.1, 77.9) (-, 86.5) (96.8, -) (97.2, 90.9) (95.8, 86.2) (96.7, 88.8)
Capsule (94, 86.0) (88, 86.2) (81.7, 77.9) (-, 91.6) (95.8, -) (99.0 ,93.7) (98.3, 91.9) (98.5, 93.5)
Hazelnut (97, 91.6) (95, 91.7) (87.7, 77.0) (-, 93.7) (97.5, -) (99.1, 95.4) (97.7, 91.4) (98.2, 92.6)
Metal Nut (89, 60.3) (86, 83.0) (78.7, 57.6) (-, 89.5) (98.0, -) (98.1, 94.4) (96.7, 81.9) (97.2, 85.6)
Pill (91, 83.0) (85, 89.3) (81.3, 79.3) (-, 93.5) (95.1, -) (96.5, 94.6) (94.7, 90.6) (95.7, 92.7)
Screw (96, 88.7) (96, 75.4) (75.3, 66.4) (-, 92.8) (95.7, -) (98.9, 96.0) (97.4, 91.3) (98.5, 94.4)
Toothbrush (92, 78.4) (93, 82.2) (91.9, 85.4) (-, 86.3) (98.1, -) (97.9, 93.5) (98.7, 92.3) (98.8, 93.1)
Transistor (90, 72.5) (86, 72.8) (75.4, 61.0) (-, 70.1) (97.0, -) (94.1, 87.4) (97.2, 80.2) (97.5, 84.5)
Zipper (88, 66.5) (77, 83.9) (71.6, 60.8) (-, 93.3) (95.1, -) (96.5, 92.6) (98.2, 94.7) (98.5, 95.9)
All object
classes
(91, 75.8) (88, 83.8) (81.0, 71.4) (-, 88.9) (96.7, -) (97.6, 93.4) (97.3, 89.4) (97.8, 91.6)
All classes (87, 69.4) (82, 79.0) (74.4, 64.2) (-, 85.7) (95.7, -) (96.5, 91.7) (96.7, 90.1) (97.5, 92.1)
484 T. Defard et al.
5.2 Comparison with the State-of-the-art
Localization. In Table 3, we show the AUROC and the PRO-score results for
anomaly localization on the MVTec AD. For a fair comparison, we used a Wide
ResNet-50-2 (WR50) as this backbone is used in SPADE [9]. Since the other
baselines have smaller backbones, we also try a ResNet18 (R18). We randomly
reduce the embedding size to 550 and 100 for PaDiM with WR50 and R18
respectively.
We first notice that PaDiM-WR50-Rd550 outperforms all the other methods
in both the PRO-score and the AUROC on average for all the classes. PaDiMR18-Rd100 which is a very light model also outperforms all models in the average
AUROC on the MVTec AD classes by at least 0.2p.p. When we further analyze
the PaDiM performances, we see that the gap for the object classes is small as
PaDiM-WR50-Rd550 is the best only in the AUROC (+0.2p.p) but SPADE [9] is
the best in the PRO-score (+1.8p.p). However, our models are particularly accurate on texture classes. PaDiM-WR50-Rd550 outperforms the second best model
SPADE [9] by 4.8p.p and 4.0p.p in the PRO-score and the AUROC respectively
on average on texture classes. Indeed, PaDiM learns an explicit probabilistic
model of the normal classes contrary to SPADE [9] or Patch-SVDD [31]. It is
particularly efficient on texture images because even if they are not aligned and
centered like object images, PaDiM effectively captures their statistical similarity
accross the normal train dataset.
Additionally, we evaluate our model on the STC dataset. We compare our
method to the two best reported models performing anomaly localization without temporal information, CAVGA-RU [30] and SPADE [9].As shown in Table 4,
the best result (AUROC) on the STC dataset is achieved with our simplest model
PaDiM-R18-Rd100 by a 2.1p.p. margin. In fact, pedestrian positions in images
are highly variable in this dataset and, as shown in Sect. 5.3, our method performs well on non-aligned datasets.
Detection. By taking the maximum score of the anomaly maps issued by our
models (see Section 3.3) we give anomaly scores to entire images to perform
anomaly detection at the image level. We test PaDiM for anomaly detection
with a Wide ResNet-50-2 (WR50) [32] used in SPADE and an EfficientNetB5 [29]. The Table 5 shows that our model PaDiM-WR50-Rd550 outperforms
every method except MahalanobisAD [25] with their best reported backbone,
an EfficientNet-B4. Still our PaDiM-EfficientNet-B5 outperforms every model
by at least 2.6p.p on average on all the classes in the AUROC. Besides, contrary
to the second best method for anomaly detection, MahalanobisAD [25], our
Table 4. Comparison of our PaDiM model with the state-of-the-art for the anomaly
localization on the STC in the AUROC%.
Model CAVGA-RU [30] SPADE [9] PaDiM-R18-Rd100
AUROC score% 85 89.9 91.2
PaDiM 485
Table 5. Anomaly detection results (at the image level) on the MVTec AD using
AUROC%.
Model GANomaly
[2]
ITAE
[14]
Patch SVDD
[31]
SPADE [9]
(WR50)
Mahalano-bisAD
[25]
(EfficientNet-B4)
PaDiM-WR50-
Rd550
PaDiM
EfficientNetB5
All
textures
classes
- – 94.6 – 97.2 98.8 99.0
All objects
classes
- – 90.9 – 94.8 93.6 97.2
All classes 76.2 83.9 92.1 85.5 95.8 95.3 97.9
Table 6. Anomaly localization results on the non-aligned Rd-MVTec AD. Results are
displayed as tuples (AUROC%, PRO-score%)
Model VAE (R18) SPADE (WR50) PaDiM-WR50-Rd550
All texture classes (54.7, 23.1) (84.6, 75.6) (92.4, 77.9)
All object classes (65.8, 30.2) (88.2, 65.8) (92.1, 70.8)
All classes (62.1, 27.8) (87.2, 69.0) (92.2, 73.1)
model also performs anomaly segmentation which characterizes more precisely
the anomalous areas in the images.
5.3 Anomaly Localization on a Non-aligned Dataset
To estimate the robustness of anomaly localization methods, we train and evaluate the performance of PaDiM and several state-of-the-art methods (SPADE
[9], VAE) on a modified version of the MVTec AD, Rd-MVTec AD, described in
Sect. 4.1. Results of this experiment are displayed in Table 6. For each test configuration we run 5 times data preprocessing on the MVTec AD with random
seeds to obtain 5 different versions of the dataset, denoted as Rd-MVTec AD.
Then, we average the obtained results and report them in Table 6. According
to the presented results, PaDiM-WR50-Rd550 outperforms the other models on
both texture and object classes in the PRO-score and the AUROC. Besides, the
SPADE [9] and VAE performances on the Rd-MVTec AD decrease more than
the performance of PaDiM-WR50-Rd550 when comparing to the results obtained
on the normal MVTec AD (refer to Table 3). The AUROC results decrease by
5.3p.p for PaDiM-WR50-Rd550 against 12.2p.p and 8.8p.p decline for VAE and
SPADE respectively. Thus, we can conclude that our method seems to be more
robust to non-aligned images than the other existing and tested works.
5.4 Scalability Gain
Time Complexity. In PaDiM, the training time complexity scales linearly with
the dataset size because the Gaussian parameters are estimated using the entire
486 T. Defard et al.
Table 7. Average inference time of anomaly localization in seconds on the MVTec AD
with a CPU intel i7-4710HQ @ 2.50 GHz.
Model SPADE (WR50) VAE (R18) PaDiM R18-Rd100 PaDiM-WR50-Rd550
Inference time (sec.) 7.10 0.21 0.23 0.95
training dataset. However, contrary to the methods that require to train deep
neural networks, PaDiM uses a pretrained CNN, and, thus, no deep learning
training is required which is often a complex procedure. Hence, it is very fast and
easy to train it on small datasets like MVTec AD. For our most complex model
PaDiM-WR50-Rd550, the training on a CPU (Intel CPU 6154 3 GHz 72th) with
a serial implementation takes on average 150 s on the MVTec AD classes and
1500 s on average on the STC video scenes. These training procedures could be
further accelerated using GPU hardware for the forward pass and the covariance
estimation. In contrast, training the VAE with 10 000 images per class on the
MVTec AD following the procedure described in Sect. 4.2 takes 2h40 per class
using one GPU NVIDIA P5000. Conversely, SPADE [9] requires no training as
there are no parameters to learn. Still, it computes and stores in the memory
before testing all the embedding vectors of the normal training images. Those
vectors are the inputs of a K-NN algorithm which makes SPADE’s inference very
slow as shown in Table 7.
In Table 7, we measure the model inference time using a mainstream CPU
(Intel i7-4710HQ CPU @ 2.50 GHz) with a serial implementation. On the MVTec
AD, the inference time of SPADE is around seven times slower than our PaDiM
model with equivalent backbone because of the computationally expensive NN
search. Our VAE implementation, which is similar to most reconstruction-based
models, is the fastest model but our simple model PaDiM-R18-Rd100 has the
same order of magnitude for the inference time. While having similar complexity,
PaDiM largely outperfoms the VAE methods (see Sect. 5.2).
Memory Complexity. Unlike SPADE [9] and Patch SVDD [31], the space
complexity of our model is independent of the dataset training size and depends
only on the image resolution. PaDiM keeps in the memory only the pretrained
CNN and the Gaussian parameters associated with each patch. In Table 8 we
show the memory requirement of SPADE, our VAE implementation, and PaDiM,
assuming that parameters are encoded in float32. Using equivalent backbone,
SPADE has a lower memory consumption than PaDiM on the MVTec AD.
However, when using SPADE on a larger dataset like the STC, its memory
consumption becomes intractable, whereas PaDiM-WR50-Rd550 requires seven
times less memory. The PaDiM space complexity increases from the MVTec AD
to the STC only because the input image resolution is higher in the latter dataset
as described in Sect. 4.2. Finally, one of the advantages of our framework PaDiM
is that the user can easily adapt the method by choosing the backbone and the
embedding size to fit its inference time requirements, resource limits, or expected
performance.
PaDiM 487
Table 8. Memory requirement in Gb of the anomaly localization methods trained on
the MVTec AD and the STC dataset.
Model SPADE (WR50) VAE (R18) PaDiM
R18-Rd100
PaDiMWR50-Rd550
MVTec AD 1.4 0.09 0.17 3.8
STC 37.0 - 0.21 5.2
6 Conclusion
We have presented a framework called PaDiM for anomaly detection and localization in one-class learning setting which is based on distribution modeling. It
achieves state-of-the-art performance on MVTec AD and STC datasets. Moreover, we extend the evaluation protocol to non-aligned data and the first results
show that PaDiM can be robust on these more realistic data. PaDiM low memory
and time consumption and its ease of use make it suitable for various applications, such as visual industrial control.
References
1. Abati, D., Porrello, A., Calderara, S., Cucchiara, R.: Latent space autoregression
for novelty detection. In: 2019 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), pp. 481–490 (2019)
2. Akcay, S., Atapour-Abarghouei, A., Breckon, T.P.: GANomaly: semi-supervised
anomaly detection via adversarial training. In: Jawahar, C.V., Li, H., Mori, G.,
Schindler, K. (eds.) ACCV 2018. LNCS, vol. 11363, pp. 622–637. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-20893-6 39
3. Ak¸cay, S., Atapour-Abarghouei, A., Breckon, T.P.: Skip-ganomaly: skip connected
and adversarially trained encoder-decoder anomaly detection. In: 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1–8 (2019)
4. Bergman, L., Cohen, N., Hoshen, Y.: Deep nearest neighbor anomaly detection.
In: arXiv, 2002.10445 (2020)
5. Bergman, L., Hoshen, Y.: Classification-based anomaly detection for general data.
In: International Conference on Learning Representations (ICPR) (2020)
6. Bergmann, P., Fauser, M., Sattlegger, D., Steger, C.: Mvtec ad-a comprehensive
real-world dataset for unsupervised anomaly detection. In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9584–9592
(2019)
7. Bergmann, P., Fauser, M., Sattlegger, D., Steger, C.: Uninformed students:
Student-teacher anomaly detection with discriminative latent embeddings. In: 2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp.
4182–4191 (2020)
8. Bergmann, P., L¨owe, S., Fauser, M., Sattlegger, D., Steger, C.: Improving unsupervised defect segmentation by applying structural similarity to autoencoders.
In: Proceedings of the 14th International Joint Conference on Computer Vision,
Imaging and Computer Graphics Theory and Applications (VISIGRAPP), vol. 5,
VISAPP (2019)
488 T. Defard et al.
9. Cohen, N., Hoshen, Y.: Sub-image anomaly detection with deep pyramid correspondences. In: arXiv 2005.02357 (2020)
10. Cover, T., Hart, P.: Nearest neighbor pattern classification. IEEE Trans. Inf. Theory 13(1), 21–27 (1967)
11. Deng, J., et al.: Imagenet: a large-scale hierarchical image database. In: 2009 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248–255
(2009)
12. Gong, D., et al.: Memorizing normality to detect anomaly: Memory-augmented
deep autoencoder for unsupervised anomaly detection. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 1705–1714 (2019)
13. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 770–778 (2016)
14. Huang, C., Ye, F., Cao, J., Li, M., Zhang, Y., Lu, C.: Attribute restoration framework for anomaly detection. In: arXiv, 1911.10676 (2019)
15. Kim, K.H., et al.: Rapp: Novelty detection with reconstruction along projection
pathway. In: 2020 International Conference on Learning Representations (ICLR)
(2020)
16. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: Proceedings of
the 2nd International Conference on Learning Representations (ICLR) (2014)
17. Lee, K., Lee, K., Lee, H., Shin, J.: A simple unified framework for detecting outof-distribution samples and adversarial attacks. In: Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS 2018, pp.
7167–7177. Curran Associates Inc., Red Hook, NY, USA (2018)
18. Liu, W., et al.: Towards visually explaining variational autoencoders. In: 2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 8639–8648 (2020)
19. Liu, W., Luo, W., Lian, D., Gao, S.: Future frame prediction for anomaly detection
- a new baseline. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 6536–6545 (2018)
20. Mahalanobis, P.: On the generalized distance in statistics. In: National Institute
of Science of India (1936)
21. Napoletano, P., Piccoli, F., Schettini, R.: In: Sensors (Basel, Switzerland), vol. 18,
p. 209 (2018)
22. Pearson, K.: On lines and planes of closest fit to systems of points in space. London,
Edinburgh, Dublin Philosophical Mag. J. Sci. 2(11), 559–572 (1901)
23. Perera, P., Nallapati, R., Xiang, B.: Ocgan: one-class novelty detection using gans
with constrained latent representations. In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2893–2901 (2019)
24. Pidhorskyi, S., Almohsen, R., Adjeroh, D.A., Doretto, G.: Generative probabilistic novelty detection with adversarial autoencoders. In: Proceedings of the 32nd
International Conference on Neural Information Processing Systems, NIPS 2018,
pp. 6823–6834. Curran Associates Inc., Red Hook, NY, USA (2018)
25. Rippel, O., Mertens, P., Merhof, D.: Modeling the distribution of normal data in
pre-trained deep features for anomaly detection. In: arXiv, 2005.14140 (2020)
26. Ruff, L., et al.: Deep one-class classification. Proceedings of Machine Learning
Research, vol. 80, pp. 4393–4402. PMLR, Stockholmsm¨assan, Stockholm Sweden
(10–15 July 2018)
27. Sabokrou, M., Khalooei, M., Fathy, M., Adeli, E.: Adversarially learned oneclass classifier for novelty detection. In: 2018 IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 3379–3388 (2018)
PaDiM 489
28. Sato, K., Hama, K., Matsubara, T., Uehara, K.: Predictable uncertainty-aware
unsupervised deep anomaly segmentation. In: 2019 International Joint Conference
on Neural Networks (IJCNN), pp. 1–7 (2019)
29. Tan, M., Le, Q.: EfficientNet: rethinking model scaling for convolutional neural
networks. In: Proceedings of Machine Learning Research, vol. 97, pp. 6105–6114.
PMLR, Long Beach, California, USA (09–15 June 2019)
30. Venkataramanan, S., Peng, K.C., Singh, R.V., Mahalanobis, A.: Attention guided
anomaly localization in images. In: European Conference on Computer Vision
(ECCV), vol. 2020 (2020)
31. Yi, J., Yoon, S.: Patch svdd: Patch-level svdd for anomaly detection and segmentation. In: arXiv, 2006.16067 (2020)
32. Zagoruyko, S., Komodakis, N.: Wide residual networks. In: Richard C. Wilson,
E.R.H., Smith, W.A.P. (eds.) Proceedings of the British Machine Vision Conference
(BMVC). pp. 87.1-87.12. BMVA Press (September 2016)