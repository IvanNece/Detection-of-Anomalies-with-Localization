{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS0qKQwoLocM"
      },
      "source": [
        "# 08 - Evaluation on Test-Shift with Threshold-Only Adaptation\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IvanNece/Detection-of-Anomalies-with-Localization/blob/main/notebooks/08_evaluation_shifted_threshold_only.ipynb)\n",
        "\n",
        "**Phase 6.2: Threshold-Only Adaptation**\n",
        "\n",
        "This notebook implements an ablation study to isolate the contribution of **threshold recalibration** from full model adaptation.\n",
        "\n",
        "**Experimental Setup:**\n",
        "- Models: Trained on Clean data (NO retraining)\n",
        "- Thresholds: RE-calibrated on Val-shift (F1-optimal)\n",
        "- Test: Evaluated on Test-shift\n",
        "\n",
        "**Goal:**\n",
        "Measure how much performance can be recovered through threshold adaptation alone, without model retraining.\n",
        "\n",
        "**Metrics computed:**\n",
        "- Image-level: AUROC, AUPRC, F1, Accuracy, Precision, Recall\n",
        "- Pixel-level: Pixel AUROC, PRO (Per-Region Overlap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6FLGl_sLocO"
      },
      "source": [
        "## 1. Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cWKmXSGLocO"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SETUP - Mount Google Drive & Clone Repository\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Clone repository on main branch\n",
        "print(\"Cloning repository (branch: main)...\")\n",
        "repo_dir = '/content/Detection-of-Anomalies-with-Localization'\n",
        "\n",
        "# Remove if exists\n",
        "if os.path.exists(repo_dir):\n",
        "    print(\"Removing existing repository...\")\n",
        "    !rm -rf {repo_dir}\n",
        "\n",
        "# Clone from main branch\n",
        "!git clone https://github.com/IvanNece/Detection-of-Anomalies-with-Localization.git {repo_dir}\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT = Path(repo_dir)\n",
        "\n",
        "# Dataset location\n",
        "DATASET_PATH = Path('/content/drive/MyDrive/mvtec_shifted')\n",
        "\n",
        "# Output directories on Drive\n",
        "DRIVE_ROOT = Path('/content/drive/MyDrive/anomaly_detection_project')\n",
        "PATCHCORE_MODELS_DIR = DRIVE_ROOT / '04_patchcore_clean_outputs'\n",
        "PADIM_MODELS_DIR = DRIVE_ROOT / '05_padim_clean_outputs'\n",
        "\n",
        "RESULTS_DIR = PROJECT_ROOT / 'outputs' / 'results'\n",
        "THRESHOLDS_DIR = PROJECT_ROOT / 'outputs' / 'thresholds'\n",
        "VIZ_DIR = PROJECT_ROOT / 'outputs' / 'visualizations' / 'shift_threshold_only'\n",
        "\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "THRESHOLDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify dataset exists\n",
        "if not DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Dataset not found at {DATASET_PATH}\\n\"\n",
        "        f\"Please ensure mvtec_shifted folder is in your Google Drive root.\"\n",
        "    )\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project:   {PROJECT_ROOT}\")\n",
        "print(f\"Dataset:   {DATASET_PATH}\")\n",
        "print(f\"PatchCore: {PATCHCORE_MODELS_DIR}\")\n",
        "print(f\"PaDiM:     {PADIM_MODELS_DIR}\")\n",
        "print(f\"Results:   {RESULTS_DIR}\")\n",
        "print(f\"Viz:       {VIZ_DIR}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clCBlHP22zrm"
      },
      "source": [
        "Install both `faiss` and `anomalib` libraries, required for running PatchCore and PaDiM models respectively. **Must be done before any imports.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_4LD7xQN4eG"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu --quiet\n",
        "!pip install anomalib --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q75OIqcq2zrn"
      },
      "source": [
        "Import necessary libraries and modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHW-601iLocP"
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Project imports\n",
        "from src.utils.reproducibility import set_seed\n",
        "from src.utils.config import load_config\n",
        "from src.utils.paths import ProjectPaths\n",
        "from src.data.splitter import load_splits\n",
        "from src.data.dataset import MVTecDataset\n",
        "from src.data.transforms import get_clean_transforms\n",
        "from src.models.patchcore import PatchCore\n",
        "from src.models.padim_wrapper import PadimWrapper\n",
        "\n",
        "# Metrics imports\n",
        "from src.metrics import (\n",
        "    calibrate_threshold,\n",
        "    ThresholdCalibrator,\n",
        "    compute_image_metrics,\n",
        "    compute_pixel_metrics,\n",
        "    compute_roc_curve,\n",
        "    compute_pr_curve,\n",
        "    compute_confusion_matrix,\n",
        "    aggregate_metrics,\n",
        "    aggregate_pixel_metrics\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Load configuration\n",
        "config = load_config(PROJECT_ROOT / 'configs' / 'experiment_config.yaml')\n",
        "paths = ProjectPaths(PROJECT_ROOT)\n",
        "\n",
        "# Classes to evaluate\n",
        "CLASSES = config.dataset.classes  # ['hazelnut', 'carpet', 'zipper']\n",
        "\n",
        "# Device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def evaluation_collate(batch):\n",
        "    \"\"\"Custom collate function to handle None masks in batches.\"\"\"\n",
        "    batch = list(zip(*batch))\n",
        "    images = torch.stack(batch[0])\n",
        "    masks = batch[1] # Keep as tuple/list to handle None\n",
        "    labels = torch.tensor(batch[2])\n",
        "    paths = batch[3]\n",
        "    return images, masks, labels, paths\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Classes: {CLASSES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr33gpjFLocQ"
      },
      "source": [
        "## 2. Load Shifted Data Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJGKAl9OLocQ"
      },
      "outputs": [],
      "source": [
        "# Load shifted splits\n",
        "SPLITS_PATH = paths.get_split_path('shifted')\n",
        "splits = load_splits(SPLITS_PATH)\n",
        "\n",
        "# Print split statistics\n",
        "print(\"\\nSplit Statistics:\")\n",
        "print(\"-\" * 50)\n",
        "for class_name in CLASSES:\n",
        "    val_n = len(splits[class_name]['val']['images'])\n",
        "    test_n = len(splits[class_name]['test']['images'])\n",
        "\n",
        "    val_normal = sum(1 for l in splits[class_name]['val']['labels'] if l == 0)\n",
        "    val_anom = sum(1 for l in splits[class_name]['val']['labels'] if l == 1)\n",
        "    test_normal = sum(1 for l in splits[class_name]['test']['labels'] if l == 0)\n",
        "    test_anom = sum(1 for l in splits[class_name]['test']['labels'] if l == 1)\n",
        "\n",
        "    print(f\"{class_name}:\")\n",
        "    print(f\"  Val: {val_n} ({val_normal} normal, {val_anom} anomalous)\")\n",
        "    print(f\"  Test: {test_n} ({test_normal} normal, {test_anom} anomalous)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drvMhSzLLocR"
      },
      "source": [
        "## 3. Threshold Calibration on Val-Shift\n",
        "\n",
        "**CRITICAL STEP:** We recalibrate thresholds using predictions from **clean-trained models** on **Val-shift** data.\n",
        "\n",
        "This isolates the effect of threshold adaptation from model adaptation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBV60yftLocR"
      },
      "outputs": [],
      "source": [
        "# Initialize threshold calibrators\n",
        "patchcore_calibrator = ThresholdCalibrator('patchcore')\n",
        "padim_calibrator = ThresholdCalibrator('padim')\n",
        "\n",
        "# Get transforms\n",
        "transform = get_clean_transforms(image_size=config.dataset.image_size)\n",
        "\n",
        "# Store calibration data for visualization\n",
        "calibration_data = {\n",
        "    'patchcore': {},\n",
        "    'padim': {}\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"THRESHOLD CALIBRATION (F1-Optimal on Val-shift)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PATCHCORE: Calibrate thresholds on Val-shift\n",
        "print(\"\\n>>> PATCHCORE <<<\\n\")\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n--- {class_name.upper()} ---\")\n",
        "\n",
        "    # Create validation dataset\n",
        "    val_split = splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=evaluation_collate\n",
        "    )\n",
        "\n",
        "    # Load model trained on CLEAN data\n",
        "    model = PatchCore(\n",
        "        backbone_layers=config.patchcore.layers,\n",
        "        patch_size=config.patchcore.patch_size,\n",
        "        coreset_ratio=config.patchcore.coreset_sampling_ratio,\n",
        "        n_neighbors=config.patchcore.n_neighbors,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    model.load(PATCHCORE_MODELS_DIR, class_name, domain='clean')\n",
        "\n",
        "    # Collect predictions on VAL-SHIFT\n",
        "    val_scores = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f'Validating {class_name}'):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images, return_heatmaps=False)\n",
        "\n",
        "            val_scores.extend(scores.tolist())\n",
        "            val_labels.extend(labels.numpy().tolist())\n",
        "\n",
        "    # Convert to arrays\n",
        "    val_scores = np.array(val_scores)\n",
        "    val_labels = np.array(val_labels)\n",
        "\n",
        "    # Calibrate threshold on Val-shift\n",
        "    threshold = patchcore_calibrator.calibrate(class_name, val_scores, val_labels)\n",
        "    print(f\"  Calibrated threshold: {threshold:.4f}\")\n",
        "\n",
        "    # Store for visualization\n",
        "    calibration_data['patchcore'][class_name] = {\n",
        "        'scores': val_scores,\n",
        "        'labels': val_labels,\n",
        "        'threshold': threshold\n",
        "    }\n",
        "\n",
        "# Save calibrated thresholds\n",
        "patchcore_calibrator.save(THRESHOLDS_DIR / 'shift_threshold_only_patchcore.json')\n",
        "print(f\"\\n[OK] Thresholds saved: shift_threshold_only_patchcore.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PADIM: Calibrate thresholds on Val-shift\n",
        "print(\"\\n>>> PADIM <<<\\n\")\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n--- {class_name.upper()} ---\")\n",
        "\n",
        "    # Create validation dataset\n",
        "    val_split = splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=evaluation_collate\n",
        "    )\n",
        "\n",
        "    # Load model trained on CLEAN data\n",
        "    model = PadimWrapper(\n",
        "        backbone=config.padim.backbone,\n",
        "        layers=config.padim.layers,\n",
        "        n_features=config.padim.n_features,\n",
        "        image_size=config.dataset.image_size,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    model.load(PADIM_MODELS_DIR / f'padim_{class_name}_clean.pt')\n",
        "\n",
        "    # Collect predictions on VAL-SHIFT\n",
        "    val_scores = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f'Validating {class_name}'):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images, return_heatmaps=False)\n",
        "\n",
        "            val_scores.extend(scores.tolist())\n",
        "            val_labels.extend(labels.numpy().tolist())\n",
        "\n",
        "    # Convert to arrays\n",
        "    val_scores = np.array(val_scores)\n",
        "    val_labels = np.array(val_labels)\n",
        "\n",
        "    # Calibrate threshold on Val-shift\n",
        "    threshold = padim_calibrator.calibrate(class_name, val_scores, val_labels)\n",
        "    print(f\"  Calibrated threshold: {threshold:.4f}\")\n",
        "\n",
        "    # Store for visualization\n",
        "    calibration_data['padim'][class_name] = {\n",
        "        'scores': val_scores,\n",
        "        'labels': val_labels,\n",
        "        'threshold': threshold\n",
        "    }\n",
        "\n",
        "# Save calibrated thresholds\n",
        "padim_calibrator.save(THRESHOLDS_DIR / 'shift_threshold_only_padim.json')\n",
        "print(f\"\\n[OK] Thresholds saved: shift_threshold_only_padim.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization: Score Distributions & Thresholds\n",
        "\n",
        "Visualizing how anomaly scores are distributed on Val-shifted data and where the new thresholds fall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Score distributions and thresholds\n",
        "fig, axes = plt.subplots(len(CLASSES), 2, figsize=(14, 4*len(CLASSES)))\n",
        "\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    # PatchCore\n",
        "    ax1 = axes[i, 0]\n",
        "    pc_data = calibration_data['patchcore'][class_name]\n",
        "    normal_scores = pc_data['scores'][pc_data['labels'] == 0]\n",
        "    anomalous_scores = pc_data['scores'][pc_data['labels'] == 1]\n",
        "\n",
        "    ax1.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue')\n",
        "    ax1.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red')\n",
        "    ax1.axvline(pc_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pc_data[\"threshold\"]:.2f}')\n",
        "    ax1.set_title(f'PatchCore - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Anomaly Score')\n",
        "    ax1.set_ylabel('Count')\n",
        "    ax1.legend()\n",
        "\n",
        "    # PaDiM\n",
        "    ax2 = axes[i, 1]\n",
        "    pd_data = calibration_data['padim'][class_name]\n",
        "    normal_scores = pd_data['scores'][pd_data['labels'] == 0]\n",
        "    anomalous_scores = pd_data['scores'][pd_data['labels'] == 1]\n",
        "\n",
        "    ax2.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue')\n",
        "    ax2.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red')\n",
        "    ax2.axvline(pd_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pd_data[\"threshold\"]:.2f}')\n",
        "    ax2.set_title(f'PaDiM - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlabel('Anomaly Score')\n",
        "    ax2.set_ylabel('Count')\n",
        "    ax2.legend()\n",
        "\n",
        "plt.suptitle('Score Distributions & Calibrated Thresholds (Val-shift)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(VIZ_DIR / 'score_distributions_shift_threshold.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation on Test-Shift with Recalibrated Thresholds\n",
        "\n",
        "Now we evaluate on the test set using the **recalibrated thresholds from Val-shift**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load recalibrated thresholds from saved results\n",
        "thresholds = {\n",
        "    'patchcore': patchcore_calibrator.thresholds,\n",
        "    'padim': padim_calibrator.thresholds\n",
        "}\n",
        "\n",
        "# Storage for results\n",
        "all_results = {\n",
        "    'patchcore': {},\n",
        "    'padim': {}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PATCHCORE: Evaluate on Test-shift\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST-SHIFT EVALUATION (PATCHCORE)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n--- {class_name.upper()} ---\")\n",
        "\n",
        "    # Create test dataset\n",
        "    test_split = splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=evaluation_collate\n",
        "    )\n",
        "\n",
        "    # Load model trained on CLEAN data\n",
        "    model = PatchCore(\n",
        "        backbone_layers=config.patchcore.layers,\n",
        "        patch_size=config.patchcore.patch_size,\n",
        "        coreset_ratio=config.patchcore.coreset_sampling_ratio,\n",
        "        n_neighbors=config.patchcore.n_neighbors,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    model.load(PATCHCORE_MODELS_DIR, class_name, domain='clean')\n",
        "\n",
        "    # Collect predictions\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    all_heatmaps = []\n",
        "    all_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f'Testing {class_name}'):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images, return_heatmaps=True)\n",
        "\n",
        "            all_scores.extend(scores.tolist())\n",
        "            all_labels.extend(labels.numpy().tolist())\n",
        "\n",
        "            for mask in masks:\n",
        "                if mask is not None:\n",
        "                    all_masks.append(mask.numpy().squeeze())\n",
        "                else:\n",
        "                    all_masks.append(None)\n",
        "\n",
        "            all_heatmaps.extend([h for h in heatmaps])\n",
        "\n",
        "    # Convert to arrays\n",
        "    test_scores = np.array(all_scores)\n",
        "    test_labels = np.array(all_labels)\n",
        "\n",
        "    # Get recalibrated threshold\n",
        "    threshold = thresholds['patchcore'][class_name]\n",
        "\n",
        "    # Compute image-level metrics\n",
        "    image_metrics = compute_image_metrics(test_labels, test_scores, threshold=threshold)\n",
        "\n",
        "    # Compute pixel-level metrics\n",
        "    pixel_metrics = compute_pixel_metrics(all_masks, all_heatmaps, compute_pro_metric=True)\n",
        "\n",
        "    # Store results\n",
        "    all_results['patchcore'][class_name] = {\n",
        "        'threshold': threshold,\n",
        "        'image_level': image_metrics,\n",
        "        'pixel_level': pixel_metrics,\n",
        "        'test_scores': test_scores.tolist(),\n",
        "        'test_labels': test_labels.tolist()\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"  Threshold (recalibrated on val-shift): {threshold:.4f}\")\n",
        "    print(f\"  AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics.get('accuracy', 'N/A'):.4f}\")\n",
        "    print(f\"  Pixel AUROC: {pixel_metrics.get('pixel_auroc', 'N/A')}\")\n",
        "    print(f\"  PRO: {pixel_metrics.get('pro', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PADIM: Evaluate on Test-shift\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST-SHIFT EVALUATION (PADIM)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n--- {class_name.upper()} ---\")\n",
        "\n",
        "    # Create test dataset\n",
        "    test_split = splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=evaluation_collate\n",
        "    )\n",
        "\n",
        "    # Load model trained on CLEAN data\n",
        "    model = PadimWrapper(\n",
        "        backbone=config.padim.backbone,\n",
        "        layers=config.padim.layers,\n",
        "        n_features=config.padim.n_features,\n",
        "        image_size=config.dataset.image_size,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    model.load(PADIM_MODELS_DIR / f'padim_{class_name}_clean.pt')\n",
        "\n",
        "    # Collect predictions\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    all_heatmaps = []\n",
        "    all_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f'Testing {class_name}'):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images, return_heatmaps=True)\n",
        "\n",
        "            all_scores.extend(scores.tolist())\n",
        "            all_labels.extend(labels.numpy().tolist())\n",
        "\n",
        "            for mask in masks:\n",
        "                if mask is not None:\n",
        "                    all_masks.append(mask.numpy().squeeze())\n",
        "                else:\n",
        "                    all_masks.append(None)\n",
        "\n",
        "            all_heatmaps.extend([h for h in heatmaps])\n",
        "\n",
        "    # Convert to arrays\n",
        "    test_scores = np.array(all_scores)\n",
        "    test_labels = np.array(all_labels)\n",
        "\n",
        "    # Get recalibrated threshold\n",
        "    threshold = thresholds['padim'][class_name]\n",
        "\n",
        "    # Compute image-level metrics\n",
        "    image_metrics = compute_image_metrics(test_labels, test_scores, threshold=threshold)\n",
        "\n",
        "    # Compute pixel-level metrics\n",
        "    pixel_metrics = compute_pixel_metrics(all_masks, all_heatmaps, compute_pro_metric=True)\n",
        "\n",
        "    # Store results\n",
        "    all_results['padim'][class_name] = {\n",
        "        'threshold': threshold,\n",
        "        'image_level': image_metrics,\n",
        "        'pixel_level': pixel_metrics,\n",
        "        'test_scores': test_scores.tolist(),\n",
        "        'test_labels': test_labels.tolist()\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"  Threshold (recalibrated on val-shift): {threshold:.4f}\")\n",
        "    print(f\"  AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics.get('accuracy', 'N/A'):.4f}\")\n",
        "    print(f\"  Pixel AUROC: {pixel_metrics.get('pixel_auroc', 'N/A')}\")\n",
        "    print(f\"  PRO: {pixel_metrics.get('pro', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Results & Copy to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper to convert results for JSON serialization\n",
        "def convert_for_json(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: convert_for_json(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_for_json(i) for i in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# Save full results JSON\n",
        "json_path = RESULTS_DIR / 'shifted_threshold_only_results.json'\n",
        "with open(json_path, 'w') as f:\n",
        "    json.dump(convert_for_json(all_results), f, indent=2)\n",
        "print(f\"[OK] Results saved: {json_path.name}\")\n",
        "\n",
        "# Create summary CSV\n",
        "import pandas as pd\n",
        "summary_rows = []\n",
        "\n",
        "for method, method_results in all_results.items():\n",
        "    for class_name, res in method_results.items():\n",
        "        row = {\n",
        "            'Method': method.upper(),\n",
        "            'Class': class_name,\n",
        "            'Threshold': res['threshold'],\n",
        "            'AUROC': res['image_level']['auroc'],\n",
        "            'AUPRC': res['image_level']['auprc'],\n",
        "            'F1': res['image_level']['f1'],\n",
        "            'Accuracy': res['image_level']['accuracy'],\n",
        "            'Pixel AUROC': res['pixel_level']['pixel_auroc'],\n",
        "            'PRO': res['pixel_level']['pro']\n",
        "        }\n",
        "        summary_rows.append(row)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(summary_rows)\n",
        "\n",
        "# Add Macro Average\n",
        "for method in ['PATCHCORE', 'PADIM']:\n",
        "    method_df = df[df['Method'] == method]\n",
        "    if not method_df.empty:\n",
        "        macro_avg = method_df.mean(numeric_only=True)\n",
        "        macro_row = macro_avg.to_dict()\n",
        "        macro_row['Method'] = method\n",
        "        macro_row['Class'] = 'Macro_average'\n",
        "        summary_rows.append(macro_row)\n",
        "\n",
        "final_df = pd.DataFrame(summary_rows)\n",
        "csv_path = RESULTS_DIR / 'shifted_threshold_only_results_summary.csv'\n",
        "final_df.to_csv(csv_path, index=False)\n",
        "print(f\"[OK] Summary saved: {csv_path.name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY RESULTS (Threshold-Only Adaptation)\")\n",
        "print(\"=\"*60)\n",
        "print(final_df[['Method', 'Class', 'AUROC', 'F1', 'Pixel AUROC', 'PRO']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy Results to Drive for persistence\n",
        "\n",
        "# Create destination folders\n",
        "THRESHOLD_ONLY_OUTPUTS = DRIVE_ROOT / '08_threshold_only_outputs'\n",
        "THRESHOLD_ONLY_OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "import shutil\n",
        "\n",
        "generated_files = [\n",
        "    THRESHOLDS_DIR / 'shift_threshold_only_patchcore.json',\n",
        "    THRESHOLDS_DIR / 'shift_threshold_only_padim.json',\n",
        "    RESULTS_DIR / 'shifted_threshold_only_results.json',\n",
        "    RESULTS_DIR / 'shifted_threshold_only_results_summary.csv',\n",
        "    VIZ_DIR / 'score_distributions_shift_threshold.png'\n",
        "]\n",
        "\n",
        "print(\"\\nCopying files to Drive...\")\n",
        "for src in generated_files:\n",
        "    if src.exists():\n",
        "        dst = THRESHOLD_ONLY_OUTPUTS / src.name\n",
        "        shutil.copy(src, dst)\n",
        "        print(f\"  [COPIED] {src.name}\")\n",
        "    else:\n",
        "        print(f\"  [MISSING] {src.name}\")\n",
        "\n",
        "print(f\"\\nAll results saved to: {THRESHOLD_ONLY_OUTPUTS}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
