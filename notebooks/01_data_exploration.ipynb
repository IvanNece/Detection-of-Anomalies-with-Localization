{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f3c918",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09279bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Determine environment and set project root\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        drive.mount('/content/drive')\n",
    "    \n",
    "    # Set project root (adjust this path to your Google Drive structure)\n",
    "    project_root = Path('/content/drive/MyDrive/Detection-of-Anomalies-with-Localization')\n",
    "    \n",
    "    # Clone repo if not exists\n",
    "    if not project_root.exists():\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        !git clone https://github.com/IvanNece/Detection-of-Anomalies-with-Localization.git /content/Detection-of-Anomalies-with-Localization\n",
    "        project_root = Path('/content/Detection-of-Anomalies-with-Localization')\n",
    "else:\n",
    "    # Local environment\n",
    "    project_root = Path.cwd().parent\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Project root exists: {project_root.exists()}\")\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Project imports\n",
    "from src.utils.reproducibility import set_seed\n",
    "from src.utils.config import Config\n",
    "from src.utils.paths import ProjectPaths\n",
    "\n",
    "# Helper function for config loading\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    return Config.load(config_path)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# High-res figures\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Running on: {'Google Colab' if IN_COLAB else 'Local environment'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d40f8d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(project_root / 'configs' / 'experiment_config.yaml')\n",
    "\n",
    "# Set reproducibility\n",
    "set_seed(config.seed)\n",
    "\n",
    "# Classes to analyze\n",
    "CLASSES = config.dataset.classes\n",
    "print(f\"Analyzing classes: {CLASSES}\")\n",
    "\n",
    "# Dataset paths\n",
    "DATA_ROOT = project_root / config.paths.raw_data\n",
    "print(f\"Dataset location: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b35da4",
   "metadata": {},
   "source": [
    "## 1. Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade961e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_class_structure(class_name: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Explore directory structure for a given class.\n",
    "    \n",
    "    Args:\n",
    "        class_name: Name of the class (e.g., 'hazelnut')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with structure information\n",
    "    \"\"\"\n",
    "    class_path = DATA_ROOT / class_name\n",
    "    \n",
    "    structure = {\n",
    "        'class': class_name,\n",
    "        'train_good': [],\n",
    "        'test_good': [],\n",
    "        'test_defects': {},\n",
    "        'ground_truth': {}\n",
    "    }\n",
    "    \n",
    "    # Train images (all normal)\n",
    "    train_path = class_path / 'train' / 'good'\n",
    "    if train_path.exists():\n",
    "        structure['train_good'] = sorted(list(train_path.glob('*.png')))\n",
    "    \n",
    "    # Test normal images\n",
    "    test_good_path = class_path / 'test' / 'good'\n",
    "    if test_good_path.exists():\n",
    "        structure['test_good'] = sorted(list(test_good_path.glob('*.png')))\n",
    "    \n",
    "    # Test anomalous images (by defect type)\n",
    "    test_path = class_path / 'test'\n",
    "    if test_path.exists():\n",
    "        for defect_dir in test_path.iterdir():\n",
    "            if defect_dir.is_dir() and defect_dir.name != 'good':\n",
    "                defect_type = defect_dir.name\n",
    "                structure['test_defects'][defect_type] = sorted(list(defect_dir.glob('*.png')))\n",
    "    \n",
    "    # Ground truth masks\n",
    "    gt_path = class_path / 'ground_truth'\n",
    "    if gt_path.exists():\n",
    "        for defect_dir in gt_path.iterdir():\n",
    "            if defect_dir.is_dir():\n",
    "                defect_type = defect_dir.name\n",
    "                structure['ground_truth'][defect_type] = sorted(list(defect_dir.glob('*.png')))\n",
    "    \n",
    "    return structure\n",
    "\n",
    "# Explore all classes\n",
    "dataset_structure = {}\n",
    "for class_name in CLASSES:\n",
    "    print(f\"\\nAnalyzing {class_name}...\")\n",
    "    structure = explore_class_structure(class_name)\n",
    "    dataset_structure[class_name] = structure\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"  Train (normal): {len(structure['train_good'])} images\")\n",
    "    print(f\"  Test (normal):  {len(structure['test_good'])} images\")\n",
    "    print(f\"  Defect types:   {len(structure['test_defects'])}\")\n",
    "    for defect, imgs in structure['test_defects'].items():\n",
    "        print(f\"    - {defect}: {len(imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082d056",
   "metadata": {},
   "source": [
    "## 2. Image Count Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_dataframe(dataset_structure: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create comprehensive dataframe with image counts.\n",
    "    \n",
    "    Args:\n",
    "        dataset_structure: Dataset structure dictionary\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with counts per class and split\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for class_name, structure in dataset_structure.items():\n",
    "        # Normal images\n",
    "        data.append({\n",
    "            'Class': class_name,\n",
    "            'Split': 'Train',\n",
    "            'Type': 'Normal',\n",
    "            'Defect': 'good',\n",
    "            'Count': len(structure['train_good'])\n",
    "        })\n",
    "        \n",
    "        data.append({\n",
    "            'Class': class_name,\n",
    "            'Split': 'Test',\n",
    "            'Type': 'Normal',\n",
    "            'Defect': 'good',\n",
    "            'Count': len(structure['test_good'])\n",
    "        })\n",
    "        \n",
    "        # Anomalous images by defect type\n",
    "        for defect, imgs in structure['test_defects'].items():\n",
    "            data.append({\n",
    "                'Class': class_name,\n",
    "                'Split': 'Test',\n",
    "                'Type': 'Anomalous',\n",
    "                'Defect': defect,\n",
    "                'Count': len(imgs)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create dataframe\n",
    "df_counts = create_count_dataframe(dataset_structure)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(df_counts.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY BY CLASS\")\n",
    "print(\"=\"*60)\n",
    "summary = df_counts.groupby(['Class', 'Type'])['Count'].sum().reset_index()\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Total counts\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "total_normal = df_counts[df_counts['Type'] == 'Normal']['Count'].sum()\n",
    "total_anomalous = df_counts[df_counts['Type'] == 'Anomalous']['Count'].sum()\n",
    "print(f\"Total Normal Images:    {total_normal}\")\n",
    "print(f\"Total Anomalous Images: {total_anomalous}\")\n",
    "print(f\"Total Images:           {total_normal + total_anomalous}\")\n",
    "print(f\"Anomaly Ratio:          {total_anomalous / (total_normal + total_anomalous):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278e3b3",
   "metadata": {},
   "source": [
    "### Visualization: Image Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Normal vs Anomalous by Class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "pivot_data = df_counts.groupby(['Class', 'Type'])['Count'].sum().unstack()\n",
    "pivot_data.plot(kind='bar', stacked=True, ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Image Distribution: Normal vs Anomalous', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[0].legend(title='Type', loc='upper right')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "# Train vs Test split\n",
    "split_data = df_counts[df_counts['Type'] == 'Normal'].groupby(['Class', 'Split'])['Count'].sum().unstack()\n",
    "split_data.plot(kind='bar', ax=axes[1], color=['#3498db', '#9b59b6'])\n",
    "axes[1].set_title('Normal Images: Train vs Test Split', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[1].legend(title='Split', loc='upper right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Defect Types Distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    class_data = df_counts[(df_counts['Class'] == class_name) & (df_counts['Type'] == 'Anomalous')]\n",
    "    \n",
    "    axes[idx].barh(class_data['Defect'], class_data['Count'], color='#e67e22')\n",
    "    axes[idx].set_title(f'{class_name.capitalize()} - Defect Types', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Number of Images', fontsize=10)\n",
    "    axes[idx].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(class_data['Count']):\n",
    "        axes[idx].text(v + 0.5, i, str(v), va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f410d",
   "metadata": {},
   "source": [
    "## 3. Image Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17646b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_dimensions(dataset_structure: Dict, sample_size: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze image dimensions across dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_structure: Dataset structure dictionary\n",
    "        sample_size: Number of images to sample per class\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with dimension statistics\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for class_name, structure in dataset_structure.items():\n",
    "        print(f\"Analyzing dimensions for {class_name}...\")\n",
    "        \n",
    "        # Sample images from train\n",
    "        train_sample = structure['train_good'][:sample_size]\n",
    "        \n",
    "        for img_path in tqdm(train_sample, desc=f\"  {class_name}\"):\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            \n",
    "            data.append({\n",
    "                'Class': class_name,\n",
    "                'Width': width,\n",
    "                'Height': height,\n",
    "                'Aspect_Ratio': width / height,\n",
    "                'Megapixels': (width * height) / 1e6\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Analyze dimensions\n",
    "df_dimensions = analyze_image_dimensions(dataset_structure, sample_size=50)\n",
    "\n",
    "# Display statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMAGE DIMENSION STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(df_dimensions.groupby('Class').describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7b498",
   "metadata": {},
   "source": [
    "### Visualization: Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0604be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Resolution distribution\n",
    "for class_name in CLASSES:\n",
    "    class_data = df_dimensions[df_dimensions['Class'] == class_name]\n",
    "    axes[0].scatter(class_data['Width'], class_data['Height'], \n",
    "                   label=class_name, alpha=0.6, s=100)\n",
    "\n",
    "axes[0].set_title('Image Resolution Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Width (pixels)', fontsize=12)\n",
    "axes[0].set_ylabel('Height (pixels)', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Aspect ratio distribution\n",
    "df_dimensions.boxplot(column='Aspect_Ratio', by='Class', ax=axes[1])\n",
    "axes[1].set_title('Aspect Ratio Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Aspect Ratio', fontsize=12)\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESOLUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "resolution_summary = df_dimensions.groupby('Class').agg({\n",
    "    'Width': ['mean', 'std', 'min', 'max'],\n",
    "    'Height': ['mean', 'std', 'min', 'max'],\n",
    "    'Aspect_Ratio': ['mean', 'std']\n",
    "}).round(2)\n",
    "print(resolution_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfbc7b",
   "metadata": {},
   "source": [
    "## 4. Visual Inspection: Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset_structure: Dict, n_samples: int = 3):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each class.\n",
    "    \n",
    "    Args:\n",
    "        dataset_structure: Dataset structure dictionary\n",
    "        n_samples: Number of samples per category\n",
    "    \"\"\"\n",
    "    for class_name, structure in dataset_structure.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CLASS: {class_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Normal images (train)\n",
    "        fig, axes = plt.subplots(1, n_samples, figsize=(15, 5))\n",
    "        fig.suptitle(f'{class_name.capitalize()} - Normal Images (Train)', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for idx in range(n_samples):\n",
    "            img_path = structure['train_good'][idx * len(structure['train_good']) // n_samples]\n",
    "            img = Image.open(img_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f\"Sample {idx+1}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Anomalous images (sample from different defect types)\n",
    "        defect_types = list(structure['test_defects'].keys())[:n_samples]\n",
    "        \n",
    "        if defect_types:\n",
    "            fig, axes = plt.subplots(1, len(defect_types), figsize=(15, 5))\n",
    "            if len(defect_types) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            fig.suptitle(f'{class_name.capitalize()} - Anomalous Images', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            \n",
    "            for idx, defect in enumerate(defect_types):\n",
    "                img_path = structure['test_defects'][defect][0]\n",
    "                img = Image.open(img_path)\n",
    "                axes[idx].imshow(img)\n",
    "                axes[idx].axis('off')\n",
    "                axes[idx].set_title(f\"Defect: {defect}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "visualize_samples(dataset_structure, n_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bfe66",
   "metadata": {},
   "source": [
    "## 5. Ground Truth Mask Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_masks(dataset_structure: Dict, n_samples: int = 2):\n",
    "    \"\"\"\n",
    "    Visualize anomalous images with their ground truth masks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_structure: Dataset structure dictionary\n",
    "        n_samples: Number of samples to show per class\n",
    "    \"\"\"\n",
    "    for class_name, structure in dataset_structure.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"MASKS: {class_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        defect_types = list(structure['test_defects'].keys())[:n_samples]\n",
    "        \n",
    "        for defect in defect_types:\n",
    "            if defect in structure['ground_truth']:\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                fig.suptitle(f'{class_name.capitalize()} - Defect: {defect}', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "                \n",
    "                # Image\n",
    "                img_path = structure['test_defects'][defect][0]\n",
    "                img = Image.open(img_path)\n",
    "                axes[0].imshow(img)\n",
    "                axes[0].axis('off')\n",
    "                axes[0].set_title('Anomalous Image', fontsize=12)\n",
    "                \n",
    "                # Mask\n",
    "                mask_path = structure['ground_truth'][defect][0]\n",
    "                mask = Image.open(mask_path)\n",
    "                axes[1].imshow(mask, cmap='gray')\n",
    "                axes[1].axis('off')\n",
    "                axes[1].set_title('Ground Truth Mask', fontsize=12)\n",
    "                \n",
    "                # Overlay\n",
    "                img_array = np.array(img)\n",
    "                mask_array = np.array(mask)\n",
    "                overlay = img_array.copy()\n",
    "                overlay[mask_array > 0] = [255, 0, 0]  # Red overlay on defects\n",
    "                axes[2].imshow(overlay)\n",
    "                axes[2].axis('off')\n",
    "                axes[2].set_title('Overlay (Defects in Red)', fontsize=12)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "# Visualize masks\n",
    "visualize_masks(dataset_structure, n_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6973f",
   "metadata": {},
   "source": [
    "## 6. Key Findings & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13098f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Class balance\n",
    "print(\"\\n1. CLASS DISTRIBUTION\")\n",
    "print(\"-\" * 40)\n",
    "for class_name in CLASSES:\n",
    "    class_data = df_counts[df_counts['Class'] == class_name]\n",
    "    n_normal = class_data[class_data['Type'] == 'Normal']['Count'].sum()\n",
    "    n_anomalous = class_data[class_data['Type'] == 'Anomalous']['Count'].sum()\n",
    "    ratio = n_anomalous / (n_normal + n_anomalous) * 100\n",
    "    print(f\"  {class_name.capitalize():10s}: {n_normal:3d} normal, {n_anomalous:3d} anomalous ({ratio:.1f}% anomaly rate)\")\n",
    "\n",
    "# 2. Image dimensions\n",
    "print(\"\\n2. IMAGE DIMENSIONS\")\n",
    "print(\"-\" * 40)\n",
    "for class_name in CLASSES:\n",
    "    class_dims = df_dimensions[df_dimensions['Class'] == class_name]\n",
    "    avg_w = class_dims['Width'].mean()\n",
    "    avg_h = class_dims['Height'].mean()\n",
    "    print(f\"  {class_name.capitalize():10s}: {avg_w:.0f} x {avg_h:.0f} pixels (avg)\")\n",
    "\n",
    "# 3. Defect diversity\n",
    "print(\"\\n3. DEFECT TYPE DIVERSITY\")\n",
    "print(\"-\" * 40)\n",
    "for class_name in CLASSES:\n",
    "    n_defects = len(dataset_structure[class_name]['test_defects'])\n",
    "    defect_names = list(dataset_structure[class_name]['test_defects'].keys())\n",
    "    print(f\"  {class_name.capitalize():10s}: {n_defects} defect types - {', '.join(defect_names[:5])}\")\n",
    "\n",
    "# 4. Recommendations\n",
    "print(\"\\n4. RECOMMENDATIONS FOR PREPROCESSING\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  - Resize all images to 224x224 (ResNet standard)\")\n",
    "print(\"  - Maintain aspect ratio during resizing to avoid distortion\")\n",
    "print(\"  - Apply ImageNet normalization for pre-trained backbone\")\n",
    "print(\"  - Consider data augmentation for anomalous samples (limited quantity)\")\n",
    "print(\"  - Ensure ground truth masks are resized consistently with images\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EDA COMPLETE - Ready for data preparation phase\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6eca4",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Proceed to **Notebook 02: Data Preparation** to:\n",
    "1. Implement data splitting logic (Train/Val/Test)\n",
    "2. Create MVTecDataset class\n",
    "3. Implement preprocessing transforms\n",
    "4. Save split configurations for reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
