{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b916144b",
      "metadata": {
        "id": "b916144b"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IvanNece/Detection-of-Anomalies-with-Localization/blob/main/notebooks/09_full_shift_adaptation.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9067020",
      "metadata": {
        "id": "f9067020"
      },
      "source": [
        "## 1. Setup - Mount Drive & Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1337472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1337472",
        "outputId": "b1ecb4cf-f7e8-4a92-a06b-8dcac7d43c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Done!\n",
            "\n",
            "Cloning repository (branch: main)...\n",
            "Cloning into '/content/Detection-of-Anomalies-with-Localization'...\n",
            "remote: Enumerating objects: 795, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 795 (delta 3), reused 8 (delta 3), pack-reused 768 (from 1)\u001b[K\n",
            "Receiving objects: 100% (795/795), 190.84 MiB | 20.77 MiB/s, done.\n",
            "Resolving deltas: 100% (449/449), done.\n",
            "Updating files: 100% (98/98), done.\n",
            "Done!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SETUP COMPLETE - PHASE 7: FULL SHIFT ADAPTATION\n",
            "======================================================================\n",
            "Project:  /content/Detection-of-Anomalies-with-Localization\n",
            "Clean Dataset:  /content/drive/MyDrive/mvtec_ad\n",
            "Shifted Dataset: /content/drive/MyDrive/mvtec_shifted\n",
            "Branch:   main\n",
            "Models:   /content/Detection-of-Anomalies-with-Localization/outputs/models\n",
            "Results:  /content/Detection-of-Anomalies-with-Localization/outputs/results\n",
            "Thresholds: /content/Detection-of-Anomalies-with-Localization/outputs/thresholds\n",
            "Viz:      /content/Detection-of-Anomalies-with-Localization/outputs/visualizations/shifted_full_adaptation\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SETUP - Mount Google Drive & Clone Repository\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Clone repository on main branch\n",
        "print(\"Cloning repository (branch: main)...\")\n",
        "repo_dir = '/content/Detection-of-Anomalies-with-Localization'\n",
        "\n",
        "# Remove if exists\n",
        "if os.path.exists(repo_dir):\n",
        "    print(\"Removing existing repository...\")\n",
        "    !rm -rf {repo_dir}\n",
        "\n",
        "# Clone from main branch\n",
        "!git clone https://github.com/IvanNece/Detection-of-Anomalies-with-Localization.git {repo_dir}\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT = Path(repo_dir)\n",
        "\n",
        "# Dataset locations (both clean and shifted)\n",
        "CLEAN_DATASET_PATH = Path('/content/drive/MyDrive/mvtec_ad')\n",
        "SHIFTED_DATASET_PATH = Path('/content/drive/MyDrive/mvtec_shifted')\n",
        "\n",
        "# Output directories\n",
        "MODELS_DIR = PROJECT_ROOT / 'outputs' / 'models'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'outputs' / 'results'\n",
        "THRESHOLDS_DIR = PROJECT_ROOT / 'outputs' / 'thresholds'\n",
        "VIZ_DIR = PROJECT_ROOT / 'outputs' / 'visualizations' / 'shifted_full_adaptation'\n",
        "\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "THRESHOLDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify datasets exist\n",
        "if not CLEAN_DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Clean dataset not found at {CLEAN_DATASET_PATH}\\n\"\n",
        "        f\"Please ensure mvtec_ad folder is in your Google Drive.\"\n",
        "    )\n",
        "\n",
        "if not SHIFTED_DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Shifted dataset not found at {SHIFTED_DATASET_PATH}\\n\"\n",
        "        f\"Please run notebook 03_domain_shift_generation.ipynb first.\"\n",
        "    )\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE - PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project:  {PROJECT_ROOT}\")\n",
        "print(f\"Clean Dataset:  {CLEAN_DATASET_PATH}\")\n",
        "print(f\"Shifted Dataset: {SHIFTED_DATASET_PATH}\")\n",
        "print(f\"Branch:   main\")\n",
        "print(f\"Models:   {MODELS_DIR}\")\n",
        "print(f\"Results:  {RESULTS_DIR}\")\n",
        "print(f\"Thresholds: {THRESHOLDS_DIR}\")\n",
        "print(f\"Viz:      {VIZ_DIR}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abd03ce",
      "metadata": {
        "id": "4abd03ce"
      },
      "source": [
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d5b7286f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5b7286f",
        "outputId": "8fdb4dea-19c2-4eaa-b515-31980e33f968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ FAISS installed successfully!\n",
            "  FAISS version: 1.13.1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# INSTALL FAISS - MUST BE DONE BEFORE IMPORTS!\n",
        "# ============================================================\n",
        "# FAISS speeds up coreset sampling by 10-100x\n",
        "\n",
        "!pip install faiss-cpu --quiet\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import faiss\n",
        "    print(\"✓ FAISS installed successfully!\")\n",
        "    print(f\"  FAISS version: {faiss.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"✗ FAISS installation failed, will use numpy fallback (VERY SLOW)\")\n",
        "    print(\"  Try running: !pip install faiss-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9c58aea0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c58aea0",
        "outputId": "dd8ad112-46c0-4352-a306-a76e8f8c46df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing anomalib...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.8/851.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for freia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ Success! anomalib 2.2.0 installed\n",
            "  PaDiM components available\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# INSTALL ANOMALIB - REQUIRED FOR PADIM\n",
        "# ============================================================\n",
        "\n",
        "print(\"Installing anomalib...\")\n",
        "!pip install anomalib --quiet\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import anomalib\n",
        "    from anomalib.models.image.padim import Padim\n",
        "    from anomalib.models.image.padim.torch_model import PadimModel\n",
        "    print(f\"✓ Success! anomalib {anomalib.__version__} installed\")\n",
        "    print(\"  PaDiM components available\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Error: {e}\")\n",
        "    print(\"  Retry: !pip install anomalib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e7bfb6",
      "metadata": {
        "id": "47e7bfb6"
      },
      "source": [
        "## 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9e580fd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e580fd4",
        "outputId": "381b83a2-8cf4-46d8-c7cb-271aefe3d507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 42 for reproducibility\n",
            "Loaded configuration from /content/Detection-of-Anomalies-with-Localization/configs/experiment_config.yaml\n",
            "======================================================================\n",
            "PHASE 7: FULL SHIFT ADAPTATION\n",
            "======================================================================\n",
            "Using device: cuda\n",
            "Classes: ['hazelnut', 'carpet', 'zipper']\n",
            "Coreset ratio: 0.05\n",
            "Batch size: 8\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Project imports\n",
        "from src.utils.reproducibility import set_seed\n",
        "from src.utils.config import load_config\n",
        "from src.utils.paths import ProjectPaths\n",
        "from src.data.splitter import load_splits\n",
        "from src.data.dataset import MVTecDataset\n",
        "from src.data.transforms import get_shift_transforms\n",
        "from src.models.patchcore import PatchCore\n",
        "from src.models.padim_wrapper import PadimWrapper\n",
        "\n",
        "# Metrics imports\n",
        "from src.metrics import (\n",
        "    calibrate_threshold,\n",
        "    calibrate_threshold_with_curve,\n",
        "    ThresholdCalibrator,\n",
        "    compute_image_metrics,\n",
        "    compute_pixel_metrics,\n",
        "    compute_roc_curve,\n",
        "    compute_pr_curve,\n",
        "    compute_confusion_matrix,\n",
        "    aggregate_metrics,\n",
        "    aggregate_pixel_metrics\n",
        ")\n",
        "\n",
        "from src.evaluation import Evaluator, MultiClassEvaluator\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Load configuration\n",
        "config = load_config(PROJECT_ROOT / 'configs' / 'experiment_config.yaml')\n",
        "paths = ProjectPaths(PROJECT_ROOT)\n",
        "\n",
        "# Classes to process\n",
        "CLASSES = config.dataset.classes  # ['hazelnut', 'carpet', 'zipper']\n",
        "\n",
        "# Device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Classes: {CLASSES}\")\n",
        "print(f\"Coreset ratio: {config.patchcore.coreset_sampling_ratio}\")\n",
        "print(f\"Batch size: 8\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5736965",
      "metadata": {
        "id": "c5736965"
      },
      "source": [
        "## 4. Load Shifted Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d89826d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89826d8",
        "outputId": "c70b7594-6b1b-4e30-867e-57fcbff173ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shifted Split Statistics:\n",
            "----------------------------------------------------------------------\n",
            "hazelnut:\n",
            "  Train-shift: 312 (all normal)\n",
            "  Val-shift: 100 (79 normal, 21 anomalous)\n",
            "  Test-shift: 89 (40 normal, 49 anomalous)\n",
            "carpet:\n",
            "  Train-shift: 224 (all normal)\n",
            "  Val-shift: 82 (56 normal, 26 anomalous)\n",
            "  Test-shift: 91 (28 normal, 63 anomalous)\n",
            "zipper:\n",
            "  Train-shift: 192 (all normal)\n",
            "  Val-shift: 83 (48 normal, 35 anomalous)\n",
            "  Test-shift: 116 (32 normal, 84 anomalous)\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Load shifted splits\n",
        "SHIFTED_SPLITS_PATH = paths.get_split_path('shifted')\n",
        "shifted_splits = load_splits(SHIFTED_SPLITS_PATH)\n",
        "\n",
        "# Print split statistics\n",
        "print(\"\\nShifted Split Statistics:\")\n",
        "print(\"-\" * 70)\n",
        "for class_name in CLASSES:\n",
        "    train_n = len(shifted_splits[class_name]['train']['images'])\n",
        "    val_n = len(shifted_splits[class_name]['val']['images'])\n",
        "    test_n = len(shifted_splits[class_name]['test']['images'])\n",
        "\n",
        "    val_normal = sum(1 for l in shifted_splits[class_name]['val']['labels'] if l == 0)\n",
        "    val_anom = sum(1 for l in shifted_splits[class_name]['val']['labels'] if l == 1)\n",
        "    test_normal = sum(1 for l in shifted_splits[class_name]['test']['labels'] if l == 0)\n",
        "    test_anom = sum(1 for l in shifted_splits[class_name]['test']['labels'] if l == 1)\n",
        "\n",
        "    print(f\"{class_name}:\")\n",
        "    print(f\"  Train-shift: {train_n} (all normal)\")\n",
        "    print(f\"  Val-shift: {val_n} ({val_normal} normal, {val_anom} anomalous)\")\n",
        "    print(f\"  Test-shift: {test_n} ({test_normal} normal, {test_anom} anomalous)\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca4cdf1",
      "metadata": {
        "id": "7ca4cdf1"
      },
      "source": [
        "## 5. Prepare Data Transforms and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f446dd7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f446dd7c",
        "outputId": "45f3b919-54ba-47cc-8fa2-c7cfc4220c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transform initialized:\n",
            "  Size: 224x224\n",
            "  Normalization: ImageNet statistics\n",
            "  Note: Domain shift already applied in pre-generated shifted dataset\n",
            "[OK] Custom collate function ready\n"
          ]
        }
      ],
      "source": [
        "# Create transform for shifted data (same as clean - no additional augmentation)\n",
        "# The domain shift is already \"baked\" into the shifted dataset images\n",
        "transform = get_shift_transforms(\n",
        "    image_size=config.dataset.image_size,\n",
        "    normalize_mean=config.dataset.normalize.mean,\n",
        "    normalize_std=config.dataset.normalize.std\n",
        ")\n",
        "\n",
        "print(f\"[OK] Transform initialized:\")\n",
        "print(f\"  Size: {config.dataset.image_size}x{config.dataset.image_size}\")\n",
        "print(f\"  Normalization: ImageNet statistics\")\n",
        "print(f\"  Note: Domain shift already applied in pre-generated shifted dataset\")\n",
        "\n",
        "# Custom collate function to handle None masks\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function that handles None masks.\"\"\"\n",
        "    images = torch.stack([item[0] for item in batch])\n",
        "    masks = [item[1] for item in batch]  # Keep as list (may contain None)\n",
        "    labels = torch.tensor([item[2] for item in batch])\n",
        "    paths = [item[3] for item in batch]\n",
        "    return images, masks, labels, paths\n",
        "\n",
        "print(\"[OK] Custom collate function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93996ae",
      "metadata": {
        "id": "e93996ae"
      },
      "source": [
        "---\n",
        "# PART A: PATCHCORE - FULL SHIFT ADAPTATION\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de3c557",
      "metadata": {
        "id": "6de3c557"
      },
      "source": [
        "## 6. Re-train PatchCore on Train-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "46f696c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46f696c1",
        "outputId": "d7d291fd-fef4-4f6c-db98-d4d4b2d0de5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - TRAINING ON TRAIN-SHIFT\n",
            "======================================================================\n",
            "Coreset ratio: 5.0%\n",
            "Batch size: 8\n",
            "Num workers: 0\n",
            "Image size: 224\n",
            "Backbone layers: ['layer2', 'layer3']\n",
            "Patch size: 3\n",
            "N neighbors: 9\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "CORESET_RATIO = config.patchcore.coreset_sampling_ratio\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 0  # Set to 0 for Colab\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - TRAINING ON TRAIN-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Coreset ratio: {CORESET_RATIO*100:.1f}%\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Num workers: {NUM_WORKERS}\")\n",
        "print(f\"Image size: {config.dataset.image_size}\")\n",
        "print(f\"Backbone layers: {config.patchcore.layers}\")\n",
        "print(f\"Patch size: {config.patchcore.patch_size}\")\n",
        "print(f\"N neighbors: {config.patchcore.n_neighbors}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0cd52c40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd52c40",
        "outputId": "2dd92c53-95af-4db4-decd-91797669fc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: HAZELNUT\n",
            "======================================================================\n",
            "\n",
            "Train-shift dataset: 312 images\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 215MB/s]\n",
            "Extracting features: 100%|██████████| 39/39 [02:29<00:00,  3.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using FAISS for fast k-NN search (memory bank: 12230 samples, 1536 dims)\n",
            "\n",
            "Completed HAZELNUT:\n",
            "  Memory bank size: 12230\n",
            "  Training time: 2143.60s\n",
            "  Spatial dims: (28, 28)\n",
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: CARPET\n",
            "======================================================================\n",
            "\n",
            "Train-shift dataset: 224 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 28/28 [02:02<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using FAISS for fast k-NN search (memory bank: 8780 samples, 1536 dims)\n",
            "\n",
            "Completed CARPET:\n",
            "  Memory bank size: 8780\n",
            "  Training time: 1162.60s\n",
            "  Spatial dims: (28, 28)\n",
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: ZIPPER\n",
            "======================================================================\n",
            "\n",
            "Train-shift dataset: 192 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 24/24 [01:32<00:00,  3.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using FAISS for fast k-NN search (memory bank: 7526 samples, 1536 dims)\n",
            "\n",
            "Completed ZIPPER:\n",
            "  Memory bank size: 7526\n",
            "  Training time: 845.02s\n",
            "  Spatial dims: (28, 28)\n",
            "\n",
            "======================================================================\n",
            "✓ All PatchCore models trained on TRAIN-SHIFT successfully!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Train PatchCore models on shifted data\n",
        "patchcore_models_shift = {}\n",
        "patchcore_training_stats_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"Training PatchCore on TRAIN-SHIFT: {class_name.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Create train dataset (only normal images from shifted data)\n",
        "    train_split = shifted_splits[class_name]['train']\n",
        "    train_dataset = MVTecDataset.from_split(\n",
        "        train_split,\n",
        "        transform=transform,\n",
        "        phase='train'\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain-shift dataset: {len(train_dataset)} images\")\n",
        "\n",
        "    # Initialize PatchCore\n",
        "    model = PatchCore(\n",
        "        backbone_layers=config.patchcore.layers,\n",
        "        patch_size=config.patchcore.patch_size,\n",
        "        coreset_ratio=CORESET_RATIO,\n",
        "        n_neighbors=config.patchcore.n_neighbors,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "    # Fit model\n",
        "    start_time = time.time()\n",
        "    model.fit(train_loader, apply_coreset=True)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Save model with 'shift' domain tag\n",
        "    model.save(paths.MODELS, class_name, domain='shift')\n",
        "\n",
        "    # Store statistics\n",
        "    patchcore_training_stats_shift[class_name] = {\n",
        "        'n_train_images': len(train_dataset),\n",
        "        'memory_bank_size': len(model.memory_bank),\n",
        "        'training_time_seconds': training_time,\n",
        "        'spatial_dims': model.spatial_dims\n",
        "    }\n",
        "\n",
        "    patchcore_models_shift[class_name] = model\n",
        "\n",
        "    print(f\"\\nCompleted {class_name.upper()}:\")\n",
        "    print(f\"  Memory bank size: {len(model.memory_bank)}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Spatial dims: {model.spatial_dims}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ All PatchCore models trained on TRAIN-SHIFT successfully!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cdeddc",
      "metadata": {
        "id": "d6cdeddc"
      },
      "source": [
        "## 7. PatchCore - Predict on Val-Shift for Threshold Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e5d1143e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5d1143e",
        "outputId": "5dc911aa-ec45-4203-8400-3514bab69dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - PREDICTING ON VAL-SHIFT\n",
            "======================================================================\n",
            "\n",
            "Processing HAZELNUT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift hazelnut: 100%|██████████| 13/13 [01:26<00:00,  6.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 100 samples\n",
            "  Normal: 79, Anomalous: 21\n",
            "\n",
            "Processing CARPET...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift carpet: 100%|██████████| 11/11 [01:09<00:00,  6.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 82 samples\n",
            "  Normal: 56, Anomalous: 26\n",
            "\n",
            "Processing ZIPPER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift zipper: 100%|██████████| 11/11 [01:12<00:00,  6.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 83 samples\n",
            "  Normal: 48, Anomalous: 35\n",
            "\n",
            "✓ PatchCore val-shift predictions complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - PREDICTING ON VAL-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_val_predictions_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\nProcessing {class_name.upper()}...\")\n",
        "\n",
        "    model = patchcore_models_shift[class_name]\n",
        "\n",
        "    # Load val-shift data\n",
        "    val_split = shifted_splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f\"Val-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images, return_heatmaps=True)\n",
        "            # Fix: Remove .numpy() as scores is already a numpy array after model.predict()\n",
        "            all_scores.extend(scores)\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    patchcore_val_predictions_shift[class_name] = {\n",
        "        'scores': all_scores,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "    print(f\"  Val-shift predictions: {len(all_scores)} samples\")\n",
        "    print(f\"  Normal: {sum(1 for l in all_labels if l == 0)}, Anomalous: {sum(1 for l in all_labels if l == 1)}\")\n",
        "\n",
        "print(\"\\n✓ PatchCore val-shift predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09800dbf",
      "metadata": {
        "id": "09800dbf"
      },
      "source": [
        "## 8. PatchCore - Calibrate Thresholds on Val-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f5287624",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5287624",
        "outputId": "e65c2cf6-732c-4438-fefb-84cc3c420277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\n",
            "======================================================================\n",
            "\n",
            "HAZELNUT:\n",
            "  Optimal threshold: 425.5469\n",
            "  Score range: [244.0024, 1225.2444]\n",
            "\n",
            "CARPET:\n",
            "  Optimal threshold: 241.7909\n",
            "  Score range: [155.3440, 622.5869]\n",
            "\n",
            "ZIPPER:\n",
            "  Optimal threshold: 221.6002\n",
            "  Score range: [144.7200, 674.2153]\n",
            "[OK] Thresholds saved: patchcore_shift_thresholds.json\n",
            "\n",
            "✓ PatchCore thresholds saved to: /content/Detection-of-Anomalies-with-Localization/outputs/thresholds/patchcore_shift_thresholds.json\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_calibrator_shift = ThresholdCalibrator('patchcore_shift')\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{class_name.upper()}:\")\n",
        "\n",
        "    scores = np.array(patchcore_val_predictions_shift[class_name]['scores'])\n",
        "    labels = np.array(patchcore_val_predictions_shift[class_name]['labels'])\n",
        "\n",
        "    threshold = patchcore_calibrator_shift.calibrate(class_name, scores, labels)\n",
        "\n",
        "    print(f\"  Optimal threshold: {threshold:.4f}\")\n",
        "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
        "\n",
        "# Save thresholds\n",
        "patchcore_thresholds_path = THRESHOLDS_DIR / 'patchcore_shift_thresholds.json'\n",
        "patchcore_calibrator_shift.save(patchcore_thresholds_path)\n",
        "print(f\"\\n✓ PatchCore thresholds saved to: {patchcore_thresholds_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdc8dc3",
      "metadata": {
        "id": "ffdc8dc3"
      },
      "source": [
        "## 9. PatchCore - Evaluate on Test-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "303dff74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "303dff74",
        "outputId": "f71e18d1-bd41-4428-ba7d-7baa89631b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - EVALUATION ON TEST-SHIFT\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Evaluating HAZELNUT\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test-shift hazelnut: 100%|██████████| 12/12 [00:30<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not compute pixel AUROC: Mask shape (1, 224, 224) doesn't match heatmap shape (224, 224)\n",
            "\n",
            "HAZELNUT - Results:\n",
            "  Image AUROC: 0.9673\n",
            "  Image AUPRC: 0.9805\n",
            "  F1-Score: 0.9072\n",
            "  Accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported format string passed to NoneType.__format__",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3779666184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Accuracy: {image_metrics['accuracy']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpixel_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Pixel AUROC: {pixel_metrics['pixel_auroc']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  PRO-Score: {pixel_metrics['pro_score']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - EVALUATION ON TEST-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_results_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating {class_name.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    model = patchcore_models_shift[class_name]\n",
        "    threshold = patchcore_calibrator_shift.get_threshold(class_name)\n",
        "\n",
        "    # Load test-shift data\n",
        "    test_split = shifted_splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_heatmaps = []\n",
        "    all_labels = []\n",
        "    all_masks = []\n",
        "    all_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f\"Test-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images, return_heatmaps=True)\n",
        "\n",
        "            # Fix: Remove .cpu() as scores and heatmaps are already numpy arrays\n",
        "            all_scores.extend(scores.tolist()) # Convert to list for consistent storage\n",
        "            all_heatmaps.extend(heatmaps.tolist()) # Convert to list for consistent storage\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_masks.extend(masks)\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    all_scores = np.array(all_scores)\n",
        "    all_heatmaps = np.array(all_heatmaps)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Image-level metrics\n",
        "    image_metrics = compute_image_metrics(\n",
        "        all_labels,\n",
        "        all_scores,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    # Pixel-level metrics (only for anomalous images with masks)\n",
        "    pixel_metrics = None\n",
        "    anomalous_indices = [i for i, l in enumerate(all_labels) if l == 1]\n",
        "    if len(anomalous_indices) > 0:\n",
        "        masks_true = [all_masks[i] for i in anomalous_indices if all_masks[i] is not None]\n",
        "        heatmaps_pred = [all_heatmaps[i] for i in anomalous_indices if all_masks[i] is not None]\n",
        "\n",
        "        if len(masks_true) > 0:\n",
        "            # Fix: Convert torch.Tensor mask to numpy array before passing to np.any()\n",
        "            pixel_metrics = compute_pixel_metrics([m.cpu().numpy() if isinstance(m, torch.Tensor) else m for m in masks_true], heatmaps_pred)\n",
        "\n",
        "    patchcore_results_shift[class_name] = {\n",
        "        'image_metrics': image_metrics,\n",
        "        'pixel_metrics': pixel_metrics,\n",
        "        'threshold': threshold,\n",
        "        'n_test_samples': len(all_labels),\n",
        "        'n_anomalous': sum(all_labels),\n",
        "        'predictions': {\n",
        "            'scores': all_scores.tolist(),\n",
        "            'labels': all_labels.tolist(),\n",
        "            'paths': all_paths\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{class_name.upper()} - Results:\")\n",
        "    print(f\"  Image AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  Image AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1-Score: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics['accuracy']:.4f}\")\n",
        "    if pixel_metrics:\n",
        "        if pixel_metrics['pixel_auroc'] is not None:\n",
        "            print(f\"  Pixel AUROC: {pixel_metrics['pixel_auroc']:.4f}\")\n",
        "        else:\n",
        "            print(f\"  Pixel AUROC: Not Computed (Mask/Heatmap shape mismatch or other issue)\")\n",
        "        print(f\"  PRO-Score: {pixel_metrics['pro_score']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"\\u2713 PatchCore evaluation on TEST-SHIFT complete!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a773af84",
      "metadata": {
        "id": "a773af84"
      },
      "source": [
        "## 10. Save PatchCore Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbc15a1f",
      "metadata": {
        "id": "fbc15a1f"
      },
      "outputs": [],
      "source": [
        "# Prepare results summary\n",
        "patchcore_summary_shift = {\n",
        "    'method': 'PatchCore',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': {\n",
        "        'coreset_ratio': CORESET_RATIO,\n",
        "        'backbone_layers': config.patchcore.layers,\n",
        "        'n_neighbors': config.patchcore.n_neighbors\n",
        "    },\n",
        "    'training_statistics': patchcore_training_stats_shift,\n",
        "    'validation_predictions': patchcore_val_predictions_shift,\n",
        "    'test_results': patchcore_results_shift\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "patchcore_results_path = RESULTS_DIR / 'patchcore_shift_full_adaptation_results.json'\n",
        "with open(patchcore_results_path, 'w') as f:\n",
        "    json.dump(patchcore_summary_shift, f, indent=2)\n",
        "\n",
        "print(f\"✓ PatchCore results saved to: {patchcore_results_path}\")\n",
        "\n",
        "# Save training stats as CSV\n",
        "import pandas as pd\n",
        "patchcore_stats_df = pd.DataFrame(patchcore_training_stats_shift).T\n",
        "patchcore_stats_df['training_time_seconds'] = patchcore_stats_df['training_time_seconds'].apply(lambda x: f\"{x:.2f}\")\n",
        "patchcore_stats_csv = RESULTS_DIR / 'patchcore_shift_training_stats.csv'\n",
        "patchcore_stats_df.to_csv(patchcore_stats_csv)\n",
        "print(f\"✓ Training stats saved to: {patchcore_stats_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ae76cc",
      "metadata": {
        "id": "d5ae76cc"
      },
      "source": [
        "---\n",
        "# PART B: PADIM - FULL SHIFT ADAPTATION\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ffaffa",
      "metadata": {
        "id": "71ffaffa"
      },
      "source": [
        "## 11. Re-train PaDiM on Train-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd572a1",
      "metadata": {
        "id": "cdd572a1"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - TRAINING ON TRAIN-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Backbone: {config.padim.backbone}\")\n",
        "print(f\"Layers: {config.padim.layers}\")\n",
        "print(f\"N features: {config.padim.n_features}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ad63db",
      "metadata": {
        "id": "e8ad63db"
      },
      "outputs": [],
      "source": [
        "# Train PaDiM models on shifted data\n",
        "padim_models_shift = {}\n",
        "padim_training_stats_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"Training PaDiM on TRAIN-SHIFT: {class_name.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Create train dataset\n",
        "    train_split = shifted_splits[class_name]['train']\n",
        "    train_dataset = MVTecDataset.from_split(\n",
        "        train_split,\n",
        "        transform=transform,\n",
        "        phase='train'\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain-shift dataset: {len(train_dataset)} images\")\n",
        "\n",
        "    # Initialize PaDiM\n",
        "    model = PadimWrapper(\n",
        "        backbone=config.padim.backbone,\n",
        "        layers=config.padim.layers,\n",
        "        n_features=config.padim.n_features,\n",
        "        image_size=config.dataset.image_size,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "    # Train (fit on normal samples)\n",
        "    model.fit(train_loader, verbose=True)\n",
        "\n",
        "    # Save model with 'shift' domain tag\n",
        "    model_path = MODELS_DIR / f\"padim_{class_name}_shift.pt\"\n",
        "    model.save(model_path, include_stats=True)\n",
        "\n",
        "    # Store statistics\n",
        "    padim_training_stats_shift[class_name] = {\n",
        "        'n_train_images': model.training_stats['num_samples'],\n",
        "        'training_time_seconds': model.training_stats['training_time_seconds'],\n",
        "        'memory_bank_size_mb': model.training_stats['memory_bank_size_mb']\n",
        "    }\n",
        "\n",
        "    padim_models_shift[class_name] = model\n",
        "\n",
        "    print(f\"\\nCompleted {class_name.upper()}:\")\n",
        "    print(f\"  Model: {model_path.name}\")\n",
        "    print(f\"  Training time: {model.training_stats['training_time_seconds']:.2f}s\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ All PaDiM models trained on TRAIN-SHIFT successfully!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec80870",
      "metadata": {
        "id": "2ec80870"
      },
      "source": [
        "## 12. PaDiM - Predict on Val-Shift for Threshold Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6583bc11",
      "metadata": {
        "id": "6583bc11"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - PREDICTING ON VAL-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_val_predictions_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\nProcessing {class_name.upper()}...\")\n",
        "\n",
        "    model = padim_models_shift[class_name]\n",
        "\n",
        "    # Load val-shift data\n",
        "    val_split = shifted_splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f\"Val-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images)\n",
        "            all_scores.extend(scores.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    padim_val_predictions_shift[class_name] = {\n",
        "        'scores': all_scores,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "    print(f\"  Val-shift predictions: {len(all_scores)} samples\")\n",
        "    print(f\"  Normal: {sum(1 for l in all_labels if l == 0)}, Anomalous: {sum(1 for l in all_labels if l == 1)}\")\n",
        "\n",
        "print(\"\\n✓ PaDiM val-shift predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80563f6b",
      "metadata": {
        "id": "80563f6b"
      },
      "source": [
        "## 13. PaDiM - Calibrate Thresholds on Val-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b666b2",
      "metadata": {
        "id": "44b666b2"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_calibrator_shift = ThresholdCalibrator('padim_shift')\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{class_name.upper()}:\")\n",
        "\n",
        "    scores = np.array(padim_val_predictions_shift[class_name]['scores'])\n",
        "    labels = np.array(padim_val_predictions_shift[class_name]['labels'])\n",
        "\n",
        "    threshold = padim_calibrator_shift.calibrate(class_name, scores, labels)\n",
        "\n",
        "    print(f\"  Optimal threshold: {threshold:.4f}\")\n",
        "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
        "\n",
        "# Save thresholds\n",
        "padim_thresholds_path = THRESHOLDS_DIR / 'padim_shift_thresholds.json'\n",
        "padim_calibrator_shift.save(padim_thresholds_path)\n",
        "print(f\"\\n✓ PaDiM thresholds saved to: {padim_thresholds_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db127008",
      "metadata": {
        "id": "db127008"
      },
      "source": [
        "## 14. PaDiM - Evaluate on Test-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf887e79",
      "metadata": {
        "id": "bf887e79"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - EVALUATION ON TEST-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_results_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating {class_name.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    model = padim_models_shift[class_name]\n",
        "    threshold = padim_calibrator_shift.get_threshold(class_name)\n",
        "\n",
        "    # Load test-shift data\n",
        "    test_split = shifted_splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_heatmaps = []\n",
        "    all_labels = []\n",
        "    all_masks = []\n",
        "    all_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f\"Test-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images)\n",
        "\n",
        "            all_scores.extend(scores.cpu().numpy())\n",
        "            all_heatmaps.extend(heatmaps.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_masks.extend(masks)\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    all_scores = np.array(all_scores)\n",
        "    all_heatmaps = np.array(all_heatmaps)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Image-level metrics\n",
        "    image_metrics = compute_image_metrics(\n",
        "        y_true=all_labels,\n",
        "        y_scores=all_scores,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    # Pixel-level metrics\n",
        "    pixel_metrics = None\n",
        "    anomalous_indices = [i for i, l in enumerate(all_labels) if l == 1]\n",
        "    if len(anomalous_indices) > 0:\n",
        "        masks_true = [all_masks[i] for i in anomalous_indices if all_masks[i] is not None]\n",
        "        heatmaps_pred = [all_heatmaps[i] for i in anomalous_indices if all_masks[i] is not None]\n",
        "\n",
        "        if len(masks_true) > 0:\n",
        "            pixel_metrics = compute_pixel_metrics(masks_true, heatmaps_pred)\n",
        "\n",
        "    padim_results_shift[class_name] = {\n",
        "        'image_metrics': image_metrics,\n",
        "        'pixel_metrics': pixel_metrics,\n",
        "        'threshold': threshold,\n",
        "        'n_test_samples': len(all_labels),\n",
        "        'n_anomalous': sum(all_labels),\n",
        "        'predictions': {\n",
        "            'scores': all_scores.tolist(),\n",
        "            'labels': all_labels.tolist(),\n",
        "            'paths': all_paths\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{class_name.upper()} - Results:\")\n",
        "    print(f\"  Image AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  Image AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1-Score: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics['accuracy']:.4f}\")\n",
        "    if pixel_metrics:\n",
        "        print(f\"  Pixel AUROC: {pixel_metrics['pixel_auroc']:.4f}\")\n",
        "        print(f\"  PRO-Score: {pixel_metrics['pro_score']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ PaDiM evaluation on TEST-SHIFT complete!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416858f2",
      "metadata": {
        "id": "416858f2"
      },
      "source": [
        "## 15. Save PaDiM Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8c5eb3",
      "metadata": {
        "id": "8a8c5eb3"
      },
      "outputs": [],
      "source": [
        "# Prepare results summary\n",
        "padim_summary_shift = {\n",
        "    'method': 'PaDiM',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': {\n",
        "        'backbone': config.padim.backbone,\n",
        "        'layers': config.padim.layers,\n",
        "        'n_features': config.padim.n_features\n",
        "    },\n",
        "    'training_statistics': padim_training_stats_shift,\n",
        "    'validation_predictions': padim_val_predictions_shift,\n",
        "    'test_results': padim_results_shift\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "padim_results_path = RESULTS_DIR / 'padim_shift_full_adaptation_results.json'\n",
        "with open(padim_results_path, 'w') as f:\n",
        "    json.dump(padim_summary_shift, f, indent=2)\n",
        "\n",
        "print(f\"✓ PaDiM results saved to: {padim_results_path}\")\n",
        "\n",
        "# Save training stats as CSV\n",
        "padim_stats_df = pd.DataFrame(padim_training_stats_shift).T\n",
        "padim_stats_df['training_time_seconds'] = padim_stats_df['training_time_seconds'].apply(lambda x: f\"{x:.2f}\")\n",
        "padim_stats_csv = RESULTS_DIR / 'padim_shift_training_stats.csv'\n",
        "padim_stats_df.to_csv(padim_stats_csv)\n",
        "print(f\"✓ Training stats saved to: {padim_stats_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e234939",
      "metadata": {
        "id": "1e234939"
      },
      "source": [
        "---\n",
        "# PART C: AGGREGATE RESULTS & VISUALIZATIONS\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3c5306",
      "metadata": {
        "id": "fe3c5306"
      },
      "source": [
        "## 16. Aggregate Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35314b71",
      "metadata": {
        "id": "35314b71"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AGGREGATE RESULTS - PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Aggregate image-level metrics\n",
        "def aggregate_image_metrics_across_classes(results_dict):\n",
        "    \"\"\"Aggregate image-level metrics across all classes.\"\"\"\n",
        "    metrics_by_class = {}\n",
        "    for class_name, result in results_dict.items():\n",
        "        metrics_by_class[class_name] = result['image_metrics']\n",
        "\n",
        "    # Compute macro-average\n",
        "    macro_avg = {}\n",
        "    for metric in ['auroc', 'auprc', 'f1', 'accuracy', 'precision', 'recall']:\n",
        "        values = [m[metric] for m in metrics_by_class.values()]\n",
        "        macro_avg[metric] = np.mean(values)\n",
        "\n",
        "    return metrics_by_class, macro_avg\n",
        "\n",
        "# PatchCore\n",
        "pc_metrics_by_class, pc_macro = aggregate_image_metrics_across_classes(patchcore_results_shift)\n",
        "\n",
        "# PaDiM\n",
        "pd_metrics_by_class, pd_macro = aggregate_image_metrics_across_classes(padim_results_shift)\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"IMAGE-LEVEL METRICS (Test-Shift with Full Adaptation)\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Class':<12} {'Method':<10} {'AUROC':>8} {'AUPRC':>8} {'F1':>8} {'Acc':>8}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    pc_m = pc_metrics_by_class[class_name]\n",
        "    pd_m = pd_metrics_by_class[class_name]\n",
        "\n",
        "    print(f\"{class_name:<12} {'PatchCore':<10} {pc_m['auroc']:>8.4f} {pc_m['auprc']:>8.4f} {pc_m['f1']:>8.4f} {pc_m['accuracy']:>8.4f}\")\n",
        "    print(f\"{'':<12} {'PaDiM':<10} {pd_m['auroc']:>8.4f} {pd_m['auprc']:>8.4f} {pd_m['f1']:>8.4f} {pd_m['accuracy']:>8.4f}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "print(f\"{'MACRO AVG':<12} {'PatchCore':<10} {pc_macro['auroc']:>8.4f} {pc_macro['auprc']:>8.4f} {pc_macro['f1']:>8.4f} {pc_macro['accuracy']:>8.4f}\")\n",
        "print(f\"{'':<12} {'PaDiM':<10} {pd_macro['auroc']:>8.4f} {pd_macro['auprc']:>8.4f} {pd_macro['f1']:>8.4f} {pd_macro['accuracy']:>8.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save summary CSV\n",
        "summary_data = []\n",
        "for class_name in CLASSES:\n",
        "    pc_m = pc_metrics_by_class[class_name]\n",
        "    pd_m = pd_metrics_by_class[class_name]\n",
        "\n",
        "    summary_data.append({\n",
        "        'class': class_name,\n",
        "        'method': 'PatchCore',\n",
        "        'domain': 'shift',\n",
        "        'adaptation': 'full',\n",
        "        'auroc': pc_m['auroc'],\n",
        "        'auprc': pc_m['auprc'],\n",
        "        'f1': pc_m['f1'],\n",
        "        'accuracy': pc_m['accuracy'],\n",
        "        'precision': pc_m['precision'],\n",
        "        'recall': pc_m['recall']\n",
        "    })\n",
        "\n",
        "    summary_data.append({\n",
        "        'class': class_name,\n",
        "        'method': 'PaDiM',\n",
        "        'domain': 'shift',\n",
        "        'adaptation': 'full',\n",
        "        'auroc': pd_m['auroc'],\n",
        "        'auprc': pd_m['auprc'],\n",
        "        'f1': pd_m['f1'],\n",
        "        'accuracy': pd_m['accuracy'],\n",
        "        'precision': pd_m['precision'],\n",
        "        'recall': pd_m['recall']\n",
        "    })\n",
        "\n",
        "# Add macro averages\n",
        "summary_data.append({\n",
        "    'class': 'MACRO_AVG',\n",
        "    'method': 'PatchCore',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'auroc': pc_macro['auroc'],\n",
        "    'auprc': pc_macro['auprc'],\n",
        "    'f1': pc_macro['f1'],\n",
        "    'accuracy': pc_macro['accuracy'],\n",
        "    'precision': pc_macro['precision'],\n",
        "    'recall': pc_macro['recall']\n",
        "})\n",
        "\n",
        "summary_data.append({\n",
        "    'class': 'MACRO_AVG',\n",
        "    'method': 'PaDiM',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'auroc': pd_macro['auroc'],\n",
        "    'auprc': pd_macro['auprc'],\n",
        "    'f1': pd_macro['f1'],\n",
        "    'accuracy': pd_macro['accuracy'],\n",
        "    'precision': pd_macro['precision'],\n",
        "    'recall': pd_macro['recall']\n",
        "})\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_csv_path = RESULTS_DIR / 'shift_full_adaptation_results_summary.csv'\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "print(f\"\\n✓ Summary CSV saved to: {summary_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac1bcb2",
      "metadata": {
        "id": "6ac1bcb2"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# VISUALIZATION: Score Distributions & Calibrated Thresholds\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SCORE DISTRIBUTIONS & CALIBRATED THRESHOLDS (Val-shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "fig, axes = plt.subplots(len(CLASSES), 2, figsize=(14, 4*len(CLASSES)))\n",
        "\n",
        "# Handle single class case (axes would be 1D)\n",
        "if len(CLASSES) == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    # PatchCore\n",
        "    ax1 = axes[i, 0]\n",
        "    pc_data = calibration_data['patchcore'][class_name]\n",
        "    normal_scores = pc_data['scores'][pc_data['labels'] == 0]\n",
        "    anomalous_scores = pc_data['scores'][pc_data['labels'] == 1]\n",
        "\n",
        "    ax1.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue', edgecolor='black')\n",
        "    ax1.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red', edgecolor='black')\n",
        "    ax1.axvline(pc_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pc_data[\"threshold\"]:.2f}')\n",
        "    ax1.set_title(f'PatchCore - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Anomaly Score', fontsize=10)\n",
        "    ax1.set_ylabel('Count', fontsize=10)\n",
        "    ax1.legend(loc='upper right', fontsize=9)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # PaDiM\n",
        "    ax2 = axes[i, 1]\n",
        "    pd_data = calibration_data['padim'][class_name]\n",
        "    normal_scores = pd_data['scores'][pd_data['labels'] == 0]\n",
        "    anomalous_scores = pd_data['scores'][pd_data['labels'] == 1]\n",
        "\n",
        "    ax2.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue', edgecolor='black')\n",
        "    ax2.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red', edgecolor='black')\n",
        "    ax2.axvline(pd_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pd_data[\"threshold\"]:.2f}')\n",
        "    ax2.set_title(f'PaDiM - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlabel('Anomaly Score', fontsize=10)\n",
        "    ax2.set_ylabel('Count', fontsize=10)\n",
        "    ax2.legend(loc='upper right', fontsize=9)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Score Distributions & Calibrated Thresholds (Val-shift)',\n",
        "             fontsize=16, fontweight='bold', y=1.0)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "save_path = VIZ_DIR / 'score_distributions_shift_full_adaptation.png'\n",
        "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n[SAVED] {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10363fe",
      "metadata": {
        "id": "a10363fe"
      },
      "source": [
        "## 17. Visualize ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3fc468",
      "metadata": {
        "id": "1a3fc468"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating ROC curves...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for idx, class_name in enumerate(CLASSES):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # PatchCore\n",
        "    pc_scores = np.array(patchcore_results_shift[class_name]['predictions']['scores'])\n",
        "    pc_labels = np.array(patchcore_results_shift[class_name]['predictions']['labels'])\n",
        "    pc_fpr, pc_tpr, _ = compute_roc_curve(pc_labels, pc_scores)\n",
        "    pc_auroc = patchcore_results_shift[class_name]['image_metrics']['auroc']\n",
        "\n",
        "    # PaDiM\n",
        "    pd_scores = np.array(padim_results_shift[class_name]['predictions']['scores'])\n",
        "    pd_labels = np.array(padim_results_shift[class_name]['predictions']['labels'])\n",
        "    pd_fpr, pd_tpr, _ = compute_roc_curve(pd_labels, pd_scores)\n",
        "    pd_auroc = padim_results_shift[class_name]['image_metrics']['auroc']\n",
        "\n",
        "    # Plot\n",
        "    ax.plot(pc_fpr, pc_tpr, label=f'PatchCore (AUROC={pc_auroc:.3f})', linewidth=2)\n",
        "    ax.plot(pd_fpr, pd_tpr, label=f'PaDiM (AUROC={pd_auroc:.3f})', linewidth=2)\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
        "\n",
        "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "    ax.set_title(f'{class_name.capitalize()} - ROC Curve', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "roc_path = VIZ_DIR / 'roc_curves_shift_full_adaptation.png'\n",
        "plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ ROC curves saved to: {roc_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652af899",
      "metadata": {
        "id": "652af899"
      },
      "source": [
        "## 18. Visualize Precision-Recall Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b0300d",
      "metadata": {
        "id": "a5b0300d"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating Precision-Recall curves...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for idx, class_name in enumerate(CLASSES):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # PatchCore\n",
        "    pc_scores = np.array(patchcore_results_shift[class_name]['predictions']['scores'])\n",
        "    pc_labels = np.array(patchcore_results_shift[class_name]['predictions']['labels'])\n",
        "    pc_precision, pc_recall, _ = compute_pr_curve(pc_labels, pc_scores)\n",
        "    pc_auprc = patchcore_results_shift[class_name]['image_metrics']['auprc']\n",
        "\n",
        "    # PaDiM\n",
        "    pd_scores = np.array(padim_results_shift[class_name]['predictions']['scores'])\n",
        "    pd_labels = np.array(padim_results_shift[class_name]['predictions']['labels'])\n",
        "    pd_precision, pd_recall, _ = compute_pr_curve(pd_labels, pd_scores)\n",
        "    pd_auprc = padim_results_shift[class_name]['image_metrics']['auprc']\n",
        "\n",
        "    # Plot\n",
        "    ax.plot(pc_recall, pc_precision, label=f'PatchCore (AUPRC={pc_auprc:.3f})', linewidth=2)\n",
        "    ax.plot(pd_recall, pd_precision, label=f'PaDiM (AUPRC={pd_auprc:.3f})', linewidth=2)\n",
        "\n",
        "    # Random baseline (proportion of anomalies)\n",
        "    baseline = sum(pc_labels) / len(pc_labels)\n",
        "    ax.axhline(y=baseline, color='k', linestyle='--', label=f'Random (P={baseline:.2f})', linewidth=1)\n",
        "\n",
        "    ax.set_xlabel('Recall', fontsize=12)\n",
        "    ax.set_ylabel('Precision', fontsize=12)\n",
        "    ax.set_title(f'{class_name.capitalize()} - PR Curve', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower left')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "pr_path = VIZ_DIR / 'pr_curves_shift_full_adaptation.png'\n",
        "plt.savefig(pr_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ PR curves saved to: {pr_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e502fe2",
      "metadata": {
        "id": "6e502fe2"
      },
      "source": [
        "## 19. Visualize Sample Predictions with Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0114956",
      "metadata": {
        "id": "d0114956"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating sample predictions with heatmaps...\")\n",
        "\n",
        "def denormalize_image(img_tensor, mean, std):\n",
        "    \"\"\"Denormalize image for visualization.\"\"\"\n",
        "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    img = img * np.array(std) + np.array(mean)\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "# Select one class for detailed visualization\n",
        "class_name = 'hazelnut'  # Change to visualize other classes\n",
        "\n",
        "print(f\"\\nVisualizing predictions for: {class_name.upper()}\")\n",
        "\n",
        "# Load test-shift data for this class\n",
        "test_split = shifted_splits[class_name]['test']\n",
        "test_dataset = MVTecDataset.from_split(\n",
        "    test_split,\n",
        "    transform=transform,\n",
        "    phase='test'\n",
        ")\n",
        "\n",
        "# Get anomalous samples\n",
        "anomalous_indices = [i for i, l in enumerate(test_dataset.labels) if l == 1]\n",
        "\n",
        "# Select 6 random anomalous samples\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(anomalous_indices, min(6, len(anomalous_indices)), replace=False)\n",
        "\n",
        "# Get predictions\n",
        "patchcore_model = patchcore_models_shift[class_name]\n",
        "padim_model = padim_models_shift[class_name]\n",
        "\n",
        "fig, axes = plt.subplots(6, 4, figsize=(16, 24))\n",
        "\n",
        "for row_idx, sample_idx in enumerate(sample_indices):\n",
        "    image, mask, label, path = test_dataset[sample_idx]\n",
        "\n",
        "    # PatchCore prediction\n",
        "    with torch.no_grad():\n",
        "        pc_score, pc_heatmap = patchcore_model.predict(image.unsqueeze(0).to(DEVICE), return_heatmaps=True)\n",
        "        pc_score = pc_score[0].cpu().numpy()\n",
        "        pc_heatmap = pc_heatmap[0].cpu().numpy()\n",
        "\n",
        "    # PaDiM prediction\n",
        "    with torch.no_grad():\n",
        "        pd_score, pd_heatmap = padim_model.predict(image.unsqueeze(0).to(DEVICE))\n",
        "        pd_score = pd_score[0].cpu().numpy()\n",
        "        pd_heatmap = pd_heatmap[0].cpu().numpy()\n",
        "\n",
        "    # Denormalize image\n",
        "    img_vis = denormalize_image(image, config.dataset.normalize.mean, config.dataset.normalize.std)\n",
        "\n",
        "    # Plot\n",
        "    # Column 1: Original Image\n",
        "    axes[row_idx, 0].imshow(img_vis)\n",
        "    axes[row_idx, 0].set_title(f'Original\\nScore: {pc_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 0].axis('off')\n",
        "\n",
        "    # Column 2: Ground Truth Mask\n",
        "    if mask is not None:\n",
        "        axes[row_idx, 1].imshow(mask.squeeze(), cmap='gray')\n",
        "        axes[row_idx, 1].set_title('GT Mask', fontsize=10)\n",
        "    else:\n",
        "        axes[row_idx, 1].text(0.5, 0.5, 'No Mask', ha='center', va='center', fontsize=12)\n",
        "    axes[row_idx, 1].axis('off')\n",
        "\n",
        "    # Column 3: PatchCore Heatmap\n",
        "    axes[row_idx, 2].imshow(img_vis)\n",
        "    heatmap_overlay = axes[row_idx, 2].imshow(pc_heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[row_idx, 2].set_title(f'PatchCore\\nScore: {pc_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 2].axis('off')\n",
        "\n",
        "    # Column 4: PaDiM Heatmap\n",
        "    axes[row_idx, 3].imshow(img_vis)\n",
        "    axes[row_idx, 3].imshow(pd_heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[row_idx, 3].set_title(f'PaDiM\\nScore: {pd_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 3].axis('off')\n",
        "\n",
        "plt.suptitle(f'{class_name.capitalize()} - Sample Predictions (Test-Shift with Full Adaptation)',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "heatmap_path = VIZ_DIR / f'sample_predictions_{class_name}_shift_full_adaptation.png'\n",
        "plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ Sample predictions saved to: {heatmap_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d3a16d",
      "metadata": {
        "id": "85d3a16d"
      },
      "source": [
        "## 20. Final Summary and Comparison with Phase 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8b8b10",
      "metadata": {
        "id": "2c8b8b10"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PHASE 7 COMPLETE - FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey Achievements:\")\n",
        "print(\"  ✓ Re-trained PatchCore on Train-shift (all classes)\")\n",
        "print(\"  ✓ Re-trained PaDiM on Train-shift (all classes)\")\n",
        "print(\"  ✓ Calibrated thresholds on Val-shift (F1-optimal)\")\n",
        "print(\"  ✓ Evaluated on Test-shift with adapted models\")\n",
        "print(\"  ✓ Generated comprehensive visualizations\")\n",
        "print(\"\\nExpected Improvements over Phase 6 (No Adaptation):\")\n",
        "print(\"  • Image AUROC: ~15-20% improvement\")\n",
        "print(\"  • Pixel AUROC: ~15-20% improvement\")\n",
        "print(\"  • F1-Score: ~20-25% improvement\")\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"  • Compare results with Phase 6 (notebooks 07 & 08)\")\n",
        "print(\"  • Analyze performance recovery\")\n",
        "print(\"  • Identify remaining gaps and failure cases\")\n",
        "print(\"  • Generate final report tables\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print file locations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OUTPUT FILES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nModels:\")\n",
        "for class_name in CLASSES:\n",
        "    print(f\"  • patchcore_{class_name}_shift.npy\")\n",
        "    print(f\"  • patchcore_{class_name}_shift_config.pth\")\n",
        "    print(f\"  • padim_{class_name}_shift.pt\")\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "print(f\"  • {patchcore_results_path.name}\")\n",
        "print(f\"  • {padim_results_path.name}\")\n",
        "print(f\"  • {summary_csv_path.name}\")\n",
        "\n",
        "print(\"\\nThresholds:\")\n",
        "print(f\"  • {patchcore_thresholds_path.name}\")\n",
        "print(f\"  • {padim_thresholds_path.name}\")\n",
        "\n",
        "print(\"\\nVisualizations:\")\n",
        "print(f\"  • roc_curves_shift_full_adaptation.png\")\n",
        "print(f\"  • pr_curves_shift_full_adaptation.png\")\n",
        "print(f\"  • sample_predictions_*_shift_full_adaptation.png\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abf2a02",
      "metadata": {
        "id": "2abf2a02"
      },
      "source": [
        "\n",
        "**FILES GENERATED - PHASE 7: FULL SHIFT ADAPTATION**\n",
        "\n",
        "---\n",
        "\n",
        "### 📦 MODELS TRAINED ON TRAIN-SHIFT\n",
        "**Directory:** `outputs/models/`\n",
        "- `patchcore_<class>_shift.npy` — PatchCore memory bank\n",
        "- `patchcore_<class>_shift_config.pth` — PatchCore config\n",
        "- `padim_<class>_shift.pt` — PaDiM model (Gaussian distributions)\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 RESULTS & METRICS\n",
        "**Directory:** `outputs/results/`\n",
        "- `patchcore_shift_full_adaptation_results.json` — Complete PatchCore results (all metrics per class)\n",
        "- `padim_shift_full_adaptation_results.json` — Complete PaDiM results (all metrics per class)\n",
        "- `shift_full_adaptation_results_summary.csv` — Summary table with macro-averages\n",
        "- `patchcore_shift_training_stats.csv` — Training statistics for PatchCore\n",
        "- `padim_shift_training_stats.csv` — Training statistics for PaDiM\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 CALIBRATED THRESHOLDS\n",
        "**Directory:** `outputs/thresholds/`\n",
        "- `patchcore_shift_thresholds.json` — F1-optimal thresholds calibrated on Val-shift\n",
        "- `padim_shift_thresholds.json` — F1-optimal thresholds calibrated on Val-shift\n",
        "\n",
        "---\n",
        "\n",
        "### 📈 VISUALIZATIONS\n",
        "**Directory:** `outputs/visualizations/shifted_full_adaptation/`\n",
        "- `score_distributions_shift_full_adaptation.png` — Score distributions with thresholds for all classes\n",
        "- `roc_curves_shift_full_adaptation.png` — ROC curves comparing PatchCore vs PaDiM\n",
        "- `pr_curves_shift_full_adaptation.png` — Precision-Recall curves\n",
        "- `sample_predictions_<class>_shift_full_adaptation.png` — Heatmap overlays on anomalous samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f336e77",
      "metadata": {
        "id": "3f336e77"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# COPY ALL RESULTS TO GOOGLE DRIVE FOR PERSISTENCE\n",
        "# ============================================================\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Create destination folder in Drive\n",
        "DRIVE_ROOT = Path('/content/drive/MyDrive/anomaly_detection_project')\n",
        "PHASE7_OUTPUTS = DRIVE_ROOT / '09_full_shift_adaptation_outputs'\n",
        "PHASE7_OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COPYING FILES TO GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDestination: {PHASE7_OUTPUTS}\")\n",
        "\n",
        "# List of all generated files\n",
        "generated_files = []\n",
        "\n",
        "# Models\n",
        "print(\"\\n📦 Copying models...\")\n",
        "for class_name in CLASSES:\n",
        "    model_files = [\n",
        "        MODELS_DIR / f'patchcore_{class_name}_shift.npy',\n",
        "        MODELS_DIR / f'patchcore_{class_name}_shift_config.pth',\n",
        "        MODELS_DIR / f'padim_{class_name}_shift.pt'\n",
        "    ]\n",
        "    generated_files.extend(model_files)\n",
        "\n",
        "# Results\n",
        "print(\"📊 Copying results...\")\n",
        "result_files = [\n",
        "    RESULTS_DIR / 'patchcore_shift_full_adaptation_results.json',\n",
        "    RESULTS_DIR / 'padim_shift_full_adaptation_results.json',\n",
        "    RESULTS_DIR / 'shift_full_adaptation_results_summary.csv',\n",
        "    RESULTS_DIR / 'patchcore_shift_training_stats.csv',\n",
        "    RESULTS_DIR / 'padim_shift_training_stats.csv'\n",
        "]\n",
        "generated_files.extend(result_files)\n",
        "\n",
        "# Thresholds\n",
        "print(\"🎯 Copying thresholds...\")\n",
        "threshold_files = [\n",
        "    THRESHOLDS_DIR / 'patchcore_shift_thresholds.json',\n",
        "    THRESHOLDS_DIR / 'padim_shift_thresholds.json'\n",
        "]\n",
        "generated_files.extend(threshold_files)\n",
        "\n",
        "# Visualizations\n",
        "print(\"📈 Copying visualizations...\")\n",
        "viz_files = [\n",
        "    VIZ_DIR / 'score_distributions_shift_full_adaptation.png',\n",
        "    VIZ_DIR / 'roc_curves_shift_full_adaptation.png',\n",
        "    VIZ_DIR / 'pr_curves_shift_full_adaptation.png'\n",
        "]\n",
        "for class_name in CLASSES:\n",
        "    viz_files.append(VIZ_DIR / f'sample_predictions_{class_name}_shift_full_adaptation.png')\n",
        "generated_files.extend(viz_files)\n",
        "\n",
        "# Copy all files\n",
        "copied_count = 0\n",
        "missing_count = 0\n",
        "\n",
        "for src_path in generated_files:\n",
        "    if src_path.exists():\n",
        "        # Preserve directory structure\n",
        "        if 'models' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'models'\n",
        "        elif 'results' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'results'\n",
        "        elif 'thresholds' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'thresholds'\n",
        "        elif 'visualizations' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'visualizations'\n",
        "        else:\n",
        "            dst_dir = PHASE7_OUTPUTS\n",
        "\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        dst_path = dst_dir / src_path.name\n",
        "\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        print(f\"  ✓ {src_path.name}\")\n",
        "        copied_count += 1\n",
        "    else:\n",
        "        print(f\"  ✗ MISSING: {src_path.name}\")\n",
        "        missing_count += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ Copy complete: {copied_count} files copied, {missing_count} missing\")\n",
        "print(f\"✓ All results saved to: {PHASE7_OUTPUTS}\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}