{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b916144b",
      "metadata": {
        "id": "b916144b"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IvanNece/Detection-of-Anomalies-with-Localization/blob/main/notebooks/09_full_shift_adaptation.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9067020",
      "metadata": {
        "id": "f9067020"
      },
      "source": [
        "## 1. Setup - Mount Drive & Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d1337472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1337472",
        "outputId": "fbc042b1-74dd-448a-9470-53cabd97d851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Done!\n",
            "\n",
            "Cloning repository (branch: main)...\n",
            "Removing existing repository...\n",
            "Cloning into '/content/Detection-of-Anomalies-with-Localization'...\n",
            "remote: Enumerating objects: 821, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 821 (delta 0), reused 1 (delta 0), pack-reused 798 (from 2)\u001b[K\n",
            "Receiving objects: 100% (821/821), 312.75 MiB | 12.50 MiB/s, done.\n",
            "Resolving deltas: 100% (457/457), done.\n",
            "Updating files: 100% (105/105), done.\n",
            "Done!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SETUP COMPLETE - PHASE 7: FULL SHIFT ADAPTATION\n",
            "======================================================================\n",
            "Project:  /content/Detection-of-Anomalies-with-Localization\n",
            "Clean Dataset:  /content/drive/MyDrive/mvtec_ad\n",
            "Shifted Dataset: /content/drive/MyDrive/mvtec_shifted\n",
            "Branch:   main\n",
            "Models:   /content/Detection-of-Anomalies-with-Localization/outputs/models\n",
            "Results:  /content/Detection-of-Anomalies-with-Localization/outputs/results\n",
            "Thresholds: /content/Detection-of-Anomalies-with-Localization/outputs/thresholds\n",
            "Viz:      /content/Detection-of-Anomalies-with-Localization/outputs/visualizations/shifted_full_adaptation\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SETUP - Mount Google Drive & Clone Repository\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Clone repository on main branch\n",
        "print(\"Cloning repository (branch: main)...\")\n",
        "repo_dir = '/content/Detection-of-Anomalies-with-Localization'\n",
        "\n",
        "# Remove if exists\n",
        "if os.path.exists(repo_dir):\n",
        "    print(\"Removing existing repository...\")\n",
        "    !rm -rf {repo_dir}\n",
        "\n",
        "# Clone from main branch\n",
        "!git clone https://github.com/IvanNece/Detection-of-Anomalies-with-Localization.git {repo_dir}\n",
        "print(\"Done!\\n\")\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT = Path(repo_dir)\n",
        "\n",
        "# Dataset locations (both clean and shifted)\n",
        "CLEAN_DATASET_PATH = Path('/content/drive/MyDrive/mvtec_ad')\n",
        "SHIFTED_DATASET_PATH = Path('/content/drive/MyDrive/mvtec_shifted')\n",
        "\n",
        "# Output directories\n",
        "MODELS_DIR = PROJECT_ROOT / 'outputs' / 'models'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'outputs' / 'results'\n",
        "THRESHOLDS_DIR = PROJECT_ROOT / 'outputs' / 'thresholds'\n",
        "VIZ_DIR = PROJECT_ROOT / 'outputs' / 'visualizations' / 'shifted_full_adaptation'\n",
        "\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "THRESHOLDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify datasets exist\n",
        "if not CLEAN_DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Clean dataset not found at {CLEAN_DATASET_PATH}\\n\"\n",
        "        f\"Please ensure mvtec_ad folder is in your Google Drive.\"\n",
        "    )\n",
        "\n",
        "if not SHIFTED_DATASET_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Shifted dataset not found at {SHIFTED_DATASET_PATH}\\n\"\n",
        "        f\"Please run notebook 03_domain_shift_generation.ipynb first.\"\n",
        "    )\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE - PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project:  {PROJECT_ROOT}\")\n",
        "print(f\"Clean Dataset:  {CLEAN_DATASET_PATH}\")\n",
        "print(f\"Shifted Dataset: {SHIFTED_DATASET_PATH}\")\n",
        "print(f\"Branch:   main\")\n",
        "print(f\"Models:   {MODELS_DIR}\")\n",
        "print(f\"Results:  {RESULTS_DIR}\")\n",
        "print(f\"Thresholds: {THRESHOLDS_DIR}\")\n",
        "print(f\"Viz:      {VIZ_DIR}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abd03ce",
      "metadata": {
        "id": "4abd03ce"
      },
      "source": [
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d5b7286f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5b7286f",
        "outputId": "29936b3c-66eb-4648-a856-cec86c71980c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ FAISS installed successfully!\n",
            "  FAISS version: 1.13.1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# INSTALL FAISS - MUST BE DONE BEFORE IMPORTS!\n",
        "# ============================================================\n",
        "# FAISS speeds up coreset sampling by 10-100x\n",
        "\n",
        "!pip install faiss-cpu --quiet\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import faiss\n",
        "    print(\"✓ FAISS installed successfully!\")\n",
        "    print(f\"  FAISS version: {faiss.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"✗ FAISS installation failed, will use numpy fallback (VERY SLOW)\")\n",
        "    print(\"  Try running: !pip install faiss-cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9c58aea0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c58aea0",
        "outputId": "1a801c07-dff2-4753-e176-1253276ad7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing anomalib...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.8/851.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for freia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ Success! anomalib 2.2.0 installed\n",
            "  PaDiM components available\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# INSTALL ANOMALIB - REQUIRED FOR PADIM\n",
        "# ============================================================\n",
        "\n",
        "print(\"Installing anomalib...\")\n",
        "!pip install anomalib --quiet\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import anomalib\n",
        "    from anomalib.models.image.padim import Padim\n",
        "    from anomalib.models.image.padim.torch_model import PadimModel\n",
        "    print(f\"✓ Success! anomalib {anomalib.__version__} installed\")\n",
        "    print(\"  PaDiM components available\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Error: {e}\")\n",
        "    print(\"  Retry: !pip install anomalib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e7bfb6",
      "metadata": {
        "id": "47e7bfb6"
      },
      "source": [
        "## 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e580fd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e580fd4",
        "outputId": "bfa6c0cc-bac1-41a4-ee4e-a34e7bea1b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 42 for reproducibility\n",
            "Loaded configuration from /content/Detection-of-Anomalies-with-Localization/configs/experiment_config.yaml\n",
            "======================================================================\n",
            "PHASE 7: FULL SHIFT ADAPTATION\n",
            "======================================================================\n",
            "Using device: cpu\n",
            "Classes: ['hazelnut', 'carpet', 'zipper']\n",
            "Coreset ratio: 0.05\n",
            "Batch size: 8\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Project imports\n",
        "from src.utils.reproducibility import set_seed\n",
        "from src.utils.config import load_config\n",
        "from src.utils.paths import ProjectPaths\n",
        "from src.data.splitter import load_splits\n",
        "from src.data.dataset import MVTecDataset\n",
        "from src.data.transforms import get_shift_transforms\n",
        "from src.models.patchcore import PatchCore\n",
        "from src.models.padim_wrapper import PadimWrapper\n",
        "\n",
        "# Metrics imports\n",
        "from src.metrics import (\n",
        "    calibrate_threshold,\n",
        "    calibrate_threshold_with_curve,\n",
        "    ThresholdCalibrator,\n",
        "    compute_image_metrics,\n",
        "    compute_pixel_metrics,\n",
        "    compute_roc_curve,\n",
        "    compute_pr_curve,\n",
        "    compute_confusion_matrix,\n",
        "    aggregate_metrics,\n",
        "    aggregate_pixel_metrics\n",
        ")\n",
        "\n",
        "from src.evaluation import Evaluator, MultiClassEvaluator\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Load configuration\n",
        "config = load_config(PROJECT_ROOT / 'configs' / 'experiment_config.yaml')\n",
        "paths = ProjectPaths(PROJECT_ROOT)\n",
        "\n",
        "# Classes to process\n",
        "CLASSES = config.dataset.classes  # ['hazelnut', 'carpet', 'zipper']\n",
        "\n",
        "# Device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Classes: {CLASSES}\")\n",
        "print(f\"Coreset ratio: {config.patchcore.coreset_sampling_ratio}\")\n",
        "print(f\"Batch size: 8\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5736965",
      "metadata": {
        "id": "c5736965"
      },
      "source": [
        "## 4. Load Shifted Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d89826d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89826d8",
        "outputId": "be29ad49-f328-428f-fe36-cbc266110129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shifted Split Statistics:\n",
            "----------------------------------------------------------------------\n",
            "hazelnut:\n",
            "  Train-shift: 312 (all normal)\n",
            "  Val-shift: 100 (79 normal, 21 anomalous)\n",
            "  Test-shift: 89 (40 normal, 49 anomalous)\n",
            "carpet:\n",
            "  Train-shift: 224 (all normal)\n",
            "  Val-shift: 82 (56 normal, 26 anomalous)\n",
            "  Test-shift: 91 (28 normal, 63 anomalous)\n",
            "zipper:\n",
            "  Train-shift: 192 (all normal)\n",
            "  Val-shift: 83 (48 normal, 35 anomalous)\n",
            "  Test-shift: 116 (32 normal, 84 anomalous)\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Load shifted splits\n",
        "SHIFTED_SPLITS_PATH = paths.get_split_path('shifted')\n",
        "shifted_splits = load_splits(SHIFTED_SPLITS_PATH)\n",
        "\n",
        "# Print split statistics\n",
        "print(\"\\nShifted Split Statistics:\")\n",
        "print(\"-\" * 70)\n",
        "for class_name in CLASSES:\n",
        "    train_n = len(shifted_splits[class_name]['train']['images'])\n",
        "    val_n = len(shifted_splits[class_name]['val']['images'])\n",
        "    test_n = len(shifted_splits[class_name]['test']['images'])\n",
        "\n",
        "    val_normal = sum(1 for l in shifted_splits[class_name]['val']['labels'] if l == 0)\n",
        "    val_anom = sum(1 for l in shifted_splits[class_name]['val']['labels'] if l == 1)\n",
        "    test_normal = sum(1 for l in shifted_splits[class_name]['test']['labels'] if l == 0)\n",
        "    test_anom = sum(1 for l in shifted_splits[class_name]['test']['labels'] if l == 1)\n",
        "\n",
        "    print(f\"{class_name}:\")\n",
        "    print(f\"  Train-shift: {train_n} (all normal)\")\n",
        "    print(f\"  Val-shift: {val_n} ({val_normal} normal, {val_anom} anomalous)\")\n",
        "    print(f\"  Test-shift: {test_n} ({test_normal} normal, {test_anom} anomalous)\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca4cdf1",
      "metadata": {
        "id": "7ca4cdf1"
      },
      "source": [
        "## 5. Prepare Data Transforms and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f446dd7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f446dd7c",
        "outputId": "7ab645a8-72e0-420c-cc87-eacfcf444a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transform initialized:\n",
            "  Size: 224x224\n",
            "  Normalization: ImageNet statistics\n",
            "  Note: Domain shift already applied in pre-generated shifted dataset\n",
            "[OK] Custom collate function ready\n"
          ]
        }
      ],
      "source": [
        "# Create transform for shifted data (same as clean - no additional augmentation)\n",
        "# The domain shift is already \"baked\" into the shifted dataset images\n",
        "transform = get_shift_transforms(\n",
        "    image_size=config.dataset.image_size,\n",
        "    normalize_mean=config.dataset.normalize.mean,\n",
        "    normalize_std=config.dataset.normalize.std\n",
        ")\n",
        "\n",
        "print(f\"[OK] Transform initialized:\")\n",
        "print(f\"  Size: {config.dataset.image_size}x{config.dataset.image_size}\")\n",
        "print(f\"  Normalization: ImageNet statistics\")\n",
        "print(f\"  Note: Domain shift already applied in pre-generated shifted dataset\")\n",
        "\n",
        "# Custom collate function to handle None masks\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function that handles None masks.\"\"\"\n",
        "    images = torch.stack([item[0] for item in batch])\n",
        "    masks = [item[1] for item in batch]  # Keep as list (may contain None)\n",
        "    labels = torch.tensor([item[2] for item in batch])\n",
        "    paths = [item[3] for item in batch]\n",
        "    return images, masks, labels, paths\n",
        "\n",
        "print(\"[OK] Custom collate function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93996ae",
      "metadata": {
        "id": "e93996ae"
      },
      "source": [
        "---\n",
        "# PART A: PATCHCORE - FULL SHIFT ADAPTATION\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de3c557",
      "metadata": {
        "id": "6de3c557"
      },
      "source": [
        "## 6. Re-train PatchCore on Train-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "46f696c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46f696c1",
        "outputId": "369c6019-fa3d-4f0d-f67c-17883dd245ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - TRAINING ON TRAIN-SHIFT\n",
            "======================================================================\n",
            "Coreset ratio: 5.0%\n",
            "Batch size: 8\n",
            "Num workers: 0\n",
            "Image size: 224\n",
            "Backbone layers: ['layer2', 'layer3']\n",
            "Patch size: 3\n",
            "N neighbors: 9\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "CORESET_RATIO = config.patchcore.coreset_sampling_ratio\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 0  # Set to 0 for Colab\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - TRAINING ON TRAIN-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Coreset ratio: {CORESET_RATIO*100:.1f}%\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Num workers: {NUM_WORKERS}\")\n",
        "print(f\"Image size: {config.dataset.image_size}\")\n",
        "print(f\"Backbone layers: {config.patchcore.layers}\")\n",
        "print(f\"Patch size: {config.patchcore.patch_size}\")\n",
        "print(f\"N neighbors: {config.patchcore.n_neighbors}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0cd52c40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd52c40",
        "outputId": "37175609-3be5-4b31-d641-d334e896a708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: HAZELNUT\n",
            "======================================================================\n",
            "\n",
            "✓ Model files found! Loading existing model...\n",
            "  • patchcore_hazelnut_shift.npy\n",
            "  • patchcore_hazelnut_shift_config.pth\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 142MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using FAISS for fast k-NN search (memory bank: 12230 samples, 1536 dims)\n",
            "  Memory bank size: 12230\n",
            "  Spatial dims: (28, 28)\n",
            "  [SKIPPED TRAINING - Using cached model]\n",
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: CARPET\n",
            "======================================================================\n",
            "\n",
            "✓ Model files found! Loading existing model...\n",
            "  • patchcore_carpet_shift.npy\n",
            "  • patchcore_carpet_shift_config.pth\n",
            "✓ Using FAISS for fast k-NN search (memory bank: 8780 samples, 1536 dims)\n",
            "  Memory bank size: 8780\n",
            "  Spatial dims: (28, 28)\n",
            "  [SKIPPED TRAINING - Using cached model]\n",
            "\n",
            "======================================================================\n",
            "Training PatchCore on TRAIN-SHIFT: ZIPPER\n",
            "======================================================================\n",
            "\n",
            "✓ Model files found! Loading existing model...\n",
            "  • patchcore_zipper_shift.npy\n",
            "  • patchcore_zipper_shift_config.pth\n",
            "✓ Using FAISS for fast k-NN search (memory bank: 7526 samples, 1536 dims)\n",
            "  Memory bank size: 7526\n",
            "  Spatial dims: (28, 28)\n",
            "  [SKIPPED TRAINING - Using cached model]\n",
            "\n",
            "======================================================================\n",
            "✓ All PatchCore models ready!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train PatchCore models on shifted data\n",
        "patchcore_models_shift = {}\n",
        "patchcore_training_stats_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"Training PatchCore on TRAIN-SHIFT: {class_name.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Check if model files already exist\n",
        "    model_file = paths.MODELS / f'patchcore_{class_name}_shift.npy'\n",
        "    config_file = paths.MODELS / f'patchcore_{class_name}_shift_config.pth'\n",
        "\n",
        "    if model_file.exists() and config_file.exists():\n",
        "        print(f\"\\n✓ Model files found! Loading existing model...\")\n",
        "        print(f\"  • {model_file.name}\")\n",
        "        print(f\"  • {config_file.name}\")\n",
        "\n",
        "        # Load existing model\n",
        "        model = PatchCore(\n",
        "            backbone_layers=config.patchcore.layers,\n",
        "            patch_size=config.patchcore.patch_size,\n",
        "            coreset_ratio=CORESET_RATIO,\n",
        "            n_neighbors=config.patchcore.n_neighbors,\n",
        "            device=DEVICE\n",
        "        )\n",
        "        model.load(paths.MODELS, class_name, domain='shift')\n",
        "\n",
        "        # Load training stats from config file\n",
        "        checkpoint = torch.load(config_file, map_location=DEVICE)\n",
        "        patchcore_training_stats_shift[class_name] = {\n",
        "            'n_train_images': checkpoint.get('n_train_images', 'N/A'),\n",
        "            'memory_bank_size': len(model.memory_bank),\n",
        "            'training_time_seconds': checkpoint.get('training_time_seconds', 'N/A'),\n",
        "            'spatial_dims': model.spatial_dims\n",
        "        }\n",
        "\n",
        "        print(f\"  Memory bank size: {len(model.memory_bank)}\")\n",
        "        print(f\"  Spatial dims: {model.spatial_dims}\")\n",
        "        print(\"  [SKIPPED TRAINING - Using cached model]\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n⚠ Model files not found. Starting training from scratch...\")\n",
        "\n",
        "        # Create train dataset (only normal images from shifted data)\n",
        "        train_split = shifted_splits[class_name]['train']\n",
        "        train_dataset = MVTecDataset.from_split(\n",
        "            train_split,\n",
        "            transform=transform,\n",
        "            phase='train'\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "            pin_memory=False,\n",
        "            collate_fn=custom_collate_fn\n",
        "        )\n",
        "\n",
        "        print(f\"\\nTrain-shift dataset: {len(train_dataset)} images\")\n",
        "\n",
        "        # Initialize PatchCore\n",
        "        model = PatchCore(\n",
        "            backbone_layers=config.patchcore.layers,\n",
        "            patch_size=config.patchcore.patch_size,\n",
        "            coreset_ratio=CORESET_RATIO,\n",
        "            n_neighbors=config.patchcore.n_neighbors,\n",
        "            device=DEVICE\n",
        "        )\n",
        "\n",
        "        # Fit model\n",
        "        start_time = time.time()\n",
        "        model.fit(train_loader, apply_coreset=True)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Save model with 'shift' domain tag\n",
        "        model.save(paths.MODELS, class_name, domain='shift')\n",
        "\n",
        "        # Store statistics\n",
        "        patchcore_training_stats_shift[class_name] = {\n",
        "            'n_train_images': len(train_dataset),\n",
        "            'memory_bank_size': len(model.memory_bank),\n",
        "            'training_time_seconds': training_time,\n",
        "            'spatial_dims': model.spatial_dims\n",
        "        }\n",
        "\n",
        "        print(f\"\\nCompleted {class_name.upper()}:\")\n",
        "        print(f\"  Memory bank size: {len(model.memory_bank)}\")\n",
        "        print(f\"  Training time: {training_time:.2f}s\")\n",
        "        print(f\"  Spatial dims: {model.spatial_dims}\")\n",
        "\n",
        "    # Store model in dictionary\n",
        "    patchcore_models_shift[class_name] = model\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ All PatchCore models ready!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cdeddc",
      "metadata": {
        "id": "d6cdeddc"
      },
      "source": [
        "## 7. PatchCore - Predict on Val-Shift for Threshold Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e5d1143e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5d1143e",
        "outputId": "b18a817e-4167-42e1-d1b1-54cac6b46124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - PREDICTING ON VAL-SHIFT\n",
            "======================================================================\n",
            "\n",
            "Processing HAZELNUT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift hazelnut: 100%|██████████| 13/13 [02:59<00:00, 13.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 100 samples\n",
            "  Normal: 79, Anomalous: 21\n",
            "\n",
            "Processing CARPET...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift carpet: 100%|██████████| 11/11 [02:27<00:00, 13.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 82 samples\n",
            "  Normal: 56, Anomalous: 26\n",
            "\n",
            "Processing ZIPPER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val-shift zipper: 100%|██████████| 11/11 [02:35<00:00, 14.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Val-shift predictions: 83 samples\n",
            "  Normal: 48, Anomalous: 35\n",
            "\n",
            "✓ PatchCore val-shift predictions complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - PREDICTING ON VAL-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_val_predictions_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\nProcessing {class_name.upper()}...\")\n",
        "\n",
        "    model = patchcore_models_shift[class_name]\n",
        "\n",
        "    # Load val-shift data\n",
        "    val_split = shifted_splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f\"Val-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images, return_heatmaps=True)\n",
        "            # Fix: Remove .numpy() as scores is already a numpy array after model.predict()\n",
        "            all_scores.extend(scores)\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    patchcore_val_predictions_shift[class_name] = {\n",
        "        'scores': all_scores,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "    print(f\"  Val-shift predictions: {len(all_scores)} samples\")\n",
        "    print(f\"  Normal: {sum(1 for l in all_labels if l == 0)}, Anomalous: {sum(1 for l in all_labels if l == 1)}\")\n",
        "\n",
        "print(\"\\n✓ PatchCore val-shift predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09800dbf",
      "metadata": {
        "id": "09800dbf"
      },
      "source": [
        "## 8. PatchCore - Calibrate Thresholds on Val-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f5287624",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5287624",
        "outputId": "dd2191e9-ddd0-4aa5-83cf-cc1a60dcb745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\n",
            "======================================================================\n",
            "\n",
            "✓ Threshold file found! Loading existing thresholds...\n",
            "  • patchcore_shift_thresholds.json\n",
            "\n",
            "Loaded thresholds:\n",
            "  hazelnut: 425.5469\n",
            "  carpet: 241.7909\n",
            "  zipper: 221.6002\n",
            "[OK] Thresholds saved: patchcore_shift_thresholds.json\n",
            "  [Thresholds normalized and saved]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_thresholds_path = THRESHOLDS_DIR / 'patchcore_shift_thresholds.json'\n",
        "\n",
        "# Check if thresholds already exist\n",
        "if patchcore_thresholds_path.exists():\n",
        "    print(f\"\\n✓ Threshold file found! Loading existing thresholds...\")\n",
        "    print(f\"  • {patchcore_thresholds_path.name}\")\n",
        "\n",
        "    # Load raw JSON to inspect\n",
        "    with open(patchcore_thresholds_path, 'r') as f:\n",
        "        threshold_data = json.load(f)\n",
        "\n",
        "    # Check if thresholds dict exists and has data\n",
        "    if 'thresholds' in threshold_data and len(threshold_data['thresholds']) > 0:\n",
        "        patchcore_calibrator_shift = ThresholdCalibrator('patchcore_shift')\n",
        "\n",
        "        # Map class names (case-insensitive)\n",
        "        saved_thresholds = threshold_data['thresholds']\n",
        "\n",
        "        # Try to match class names\n",
        "        for class_name in CLASSES:\n",
        "            # Try exact match first\n",
        "            if class_name in saved_thresholds:\n",
        "                patchcore_calibrator_shift.thresholds[class_name] = saved_thresholds[class_name]\n",
        "            # Try case-insensitive match\n",
        "            elif class_name.lower() in [k.lower() for k in saved_thresholds.keys()]:\n",
        "                matching_key = [k for k in saved_thresholds.keys() if k.lower() == class_name.lower()][0]\n",
        "                patchcore_calibrator_shift.thresholds[class_name] = saved_thresholds[matching_key]\n",
        "                print(f\"  ⚠ Remapped '{matching_key}' → '{class_name}'\")\n",
        "            else:\n",
        "                print(f\"  ✗ Missing threshold for '{class_name}', will recalibrate\")\n",
        "                # Recalibrate this class\n",
        "                scores = np.array(patchcore_val_predictions_shift[class_name]['scores'])\n",
        "                labels = np.array(patchcore_val_predictions_shift[class_name]['labels'])\n",
        "                threshold = patchcore_calibrator_shift.calibrate(class_name, scores, labels)\n",
        "                print(f\"    → New threshold: {threshold:.4f}\")\n",
        "\n",
        "        print(\"\\nLoaded thresholds:\")\n",
        "        for class_name in CLASSES:\n",
        "            threshold = patchcore_calibrator_shift.get_threshold(class_name)\n",
        "            print(f\"  {class_name}: {threshold:.4f}\")\n",
        "\n",
        "        # Re-save with correct keys\n",
        "        patchcore_calibrator_shift.save(patchcore_thresholds_path)\n",
        "        print(f\"  [Thresholds normalized and saved]\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ Threshold file is empty or invalid, recalibrating...\")\n",
        "        raise ValueError(\"Empty thresholds, skip to else block\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n⚠ Threshold file not found. Starting calibration from scratch...\")\n",
        "\n",
        "    patchcore_calibrator_shift = ThresholdCalibrator('patchcore_shift')\n",
        "\n",
        "    for class_name in CLASSES:\n",
        "        print(f\"\\n{class_name.upper()}:\")\n",
        "\n",
        "        scores = np.array(patchcore_val_predictions_shift[class_name]['scores'])\n",
        "        labels = np.array(patchcore_val_predictions_shift[class_name]['labels'])\n",
        "\n",
        "        threshold = patchcore_calibrator_shift.calibrate(class_name, scores, labels)\n",
        "\n",
        "        print(f\"  Optimal threshold: {threshold:.4f}\")\n",
        "        print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
        "\n",
        "    # Save thresholds\n",
        "    patchcore_calibrator_shift.save(patchcore_thresholds_path)\n",
        "    print(f\"\\n✓ PatchCore thresholds saved to: {patchcore_thresholds_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdc8dc3",
      "metadata": {
        "id": "ffdc8dc3"
      },
      "source": [
        "## 9. PatchCore - Evaluate on Test-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "303dff74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "303dff74",
        "outputId": "c835ece2-a7af-4fca-f9f4-a960463576fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PATCHCORE - EVALUATION ON TEST-SHIFT\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Evaluating HAZELNUT\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test-shift hazelnut: 100%|██████████| 12/12 [01:09<00:00,  5.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HAZELNUT - Results:\n",
            "  Image AUROC: 0.9602\n",
            "  Image AUPRC: 0.9771\n",
            "  F1-Score: 0.9167\n",
            "  Accuracy: 0.9101\n",
            "  Pixel AUROC: 0.9633\n",
            "  PRO-Score: 0.7374\n",
            "\n",
            "======================================================================\n",
            "Evaluating CARPET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test-shift carpet: 100%|██████████| 12/12 [01:28<00:00,  7.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CARPET - Results:\n",
            "  Image AUROC: 0.8679\n",
            "  Image AUPRC: 0.9475\n",
            "  F1-Score: 0.8036\n",
            "  Accuracy: 0.7582\n",
            "  Pixel AUROC: 0.9312\n",
            "  PRO-Score: 0.6251\n",
            "\n",
            "======================================================================\n",
            "Evaluating ZIPPER\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test-shift zipper: 100%|██████████| 15/15 [03:58<00:00, 15.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ZIPPER - Results:\n",
            "  Image AUROC: 0.8251\n",
            "  Image AUPRC: 0.9230\n",
            "  F1-Score: 0.8050\n",
            "  Accuracy: 0.7328\n",
            "  Pixel AUROC: 0.9113\n",
            "  PRO-Score: 0.5566\n",
            "\n",
            "======================================================================\n",
            "✓ PatchCore evaluation on TEST-SHIFT complete!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PATCHCORE - EVALUATION ON TEST-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "patchcore_results_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating {class_name.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    model = patchcore_models_shift[class_name]\n",
        "    threshold = patchcore_calibrator_shift.get_threshold(class_name)\n",
        "\n",
        "    # Load test-shift data\n",
        "    test_split = shifted_splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_heatmaps = []\n",
        "    all_labels = []\n",
        "    all_masks = []\n",
        "    all_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f\"Test-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images, return_heatmaps=True)\n",
        "\n",
        "            all_scores.extend(scores.tolist())\n",
        "            all_heatmaps.extend(heatmaps.tolist())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_masks.extend(masks)\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    all_scores = np.array(all_scores)\n",
        "    all_heatmaps = np.array(all_heatmaps)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Image-level metrics\n",
        "    image_metrics = compute_image_metrics(\n",
        "        all_labels,\n",
        "        all_scores,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    # Pixel-level metrics (only for anomalous images with masks)\n",
        "    pixel_metrics = None\n",
        "    anomalous_indices = [i for i, l in enumerate(all_labels) if l == 1]\n",
        "    if len(anomalous_indices) > 0:\n",
        "        masks_true = []\n",
        "        heatmaps_pred = []\n",
        "\n",
        "        for i in anomalous_indices:\n",
        "            mask = all_masks[i]\n",
        "            if mask is not None:\n",
        "                # FIX: Convert to numpy and squeeze to remove channel dimension\n",
        "                if isinstance(mask, torch.Tensor):\n",
        "                    mask_np = mask.cpu().numpy().squeeze()  # (1, H, W) → (H, W)\n",
        "                else:\n",
        "                    mask_np = np.array(mask).squeeze()\n",
        "\n",
        "                masks_true.append(mask_np)\n",
        "                heatmaps_pred.append(all_heatmaps[i])\n",
        "\n",
        "        if len(masks_true) > 0:\n",
        "            pixel_metrics = compute_pixel_metrics(masks_true, heatmaps_pred)\n",
        "\n",
        "    patchcore_results_shift[class_name] = {\n",
        "        'image_metrics': image_metrics,\n",
        "        'pixel_metrics': pixel_metrics,\n",
        "        'threshold': threshold,\n",
        "        'n_test_samples': len(all_labels),\n",
        "        'n_anomalous': sum(all_labels),\n",
        "        'predictions': {\n",
        "            'scores': all_scores.tolist(),\n",
        "            'labels': all_labels.tolist(),\n",
        "            'paths': all_paths\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{class_name.upper()} - Results:\")\n",
        "    print(f\"  Image AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  Image AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1-Score: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics['accuracy']:.4f}\")\n",
        "    if pixel_metrics:\n",
        "        if pixel_metrics['pixel_auroc'] is not None:\n",
        "            print(f\"  Pixel AUROC: {pixel_metrics['pixel_auroc']:.4f}\")\n",
        "        else:\n",
        "            print(f\"  Pixel AUROC: Not Computed (Mask/Heatmap shape mismatch)\")\n",
        "        print(f\"  PRO-Score: {pixel_metrics['pro']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ PatchCore evaluation on TEST-SHIFT complete!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a773af84",
      "metadata": {
        "id": "a773af84"
      },
      "source": [
        "## 10. Save PatchCore Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fbc15a1f",
      "metadata": {
        "id": "fbc15a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85413a35-146f-4430-94d8-d168909e290c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ PatchCore results saved to: /content/Detection-of-Anomalies-with-Localization/outputs/results/patchcore_shift_full_adaptation_results.json\n",
            "✓ Training stats saved to: /content/Detection-of-Anomalies-with-Localization/outputs/results/patchcore_shift_training_stats.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def convert_numpy_types(obj):\n",
        "    \"\"\"Recursively convert numpy types to Python native types for JSON serialization.\"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_numpy_types(item) for item in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# Prepare results summary\n",
        "patchcore_summary_shift = {\n",
        "    'method': 'PatchCore',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': {\n",
        "        'coreset_ratio': float(CORESET_RATIO),  # Convert to native Python float\n",
        "        'backbone_layers': config.patchcore.layers,\n",
        "        'n_neighbors': int(config.patchcore.n_neighbors)  # Convert to native Python int\n",
        "    },\n",
        "    'training_statistics': convert_numpy_types(patchcore_training_stats_shift),\n",
        "    'validation_predictions': convert_numpy_types(patchcore_val_predictions_shift),\n",
        "    'test_results': convert_numpy_types(patchcore_results_shift)\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "patchcore_results_path = RESULTS_DIR / 'patchcore_shift_full_adaptation_results.json'\n",
        "with open(patchcore_results_path, 'w') as f:\n",
        "    json.dump(patchcore_summary_shift, f, indent=2)\n",
        "\n",
        "print(f\"✓ PatchCore results saved to: {patchcore_results_path}\")\n",
        "\n",
        "# Save training stats as CSV\n",
        "import pandas as pd\n",
        "patchcore_stats_df = pd.DataFrame(patchcore_training_stats_shift).T\n",
        "patchcore_stats_df['training_time_seconds'] = patchcore_stats_df['training_time_seconds'].apply(\n",
        "    lambda x: f\"{float(x):.2f}\" if isinstance(x, (int, float, np.number)) else x\n",
        ")\n",
        "patchcore_stats_csv = RESULTS_DIR / 'patchcore_shift_training_stats.csv'\n",
        "patchcore_stats_df.to_csv(patchcore_stats_csv)\n",
        "print(f\"✓ Training stats saved to: {patchcore_stats_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ae76cc",
      "metadata": {
        "id": "d5ae76cc"
      },
      "source": [
        "---\n",
        "# PART B: PADIM - FULL SHIFT ADAPTATION\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ffaffa",
      "metadata": {
        "id": "71ffaffa"
      },
      "source": [
        "## 11. Re-train PaDiM on Train-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd572a1",
      "metadata": {
        "id": "cdd572a1"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - TRAINING ON TRAIN-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Backbone: {config.padim.backbone}\")\n",
        "print(f\"Layers: {config.padim.layers}\")\n",
        "print(f\"N features: {config.padim.n_features}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ad63db",
      "metadata": {
        "id": "e8ad63db"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train PaDiM models on shifted data\n",
        "padim_models_shift = {}\n",
        "padim_training_stats_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"Training PaDiM on TRAIN-SHIFT: {class_name.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Check if model file already exists\n",
        "    model_path = MODELS_DIR / f\"padim_{class_name}_shift.pt\"\n",
        "\n",
        "    if model_path.exists():\n",
        "        print(f\"\\n✓ Model file found! Loading existing model...\")\n",
        "        print(f\"  • {model_path.name}\")\n",
        "\n",
        "        # Load existing model\n",
        "        model = PadimWrapper(\n",
        "            backbone=config.padim.backbone,\n",
        "            layers=config.padim.layers,\n",
        "            n_features=config.padim.n_features,\n",
        "            image_size=config.dataset.image_size,\n",
        "            device=DEVICE\n",
        "        )\n",
        "        model.load(model_path)\n",
        "\n",
        "        # Extract training stats from loaded model\n",
        "        padim_training_stats_shift[class_name] = {\n",
        "            'n_train_images': model.training_stats.get('num_samples', 'N/A'),\n",
        "            'training_time_seconds': model.training_stats.get('training_time_seconds', 'N/A'),\n",
        "            'memory_bank_size_mb': model.training_stats.get('memory_bank_size_mb', 'N/A')\n",
        "        }\n",
        "\n",
        "        print(f\"  Training samples: {model.training_stats.get('num_samples', 'N/A')}\")\n",
        "        print(f\"  Training time: {model.training_stats.get('training_time_seconds', 'N/A'):.2f}s\")\n",
        "        print(\"  [SKIPPED TRAINING - Using cached model]\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n⚠ Model file not found. Starting training from scratch...\")\n",
        "\n",
        "        # Create train dataset\n",
        "        train_split = shifted_splits[class_name]['train']\n",
        "        train_dataset = MVTecDataset.from_split(\n",
        "            train_split,\n",
        "            transform=transform,\n",
        "            phase='train'\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "            pin_memory=False,\n",
        "            collate_fn=custom_collate_fn\n",
        "        )\n",
        "\n",
        "        print(f\"\\nTrain-shift dataset: {len(train_dataset)} images\")\n",
        "\n",
        "        # Initialize PaDiM\n",
        "        model = PadimWrapper(\n",
        "            backbone=config.padim.backbone,\n",
        "            layers=config.padim.layers,\n",
        "            n_features=config.padim.n_features,\n",
        "            image_size=config.dataset.image_size,\n",
        "            device=DEVICE\n",
        "        )\n",
        "\n",
        "        # Train (fit on normal samples)\n",
        "        model.fit(train_loader, verbose=True)\n",
        "\n",
        "        # Save model with 'shift' domain tag\n",
        "        model.save(model_path, include_stats=True)\n",
        "\n",
        "        # Store statistics\n",
        "        padim_training_stats_shift[class_name] = {\n",
        "            'n_train_images': model.training_stats['num_samples'],\n",
        "            'training_time_seconds': model.training_stats['training_time_seconds'],\n",
        "            'memory_bank_size_mb': model.training_stats['memory_bank_size_mb']\n",
        "        }\n",
        "\n",
        "        print(f\"\\nCompleted {class_name.upper()}:\")\n",
        "        print(f\"  Model: {model_path.name}\")\n",
        "        print(f\"  Training time: {model.training_stats['training_time_seconds']:.2f}s\")\n",
        "\n",
        "    # Store model in dictionary\n",
        "    padim_models_shift[class_name] = model\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ All PaDiM models ready!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec80870",
      "metadata": {
        "id": "2ec80870"
      },
      "source": [
        "## 12. PaDiM - Predict on Val-Shift for Threshold Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6583bc11",
      "metadata": {
        "id": "6583bc11"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - PREDICTING ON VAL-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_val_predictions_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\nProcessing {class_name.upper()}...\")\n",
        "\n",
        "    model = padim_models_shift[class_name]\n",
        "\n",
        "    # Load val-shift data\n",
        "    val_split = shifted_splits[class_name]['val']\n",
        "    val_dataset = MVTecDataset.from_split(\n",
        "        val_split,\n",
        "        transform=transform,\n",
        "        phase='val'\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(val_loader, desc=f\"Val-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, _ = model.predict(images)\n",
        "            all_scores.extend(scores.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    padim_val_predictions_shift[class_name] = {\n",
        "        'scores': all_scores,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "    print(f\"  Val-shift predictions: {len(all_scores)} samples\")\n",
        "    print(f\"  Normal: {sum(1 for l in all_labels if l == 0)}, Anomalous: {sum(1 for l in all_labels if l == 1)}\")\n",
        "\n",
        "print(\"\\n✓ PaDiM val-shift predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80563f6b",
      "metadata": {
        "id": "80563f6b"
      },
      "source": [
        "## 13. PaDiM - Calibrate Thresholds on Val-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b666b2",
      "metadata": {
        "id": "44b666b2"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - THRESHOLD CALIBRATION (F1-Optimal on Val-Shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_calibrator_shift = ThresholdCalibrator('padim_shift')\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{class_name.upper()}:\")\n",
        "\n",
        "    scores = np.array(padim_val_predictions_shift[class_name]['scores'])\n",
        "    labels = np.array(padim_val_predictions_shift[class_name]['labels'])\n",
        "\n",
        "    threshold = padim_calibrator_shift.calibrate(class_name, scores, labels)\n",
        "\n",
        "    print(f\"  Optimal threshold: {threshold:.4f}\")\n",
        "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
        "\n",
        "# Save thresholds\n",
        "padim_thresholds_path = THRESHOLDS_DIR / 'padim_shift_thresholds.json'\n",
        "padim_calibrator_shift.save(padim_thresholds_path)\n",
        "print(f\"\\n✓ PaDiM thresholds saved to: {padim_thresholds_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db127008",
      "metadata": {
        "id": "db127008"
      },
      "source": [
        "## 14. PaDiM - Evaluate on Test-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf887e79",
      "metadata": {
        "id": "bf887e79"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PADIM - EVALUATION ON TEST-SHIFT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "padim_results_shift = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating {class_name.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    model = padim_models_shift[class_name]\n",
        "    threshold = padim_calibrator_shift.get_threshold(class_name)\n",
        "\n",
        "    # Load test-shift data\n",
        "    test_split = shifted_splits[class_name]['test']\n",
        "    test_dataset = MVTecDataset.from_split(\n",
        "        test_split,\n",
        "        transform=transform,\n",
        "        phase='test'\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=False,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    all_scores = []\n",
        "    all_heatmaps = []\n",
        "    all_labels = []\n",
        "    all_masks = []\n",
        "    all_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels, paths in tqdm(test_loader, desc=f\"Test-shift {class_name}\"):\n",
        "            images = images.to(DEVICE)\n",
        "            scores, heatmaps = model.predict(images)\n",
        "\n",
        "            all_scores.extend(scores.cpu().numpy())\n",
        "            all_heatmaps.extend(heatmaps.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_masks.extend(masks)\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    all_scores = np.array(all_scores)\n",
        "    all_heatmaps = np.array(all_heatmaps)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Image-level metrics\n",
        "    image_metrics = compute_image_metrics(\n",
        "        y_true=all_labels,\n",
        "        y_scores=all_scores,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    # Pixel-level metrics\n",
        "    pixel_metrics = None\n",
        "    anomalous_indices = [i for i, l in enumerate(all_labels) if l == 1]\n",
        "    if len(anomalous_indices) > 0:\n",
        "        masks_true = []\n",
        "        heatmaps_pred = []\n",
        "\n",
        "        for i in anomalous_indices:\n",
        "            mask = all_masks[i]\n",
        "            if mask is not None:\n",
        "                # FIX: Convert to numpy and squeeze to remove channel dimension\n",
        "                if isinstance(mask, torch.Tensor):\n",
        "                    mask_np = mask.cpu().numpy().squeeze()  # (1, H, W) → (H, W)\n",
        "                else:\n",
        "                    mask_np = np.array(mask).squeeze()\n",
        "\n",
        "                masks_true.append(mask_np)\n",
        "                heatmaps_pred.append(all_heatmaps[i])\n",
        "\n",
        "        if len(masks_true) > 0:\n",
        "            pixel_metrics = compute_pixel_metrics(masks_true, heatmaps_pred)\n",
        "\n",
        "    padim_results_shift[class_name] = {\n",
        "        'image_metrics': image_metrics,\n",
        "        'pixel_metrics': pixel_metrics,\n",
        "        'threshold': threshold,\n",
        "        'n_test_samples': len(all_labels),\n",
        "        'n_anomalous': sum(all_labels),\n",
        "        'predictions': {\n",
        "            'scores': all_scores.tolist(),\n",
        "            'labels': all_labels.tolist(),\n",
        "            'paths': all_paths\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{class_name.upper()} - Results:\")\n",
        "    print(f\"  Image AUROC: {image_metrics['auroc']:.4f}\")\n",
        "    print(f\"  Image AUPRC: {image_metrics['auprc']:.4f}\")\n",
        "    print(f\"  F1-Score: {image_metrics['f1']:.4f}\")\n",
        "    print(f\"  Accuracy: {image_metrics['accuracy']:.4f}\")\n",
        "    if pixel_metrics:\n",
        "        print(f\"  Pixel AUROC: {pixel_metrics['pixel_auroc']:.4f}\")\n",
        "        print(f\"  PRO-Score: {pixel_metrics['pro_score']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ PaDiM evaluation on TEST-SHIFT complete!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416858f2",
      "metadata": {
        "id": "416858f2"
      },
      "source": [
        "## 15. Save PaDiM Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8c5eb3",
      "metadata": {
        "id": "8a8c5eb3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Prepare results summary (riusa la funzione convert_numpy_types già definita)\n",
        "padim_summary_shift = {\n",
        "    'method': 'PaDiM',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': {\n",
        "        'backbone': config.padim.backbone,\n",
        "        'layers': config.padim.layers,\n",
        "        'n_features': int(config.padim.n_features)  # Convert to native Python int\n",
        "    },\n",
        "    'training_statistics': convert_numpy_types(padim_training_stats_shift),\n",
        "    'validation_predictions': convert_numpy_types(padim_val_predictions_shift),\n",
        "    'test_results': convert_numpy_types(padim_results_shift)\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "padim_results_path = RESULTS_DIR / 'padim_shift_full_adaptation_results.json'\n",
        "with open(padim_results_path, 'w') as f:\n",
        "    json.dump(padim_summary_shift, f, indent=2)\n",
        "\n",
        "print(f\"✓ PaDiM results saved to: {padim_results_path}\")\n",
        "\n",
        "# Save training stats as CSV\n",
        "padim_stats_df = pd.DataFrame(padim_training_stats_shift).T\n",
        "padim_stats_df['training_time_seconds'] = padim_stats_df['training_time_seconds'].apply(\n",
        "    lambda x: f\"{float(x):.2f}\" if isinstance(x, (int, float, np.number)) else x\n",
        ")\n",
        "padim_stats_csv = RESULTS_DIR / 'padim_shift_training_stats.csv'\n",
        "padim_stats_df.to_csv(padim_stats_csv)\n",
        "print(f\"✓ Training stats saved to: {padim_stats_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e234939",
      "metadata": {
        "id": "1e234939"
      },
      "source": [
        "---\n",
        "# PART C: AGGREGATE RESULTS & VISUALIZATIONS\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3c5306",
      "metadata": {
        "id": "fe3c5306"
      },
      "source": [
        "## 16. Aggregate Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35314b71",
      "metadata": {
        "id": "35314b71"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AGGREGATE RESULTS - PHASE 7: FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Aggregate image-level metrics\n",
        "def aggregate_image_metrics_across_classes(results_dict):\n",
        "    \"\"\"Aggregate image-level metrics across all classes.\"\"\"\n",
        "    metrics_by_class = {}\n",
        "    for class_name, result in results_dict.items():\n",
        "        metrics_by_class[class_name] = result['image_metrics']\n",
        "\n",
        "    # Compute macro-average\n",
        "    macro_avg = {}\n",
        "    for metric in ['auroc', 'auprc', 'f1', 'accuracy', 'precision', 'recall']:\n",
        "        values = [m[metric] for m in metrics_by_class.values()]\n",
        "        macro_avg[metric] = np.mean(values)\n",
        "\n",
        "    return metrics_by_class, macro_avg\n",
        "\n",
        "# PatchCore\n",
        "pc_metrics_by_class, pc_macro = aggregate_image_metrics_across_classes(patchcore_results_shift)\n",
        "\n",
        "# PaDiM\n",
        "pd_metrics_by_class, pd_macro = aggregate_image_metrics_across_classes(padim_results_shift)\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"IMAGE-LEVEL METRICS (Test-Shift with Full Adaptation)\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Class':<12} {'Method':<10} {'AUROC':>8} {'AUPRC':>8} {'F1':>8} {'Acc':>8}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    pc_m = pc_metrics_by_class[class_name]\n",
        "    pd_m = pd_metrics_by_class[class_name]\n",
        "\n",
        "    print(f\"{class_name:<12} {'PatchCore':<10} {pc_m['auroc']:>8.4f} {pc_m['auprc']:>8.4f} {pc_m['f1']:>8.4f} {pc_m['accuracy']:>8.4f}\")\n",
        "    print(f\"{'':<12} {'PaDiM':<10} {pd_m['auroc']:>8.4f} {pd_m['auprc']:>8.4f} {pd_m['f1']:>8.4f} {pd_m['accuracy']:>8.4f}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "print(f\"{'MACRO AVG':<12} {'PatchCore':<10} {pc_macro['auroc']:>8.4f} {pc_macro['auprc']:>8.4f} {pc_macro['f1']:>8.4f} {pc_macro['accuracy']:>8.4f}\")\n",
        "print(f\"{'':<12} {'PaDiM':<10} {pd_macro['auroc']:>8.4f} {pd_macro['auprc']:>8.4f} {pd_macro['f1']:>8.4f} {pd_macro['accuracy']:>8.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save summary CSV\n",
        "summary_data = []\n",
        "for class_name in CLASSES:\n",
        "    pc_m = pc_metrics_by_class[class_name]\n",
        "    pd_m = pd_metrics_by_class[class_name]\n",
        "\n",
        "    summary_data.append({\n",
        "        'class': class_name,\n",
        "        'method': 'PatchCore',\n",
        "        'domain': 'shift',\n",
        "        'adaptation': 'full',\n",
        "        'auroc': pc_m['auroc'],\n",
        "        'auprc': pc_m['auprc'],\n",
        "        'f1': pc_m['f1'],\n",
        "        'accuracy': pc_m['accuracy'],\n",
        "        'precision': pc_m['precision'],\n",
        "        'recall': pc_m['recall']\n",
        "    })\n",
        "\n",
        "    summary_data.append({\n",
        "        'class': class_name,\n",
        "        'method': 'PaDiM',\n",
        "        'domain': 'shift',\n",
        "        'adaptation': 'full',\n",
        "        'auroc': pd_m['auroc'],\n",
        "        'auprc': pd_m['auprc'],\n",
        "        'f1': pd_m['f1'],\n",
        "        'accuracy': pd_m['accuracy'],\n",
        "        'precision': pd_m['precision'],\n",
        "        'recall': pd_m['recall']\n",
        "    })\n",
        "\n",
        "# Add macro averages\n",
        "summary_data.append({\n",
        "    'class': 'MACRO_AVG',\n",
        "    'method': 'PatchCore',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'auroc': pc_macro['auroc'],\n",
        "    'auprc': pc_macro['auprc'],\n",
        "    'f1': pc_macro['f1'],\n",
        "    'accuracy': pc_macro['accuracy'],\n",
        "    'precision': pc_macro['precision'],\n",
        "    'recall': pc_macro['recall']\n",
        "})\n",
        "\n",
        "summary_data.append({\n",
        "    'class': 'MACRO_AVG',\n",
        "    'method': 'PaDiM',\n",
        "    'domain': 'shift',\n",
        "    'adaptation': 'full',\n",
        "    'auroc': pd_macro['auroc'],\n",
        "    'auprc': pd_macro['auprc'],\n",
        "    'f1': pd_macro['f1'],\n",
        "    'accuracy': pd_macro['accuracy'],\n",
        "    'precision': pd_macro['precision'],\n",
        "    'recall': pd_macro['recall']\n",
        "})\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_csv_path = RESULTS_DIR / 'shift_full_adaptation_results_summary.csv'\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "print(f\"\\n✓ Summary CSV saved to: {summary_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac1bcb2",
      "metadata": {
        "id": "6ac1bcb2"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# VISUALIZATION: Score Distributions & Calibrated Thresholds\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SCORE DISTRIBUTIONS & CALIBRATED THRESHOLDS (Val-shift)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "fig, axes = plt.subplots(len(CLASSES), 2, figsize=(14, 4*len(CLASSES)))\n",
        "\n",
        "# Handle single class case (axes would be 1D)\n",
        "if len(CLASSES) == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    # PatchCore\n",
        "    ax1 = axes[i, 0]\n",
        "    pc_data = calibration_data['patchcore'][class_name]\n",
        "    normal_scores = pc_data['scores'][pc_data['labels'] == 0]\n",
        "    anomalous_scores = pc_data['scores'][pc_data['labels'] == 1]\n",
        "\n",
        "    ax1.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue', edgecolor='black')\n",
        "    ax1.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red', edgecolor='black')\n",
        "    ax1.axvline(pc_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pc_data[\"threshold\"]:.2f}')\n",
        "    ax1.set_title(f'PatchCore - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Anomaly Score', fontsize=10)\n",
        "    ax1.set_ylabel('Count', fontsize=10)\n",
        "    ax1.legend(loc='upper right', fontsize=9)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # PaDiM\n",
        "    ax2 = axes[i, 1]\n",
        "    pd_data = calibration_data['padim'][class_name]\n",
        "    normal_scores = pd_data['scores'][pd_data['labels'] == 0]\n",
        "    anomalous_scores = pd_data['scores'][pd_data['labels'] == 1]\n",
        "\n",
        "    ax2.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue', edgecolor='black')\n",
        "    ax2.hist(anomalous_scores, bins=30, alpha=0.6, label='Anomalous', color='red', edgecolor='black')\n",
        "    ax2.axvline(pd_data['threshold'], color='green', linestyle='--', linewidth=2,\n",
        "                label=f'Threshold: {pd_data[\"threshold\"]:.2f}')\n",
        "    ax2.set_title(f'PaDiM - {class_name}', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlabel('Anomaly Score', fontsize=10)\n",
        "    ax2.set_ylabel('Count', fontsize=10)\n",
        "    ax2.legend(loc='upper right', fontsize=9)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Score Distributions & Calibrated Thresholds (Val-shift)',\n",
        "             fontsize=16, fontweight='bold', y=1.0)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "save_path = VIZ_DIR / 'score_distributions_shift_full_adaptation.png'\n",
        "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n[SAVED] {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10363fe",
      "metadata": {
        "id": "a10363fe"
      },
      "source": [
        "## 17. Visualize ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3fc468",
      "metadata": {
        "id": "1a3fc468"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating ROC curves...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for idx, class_name in enumerate(CLASSES):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # PatchCore\n",
        "    pc_scores = np.array(patchcore_results_shift[class_name]['predictions']['scores'])\n",
        "    pc_labels = np.array(patchcore_results_shift[class_name]['predictions']['labels'])\n",
        "    pc_fpr, pc_tpr, _ = compute_roc_curve(pc_labels, pc_scores)\n",
        "    pc_auroc = patchcore_results_shift[class_name]['image_metrics']['auroc']\n",
        "\n",
        "    # PaDiM\n",
        "    pd_scores = np.array(padim_results_shift[class_name]['predictions']['scores'])\n",
        "    pd_labels = np.array(padim_results_shift[class_name]['predictions']['labels'])\n",
        "    pd_fpr, pd_tpr, _ = compute_roc_curve(pd_labels, pd_scores)\n",
        "    pd_auroc = padim_results_shift[class_name]['image_metrics']['auroc']\n",
        "\n",
        "    # Plot\n",
        "    ax.plot(pc_fpr, pc_tpr, label=f'PatchCore (AUROC={pc_auroc:.3f})', linewidth=2)\n",
        "    ax.plot(pd_fpr, pd_tpr, label=f'PaDiM (AUROC={pd_auroc:.3f})', linewidth=2)\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
        "\n",
        "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "    ax.set_title(f'{class_name.capitalize()} - ROC Curve', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "roc_path = VIZ_DIR / 'roc_curves_shift_full_adaptation.png'\n",
        "plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ ROC curves saved to: {roc_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652af899",
      "metadata": {
        "id": "652af899"
      },
      "source": [
        "## 18. Visualize Precision-Recall Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b0300d",
      "metadata": {
        "id": "a5b0300d"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating Precision-Recall curves...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for idx, class_name in enumerate(CLASSES):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # PatchCore\n",
        "    pc_scores = np.array(patchcore_results_shift[class_name]['predictions']['scores'])\n",
        "    pc_labels = np.array(patchcore_results_shift[class_name]['predictions']['labels'])\n",
        "    pc_precision, pc_recall, _ = compute_pr_curve(pc_labels, pc_scores)\n",
        "    pc_auprc = patchcore_results_shift[class_name]['image_metrics']['auprc']\n",
        "\n",
        "    # PaDiM\n",
        "    pd_scores = np.array(padim_results_shift[class_name]['predictions']['scores'])\n",
        "    pd_labels = np.array(padim_results_shift[class_name]['predictions']['labels'])\n",
        "    pd_precision, pd_recall, _ = compute_pr_curve(pd_labels, pd_scores)\n",
        "    pd_auprc = padim_results_shift[class_name]['image_metrics']['auprc']\n",
        "\n",
        "    # Plot\n",
        "    ax.plot(pc_recall, pc_precision, label=f'PatchCore (AUPRC={pc_auprc:.3f})', linewidth=2)\n",
        "    ax.plot(pd_recall, pd_precision, label=f'PaDiM (AUPRC={pd_auprc:.3f})', linewidth=2)\n",
        "\n",
        "    # Random baseline (proportion of anomalies)\n",
        "    baseline = sum(pc_labels) / len(pc_labels)\n",
        "    ax.axhline(y=baseline, color='k', linestyle='--', label=f'Random (P={baseline:.2f})', linewidth=1)\n",
        "\n",
        "    ax.set_xlabel('Recall', fontsize=12)\n",
        "    ax.set_ylabel('Precision', fontsize=12)\n",
        "    ax.set_title(f'{class_name.capitalize()} - PR Curve', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower left')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "pr_path = VIZ_DIR / 'pr_curves_shift_full_adaptation.png'\n",
        "plt.savefig(pr_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ PR curves saved to: {pr_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e502fe2",
      "metadata": {
        "id": "6e502fe2"
      },
      "source": [
        "## 19. Visualize Sample Predictions with Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0114956",
      "metadata": {
        "id": "d0114956"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating sample predictions with heatmaps...\")\n",
        "\n",
        "def denormalize_image(img_tensor, mean, std):\n",
        "    \"\"\"Denormalize image for visualization.\"\"\"\n",
        "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    img = img * np.array(std) + np.array(mean)\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "# Select one class for detailed visualization\n",
        "class_name = 'hazelnut'  # Change to visualize other classes\n",
        "\n",
        "print(f\"\\nVisualizing predictions for: {class_name.upper()}\")\n",
        "\n",
        "# Load test-shift data for this class\n",
        "test_split = shifted_splits[class_name]['test']\n",
        "test_dataset = MVTecDataset.from_split(\n",
        "    test_split,\n",
        "    transform=transform,\n",
        "    phase='test'\n",
        ")\n",
        "\n",
        "# Get anomalous samples\n",
        "anomalous_indices = [i for i, l in enumerate(test_dataset.labels) if l == 1]\n",
        "\n",
        "# Select 6 random anomalous samples\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(anomalous_indices, min(6, len(anomalous_indices)), replace=False)\n",
        "\n",
        "# Get predictions\n",
        "patchcore_model = patchcore_models_shift[class_name]\n",
        "padim_model = padim_models_shift[class_name]\n",
        "\n",
        "fig, axes = plt.subplots(6, 4, figsize=(16, 24))\n",
        "\n",
        "for row_idx, sample_idx in enumerate(sample_indices):\n",
        "    image, mask, label, path = test_dataset[sample_idx]\n",
        "\n",
        "    # PatchCore prediction\n",
        "    with torch.no_grad():\n",
        "        pc_score, pc_heatmap = patchcore_model.predict(image.unsqueeze(0).to(DEVICE), return_heatmaps=True)\n",
        "        pc_score = pc_score[0].cpu().numpy()\n",
        "        pc_heatmap = pc_heatmap[0].cpu().numpy()\n",
        "\n",
        "    # PaDiM prediction\n",
        "    with torch.no_grad():\n",
        "        pd_score, pd_heatmap = padim_model.predict(image.unsqueeze(0).to(DEVICE))\n",
        "        pd_score = pd_score[0].cpu().numpy()\n",
        "        pd_heatmap = pd_heatmap[0].cpu().numpy()\n",
        "\n",
        "    # Denormalize image\n",
        "    img_vis = denormalize_image(image, config.dataset.normalize.mean, config.dataset.normalize.std)\n",
        "\n",
        "    # Plot\n",
        "    # Column 1: Original Image\n",
        "    axes[row_idx, 0].imshow(img_vis)\n",
        "    axes[row_idx, 0].set_title(f'Original\\nScore: {pc_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 0].axis('off')\n",
        "\n",
        "    # Column 2: Ground Truth Mask\n",
        "    if mask is not None:\n",
        "        axes[row_idx, 1].imshow(mask.squeeze(), cmap='gray')\n",
        "        axes[row_idx, 1].set_title('GT Mask', fontsize=10)\n",
        "    else:\n",
        "        axes[row_idx, 1].text(0.5, 0.5, 'No Mask', ha='center', va='center', fontsize=12)\n",
        "    axes[row_idx, 1].axis('off')\n",
        "\n",
        "    # Column 3: PatchCore Heatmap\n",
        "    axes[row_idx, 2].imshow(img_vis)\n",
        "    heatmap_overlay = axes[row_idx, 2].imshow(pc_heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[row_idx, 2].set_title(f'PatchCore\\nScore: {pc_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 2].axis('off')\n",
        "\n",
        "    # Column 4: PaDiM Heatmap\n",
        "    axes[row_idx, 3].imshow(img_vis)\n",
        "    axes[row_idx, 3].imshow(pd_heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[row_idx, 3].set_title(f'PaDiM\\nScore: {pd_score:.3f}', fontsize=10)\n",
        "    axes[row_idx, 3].axis('off')\n",
        "\n",
        "plt.suptitle(f'{class_name.capitalize()} - Sample Predictions (Test-Shift with Full Adaptation)',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "heatmap_path = VIZ_DIR / f'sample_predictions_{class_name}_shift_full_adaptation.png'\n",
        "plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ Sample predictions saved to: {heatmap_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d3a16d",
      "metadata": {
        "id": "85d3a16d"
      },
      "source": [
        "## 20. Final Summary and Comparison with Phase 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8b8b10",
      "metadata": {
        "id": "2c8b8b10"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PHASE 7 COMPLETE - FULL SHIFT ADAPTATION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey Achievements:\")\n",
        "print(\"  ✓ Re-trained PatchCore on Train-shift (all classes)\")\n",
        "print(\"  ✓ Re-trained PaDiM on Train-shift (all classes)\")\n",
        "print(\"  ✓ Calibrated thresholds on Val-shift (F1-optimal)\")\n",
        "print(\"  ✓ Evaluated on Test-shift with adapted models\")\n",
        "print(\"  ✓ Generated comprehensive visualizations\")\n",
        "print(\"\\nExpected Improvements over Phase 6 (No Adaptation):\")\n",
        "print(\"  • Image AUROC: ~15-20% improvement\")\n",
        "print(\"  • Pixel AUROC: ~15-20% improvement\")\n",
        "print(\"  • F1-Score: ~20-25% improvement\")\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"  • Compare results with Phase 6 (notebooks 07 & 08)\")\n",
        "print(\"  • Analyze performance recovery\")\n",
        "print(\"  • Identify remaining gaps and failure cases\")\n",
        "print(\"  • Generate final report tables\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print file locations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OUTPUT FILES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nModels:\")\n",
        "for class_name in CLASSES:\n",
        "    print(f\"  • patchcore_{class_name}_shift.npy\")\n",
        "    print(f\"  • patchcore_{class_name}_shift_config.pth\")\n",
        "    print(f\"  • padim_{class_name}_shift.pt\")\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "print(f\"  • {patchcore_results_path.name}\")\n",
        "print(f\"  • {padim_results_path.name}\")\n",
        "print(f\"  • {summary_csv_path.name}\")\n",
        "\n",
        "print(\"\\nThresholds:\")\n",
        "print(f\"  • {patchcore_thresholds_path.name}\")\n",
        "print(f\"  • {padim_thresholds_path.name}\")\n",
        "\n",
        "print(\"\\nVisualizations:\")\n",
        "print(f\"  • roc_curves_shift_full_adaptation.png\")\n",
        "print(f\"  • pr_curves_shift_full_adaptation.png\")\n",
        "print(f\"  • sample_predictions_*_shift_full_adaptation.png\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abf2a02",
      "metadata": {
        "id": "2abf2a02"
      },
      "source": [
        "\n",
        "**FILES GENERATED - PHASE 7: FULL SHIFT ADAPTATION**\n",
        "\n",
        "---\n",
        "\n",
        "### 📦 MODELS TRAINED ON TRAIN-SHIFT\n",
        "**Directory:** `outputs/models/`\n",
        "- `patchcore_<class>_shift.npy` — PatchCore memory bank\n",
        "- `patchcore_<class>_shift_config.pth` — PatchCore config\n",
        "- `padim_<class>_shift.pt` — PaDiM model (Gaussian distributions)\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 RESULTS & METRICS\n",
        "**Directory:** `outputs/results/`\n",
        "- `patchcore_shift_full_adaptation_results.json` — Complete PatchCore results (all metrics per class)\n",
        "- `padim_shift_full_adaptation_results.json` — Complete PaDiM results (all metrics per class)\n",
        "- `shift_full_adaptation_results_summary.csv` — Summary table with macro-averages\n",
        "- `patchcore_shift_training_stats.csv` — Training statistics for PatchCore\n",
        "- `padim_shift_training_stats.csv` — Training statistics for PaDiM\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 CALIBRATED THRESHOLDS\n",
        "**Directory:** `outputs/thresholds/`\n",
        "- `patchcore_shift_thresholds.json` — F1-optimal thresholds calibrated on Val-shift\n",
        "- `padim_shift_thresholds.json` — F1-optimal thresholds calibrated on Val-shift\n",
        "\n",
        "---\n",
        "\n",
        "### 📈 VISUALIZATIONS\n",
        "**Directory:** `outputs/visualizations/shifted_full_adaptation/`\n",
        "- `score_distributions_shift_full_adaptation.png` — Score distributions with thresholds for all classes\n",
        "- `roc_curves_shift_full_adaptation.png` — ROC curves comparing PatchCore vs PaDiM\n",
        "- `pr_curves_shift_full_adaptation.png` — Precision-Recall curves\n",
        "- `sample_predictions_<class>_shift_full_adaptation.png` — Heatmap overlays on anomalous samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f336e77",
      "metadata": {
        "id": "3f336e77"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# COPY ALL RESULTS TO GOOGLE DRIVE FOR PERSISTENCE\n",
        "# ============================================================\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Create destination folder in Drive\n",
        "DRIVE_ROOT = Path('/content/drive/MyDrive/anomaly_detection_project')\n",
        "PHASE7_OUTPUTS = DRIVE_ROOT / '09_full_shift_adaptation_outputs'\n",
        "PHASE7_OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COPYING FILES TO GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDestination: {PHASE7_OUTPUTS}\")\n",
        "\n",
        "# List of all generated files\n",
        "generated_files = []\n",
        "\n",
        "# Models\n",
        "print(\"\\n📦 Copying models...\")\n",
        "for class_name in CLASSES:\n",
        "    model_files = [\n",
        "        MODELS_DIR / f'patchcore_{class_name}_shift.npy',\n",
        "        MODELS_DIR / f'patchcore_{class_name}_shift_config.pth',\n",
        "        MODELS_DIR / f'padim_{class_name}_shift.pt'\n",
        "    ]\n",
        "    generated_files.extend(model_files)\n",
        "\n",
        "# Results\n",
        "print(\"📊 Copying results...\")\n",
        "result_files = [\n",
        "    RESULTS_DIR / 'patchcore_shift_full_adaptation_results.json',\n",
        "    RESULTS_DIR / 'padim_shift_full_adaptation_results.json',\n",
        "    RESULTS_DIR / 'shift_full_adaptation_results_summary.csv',\n",
        "    RESULTS_DIR / 'patchcore_shift_training_stats.csv',\n",
        "    RESULTS_DIR / 'padim_shift_training_stats.csv'\n",
        "]\n",
        "generated_files.extend(result_files)\n",
        "\n",
        "# Thresholds\n",
        "print(\"🎯 Copying thresholds...\")\n",
        "threshold_files = [\n",
        "    THRESHOLDS_DIR / 'patchcore_shift_thresholds.json',\n",
        "    THRESHOLDS_DIR / 'padim_shift_thresholds.json'\n",
        "]\n",
        "generated_files.extend(threshold_files)\n",
        "\n",
        "# Visualizations\n",
        "print(\"📈 Copying visualizations...\")\n",
        "viz_files = [\n",
        "    VIZ_DIR / 'score_distributions_shift_full_adaptation.png',\n",
        "    VIZ_DIR / 'roc_curves_shift_full_adaptation.png',\n",
        "    VIZ_DIR / 'pr_curves_shift_full_adaptation.png'\n",
        "]\n",
        "for class_name in CLASSES:\n",
        "    viz_files.append(VIZ_DIR / f'sample_predictions_{class_name}_shift_full_adaptation.png')\n",
        "generated_files.extend(viz_files)\n",
        "\n",
        "# Copy all files\n",
        "copied_count = 0\n",
        "missing_count = 0\n",
        "\n",
        "for src_path in generated_files:\n",
        "    if src_path.exists():\n",
        "        # Preserve directory structure\n",
        "        if 'models' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'models'\n",
        "        elif 'results' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'results'\n",
        "        elif 'thresholds' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'thresholds'\n",
        "        elif 'visualizations' in str(src_path):\n",
        "            dst_dir = PHASE7_OUTPUTS / 'visualizations'\n",
        "        else:\n",
        "            dst_dir = PHASE7_OUTPUTS\n",
        "\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        dst_path = dst_dir / src_path.name\n",
        "\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        print(f\"  ✓ {src_path.name}\")\n",
        "        copied_count += 1\n",
        "    else:\n",
        "        print(f\"  ✗ MISSING: {src_path.name}\")\n",
        "        missing_count += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ Copy complete: {copied_count} files copied, {missing_count} missing\")\n",
        "print(f\"✓ All results saved to: {PHASE7_OUTPUTS}\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}